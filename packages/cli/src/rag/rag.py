import json
from ragatouille import RAGPretrainedModel
from ragatouille.data import CorpusProcessor
from typing import List, Optional, TypedDict


class Document(TypedDict):
    content: str
    metadata: dict


class SearchArgs(TypedDict):
    query: List[str]
    docs: List[Document]
    k: Optional[int]


class SearchResult(TypedDict):
    content: str
    score: float
    rank: int
    result_index: int
    metadata: dict


def rag(args: SearchArgs) -> List[List[SearchResult]]:
    RAG = RAGPretrainedModel.from_pretrained("colbert-ir/colbertv2.0", verbose=0)
    metadatas = [doc["metadata"] for doc in args["docs"] if "metadata" in doc]
    doc_contents = [doc["content"] for doc in args["docs"]]
    k = args.get("k", 5)
    search_results = RAG.rerank(query=args["query"], documents=doc_contents, k=k)
    if type(search_results[0]) is not list:
        if len(metadatas) > 0:
            for result in search_results:
                result["metadata"] = metadatas[result["result_index"]]
        return [search_results]
    else:
        if len(metadatas) > 0:
            for batch in search_results:
                for result in batch:
                    result["metadata"] = metadatas[result["result_index"]]
        return search_results


clips = [
    {
        "content": " hey everyone thank you so much for watching the wevia podcast I'm super super excited about this podcast we have Greg kamrat and Colin Harman these two are both uh prolific entrepreneurs in the space of llm Agents uh Greg has made all sorts of amazing content about Lang chain and different examples of uh prom says AI early signal series and uh Colin has given this really impressive lecture on hallucinations and how that is manifested in agents and how to fix it at the haystack conference so I thought it would be so exciting to bring these two together and just hash out everything with our current understanding of Agents laying chain llama index and just how this whole Space is evolving uh so firstly guys thank you so much for joining the thank you so much for joining the podcast podcast absolutely thanks for having us happy to be here awesome so could we do a round of intros uh Greg can you tell us about like how you came to be working in this space yeah absolutely so my background is actually on the B2B products side of the house so I used to run a growth team over at Salesforce for sales and service cloud and then I was the first operations hire at digits which is a series C fintech company and I have a history of teaching people how to do data analysis and build data products but this year my focus has been teaching people how to use AI tools to build AI products and it's just a fascinating space right now because not only is the applications evolving but even the tools are evolving",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 0, "maxCueIdx": 41},
    },
    {
        "content": " history of teaching people how to do data analysis and build data products but this year my focus has been teaching people how to use AI tools to build AI products and it's just a fascinating space right now because not only is the applications evolving but even the tools are evolving themselves and so it's really a turbulent time which is fun to be in yeah amazing I think um I can't speak to enough of how much your videos have helped me understand Lang chain and it's very cool hearing the Salesforce background because that that uh write 100 sales emails with the Y combinator video you did I can't wait to dive into that because I think that's such an interesting topic with how this like you know personalized retrieval augmented generation can impact that kind of thing um so before we dive into it any further Colin could you also kind of tell the story of like how you can be working in this space yeah absolutely so a few years ago I was working as a machine learning engineer and um had some exposure to natural language processing and kind of decided to go all in on that and that was it turns out a pretty good time to make that decision um and then you know my in my current role I'm the head of Technology at Nash which builds uh Enterprise search and automation applications for heavy Industries so upon starting there also got really into the information retrieval side of things and um as both of you know both of those Concepts have kind of exploded in the past year two years so it's",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 34, "maxCueIdx": 75},
    },
    {
        "content": ": 68 which builds uh Enterprise search and automation applications for heavy Industries so upon starting there also got really into the information retrieval side of things and um as both of you know both of those Concepts have kind of exploded in the past year two years so it's been a great time to be in that area and and you know following content like um Connors and Greg's has been super helpful and um it's very important so uh yeah that's how I ended up here and and now just trying to you know find the future of how do you put these things into products and and understand it properly yeah fascinating I think maybe also to kick things off if we could do a round of just like how are we each thinking about like Lang chain llama index Chad gbt Marketplace just generally the space of like large language models using tools this General concept of agency like like how how would you define it to someone um yeah I'll get i'll get started with that but really I think my my opinion on it is a little it is a little um um maybe a little more old school basically um I I've been asking myself this question okay we're talking about AI a lot right and a year ago what did an AI team do and what what did you need to provide value with AI and the answer to that was basically you needed a significant amount of talent you needed a significant amount of data and you needed in many cases a lot of compute resources as well right so that's what AI was",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 69, "maxCueIdx": 109},
    },
    {
        "content": ": 102 team do and what what did you need to provide value with AI and the answer to that was basically you needed a significant amount of talent you needed a significant amount of data and you needed in many cases a lot of compute resources as well right so that's what AI was um however not with language models if you want to be AI you want to do language models you don't need any of those things right thanks to people like you guys anyone can figure out how to use these and you don't need compute to do it you can use it like a software tool so I'm thinking of language models now as a type of software just another Block in the software stack this is not AI it doesn't require special talent doesn't require special data right because the data comes with the tool um so broadly I think of of Agents as a type of application that uses language models right and I think I think you're starting to see some hints of that from entities like Microsoft talking about things in that way as well this is just the new normal and it's going to be part of you know every not every system but a large large proportion of systems out there so um agents in particular if I were to make that more specific I'd say agents are aspects of those applications that choose and use various subsystems so I'll leave it at that and we can iterate on it a bit yeah and then just to join in on there I 100 agree I think that we're seeing a pattern here where you see an early iteration of a tool that's just",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 103, "maxCueIdx": 142},
    },
    {
        "content": " those applications that choose and use various subsystems so I'll leave it at that and we can iterate on it a bit yeah and then just to join in on there I 100 agree I think that we're seeing a pattern here where you see an early iteration of a tool that's just clearly going to be what the future is going to look like now the the other side of that coin is that the reliability piece and so you're seeing things like the baby AGI and the auto GPT is it a question that they're going to be that's going to be the model for the future without a doubt it won't be the exact same thing but that sort of framework is going to be prevalent for sure we aren't quite there yet because we're solving a whole bunch of other problems that come with it but um I am all in on agents I'm a Believer count me in for it yeah I think those are both great uh you know great overviews from just the concept of just large language models being just like a compute primitive this kind of like person in the computer that you can just put in any intermediate layer of some you know transformation of data across an API or doing different kinds of skills that you can compress into natural language um so I you know in preparing for this podcast I took a look at blank chains documentation to see like what's the newest you know presentation of the ideas and so Harrison the latest abstraction is thinking that large language models can be based around you know data aware large language models and then agent uh ID",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 136, "maxCueIdx": 175},
    },
    {
        "content": "168 in preparing for this podcast I took a look at blank chains documentation to see like what's the newest you know presentation of the ideas and so Harrison the latest abstraction is thinking that large language models can be based around you know data aware large language models and then agent uh a gen agent center there's some kind of like agent agentic I've never seen that word before like agent icy but so I say these two things as like you know you connect to the data like in a vector database and that's where you know our interests around this really comes and then also connecting with the apis so I guess kind of I want to start off by diving into the data aware llms and sort of what you guys are seeing with you know I know Colin has done a lot of work on hallucinations and you know Greg has tons of videos on ingesting particular kind of data into something like a vector database so that you can then retrieve the context and facilitate the generation so how you guys currently think about this kind of like making large language models customized to your data through the use of like you know connecting it to of like you know connecting it to databases databases yeah I'll jump in quickly on that one my view on it is it's a very romantic idea to think that a language model can do anything that you want it to right and it communicates and the story tells very well that you can throw whatever command at it whatever data at it and it's just going to magically return things back to you but I think what we're",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 169, "maxCueIdx": 208},
    },
    {
        "content": " a very romantic idea to think that a language model can do anything that you want it to right and it communicates and the story tells very well that you can throw whatever command at it whatever data at it and it's just going to magically return things back to you but I think what we're seeing here is that language models are really good at some sort of tasks they're not wonderful at all tasks and that's okay because we don't want to over overload the system with too many um too many different types of requests and an example of that is where you see people say hey language model please think out loud first and then answer my question as opposed to just hey go answer my question for that so when it comes to adding data to the context of your language model I see too many folks try to throw the kitchen sink and just throw every single thing that they can on there where I think in reality you can get a really long way with better prompting and more signal to noise ratio within the context that you're passing in the first place which just speaks to the programmatic ability to do really awesome retrieval in the first place as opposed to giving everything to the language model yeah and I think a lot of it is about just how many places in kind of a search pipeline you can inject a large language model so from data ingestion using the large language model to kind of extract and format the data for the schema say you have like this High H lowercase y capital D capital E is like this idea of where you you take a query and you have",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 202, "maxCueIdx": 241},
    },
    {
        "content": " of a search pipeline you can inject a large language model so from data ingestion using the large language model to kind of extract and format the data for the schema say you have like this High H lowercase y capital D capital E is like this idea of where you you take a query and you have the large language model generate a potential document and you search with that document or say using the large language model to cut the search results say type 10 results passive language model language what else has only give these two to the next step in the chain or say the large language model re-ranks it it's like there's so many places to put the large language model in this kind of retrieval Pipeline and get better search results but I think a great topic Colin would be talking about this hallucination problem how like where are we at with hallucination and fixing it with the kind of retrieval fixing it with the kind of retrieval yeah yeah um I thought Greg brought up a great point right asking the language model to do the wrong task and that I would say is is one of the big problems here I was just talking to a client today about about you know how you can do better on math problems when you use you know true thought chain of threat prompting thought chain of threat prompting systems systems um but why would you want to solve a math problem probabilistically because you know these models have a certain error rate on these math problems when we know how to solve math problems right we we've figured that out ",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 235, "maxCueIdx": 276},
    },
    {
        "content": "268 thought chain of threat prompting systems systems um but why would you want to solve a math problem probabilistically because you know these models have a certain error rate on these math problems when we know how to solve math problems right we we've figured that out that came with when computers were invented right so um there's there's a big question of don't solve the wrong problem or don't solve a problem with the wrong tool pick the right tool for the problem and um and then getting back to okay like how do you use these language models and applications really step one for 95 of applications is going to be connect this to your proprietary data or whatever data you're trying to attend your application over so retrieval necessarily is the most important part of any of these Real World Language model applications just because um look at any software application right those are based on data as well software applications use databases they use search um so the same thing needs to happen with uh with language models because if you don't do that that's not a truly useful product it's like a demo right or you can do it in chat GPT so for most people building building businesses you need to build something better than what you can do in chat GPT and the easiest and most straightforward way to do that is connect to the important data and that yeah that can be that could be a vector index a Keyword Index like bm25 it could also be managed index like Bing search API or it could be um it could",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 269, "maxCueIdx": 310},
    },
    {
        "content": "you can do in chat GPT and the easiest and most straightforward way to do that is connect to the important data and that yeah that can be that could be a vector index a Keyword Index like bm25 it could also be managed index like Bing search API or it could be um it could be a structured database which I know Connor you're you're into the the querying using language models thing and we've been doing that for a while now too and every single one of those can be optimized using language models throughout the process so so yeah you have this concept of okay retrieve and then generate but generate can also bleed into that retrieve step and it doesn't have to be a one directional process right you can go back and forth so there's a lot of ways to improve it but it's most basic you need to retrieve if you want to deliver business value yeah I I love that not a one directional thing I mean as you mentioned like yeah I love that um like I think now llama index and Langston are both calling it The self querying retriever where you ask it you know like uh What uh uh like how long do golden doodles live on average as a dark question think about the mortality of gold noodles but like and then you you would give it like the you know symbolic schema that you like you know Vector databases like weaviate in addition to storing your unstructured text chunks you also usually have some symbolic data around the text chunks and we integrate that kind of stuff into the vector index so you have filtered search but so you so you know you give it the ",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 304, "maxCueIdx": 342},
    },
    {
        "content": " you like you know Vector databases like weaviate in addition to storing your unstructured text chunks you also usually have some symbolic data around the text chunks and we integrate that kind of stuff into the vector index so you have filtered search but so you so you know you give it the properties in the prompt and it might say you know where animal equals dog and then you know you have the symbolic filter so there's like that notion to it where you can just use more of the levers to the search engine it kind of is like with web GPT you have these search actions like you know do you want to scroll to the next page of the Bing search results and and this kind of thing and you know but so there's like that there's like using the llm to control all the levers of the vector database but I also really love this concept of um you know like an interface and this is kind of how I see client Frameworks even like stepping like into the software hat of like you know database client Frameworks like I see something like Lang chain llama indexes orchestrating like Eva and like say neo4j and then like an SQL system and like using the unique benefits of combining your data in each of these ways another kind of really interesting area of retrieval from different kinds of information sources but I think it would be a great transition into this kind of tool use now because we've already kind of transitioned from retrieval and we're now kind of making it more like a tool now kind of making it more like a tool like ",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 336, "maxCueIdx": 375},
    },
    {
        "content": " area of retrieval from different kinds of information sources but I think it would be a great transition into this kind of tool use now because we've already kind of transitioned from retrieval and we're now kind of making it more like a tool now kind of making it more like a tool like like you know I'm really curious about like how you guys are seeing things like you know zapier I know Greg has opinions on zapier and like using the calendar apis and like how to how does the tool use kind of come into this picture yeah quicker than that one I think just how I'm confident in that agent Paradigm will obviously be what's happening in the Future tools are the the other side of the coin that come with it I mean that's how you get them to interact with our lives I just saw this quote within the human Loop blog post that said uh Sam Altman suggested that a lot of people thought they wanted apps to be inside of chat gbt so they thought they wanted plugins in chat GPT but in reality what they really wanted was chat GPT in their apps so it's not chat gbt as the central point we're going to interact with all your tools it's rather because really what's the incentive for the third party applications to support that heavily right they what they want is they want the users in their app and they want the chat gbt like abilities within their own app in the first place so as we think about tools I think it's going to be a really interesting dynamic between what's best for the user and",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 369, "maxCueIdx": 408},
    },
    {
        "content": " support that heavily right they what they want is they want the users in their app and they want the chat gbt like abilities within their own app in the first place so as we think about tools I think it's going to be a really interesting dynamic between what's best for the user and what's best for the business because unfortunate not unfortunately but the way that market dynamics usually work is what's best for the business is what's going to come out in the very first place now open source software will of course help out the user and go from there but um I think this is a dynamic we still don't know how it's going to play out quite yet it's so fascinating you brought that up like we did podcast fans stay tuned for uh a deep dive on Chad gbt marketplace with Yana wellender who's building craftful so craftful with a K is um you know it's like a product manager inside of chat gbt sort of so what the product is is it's like prompts that product managers use like for analyzing customer feedback or like you know suggestions for what you do so it's kind of like skill based prompting like I think summarization has been one of the big likes the most successful skill to prompt it with like create and refine mapreduce like how you summarize with a skill and so so on this chat gbt Marketplace thing oh man I think this is so interesting and especially like you know Greg's such a prolific content creator I think this applies to you so interestingly is like and yeah like everyone",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 402, "maxCueIdx": 441},
    },
    {
        "content": " 434 mapreduce like how you summarize with a skill and so so on this chat gbt Marketplace thing oh man I think this is so interesting and especially like you know Greg's such a prolific content creator I think this applies to you so interestingly is like and yeah like everyone really but like imagine like taking all your expertise on how to use Lang chain and like kind of setting up like instead of like a course you would create now you create like a set of prompts and it's like a product on the chat gbt Marketplace and coming back to that market dynamics thing and like the business around it it's like it's like yes I want the users in my app but the exposure of the App Store might be so much like you know kind of it's pretty fascinating I don't know what do you think about that kind of oh I mean you you've kind of it's such an interesting topic to me the difference between Chad gbt Marketplace versus just the API but I think the marketplace offers a lot of marketing yeah I'd say another part of it really like maybe what goes under that that Sam Altman quote is that the llm is a feature now of a different product right and a lot of people are still thinking of it as a product but now it's just a feature right it's just software so you have a lot of people working on projects that are okay like there's some tool I use some software tool I use well I'm going to make a startup to do that with an llm well that's just going to be a feature in the incumbent in one to",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 435, "maxCueIdx": 472},
    },
    {
        "content": " 466 feature right it's just software so you have a lot of people working on projects that are okay like there's some tool I use some software tool I use well I'm going to make a startup to do that with an llm well that's just going to be a feature in the incumbent in one to two months guaranteed unless you're talking about a really really slow about a really really slow um um incumbent so these llms it's just going to be a feature it's going to make its way into everything it's because it's software now right you don't need to hire an AI team there's no barrier to hire an AI team there's no barrier to entry entry um and I think there will still be benefit from having you know possibly a app in the in the Chachi PT Marketplace app in the in the Chachi PT Marketplace but but um truly most of the the really valuable products are things that aren't going to just work in the chat GPT Marketplace because how many apps can you truly make how many um how much value can you truly provide with like a one-to-one okay you know query or you know um chat chat entry and then computation like that is very limited and there's more benefit coming from integrating that into a different platform or a different application you know and building on what Colin just said there another statement I believe to be true is that there will be some Central repository for all the memory about Greg or about any personal person so Greg Greg's style my",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 467, "maxCueIdx": 507},
    },
    {
        "content": " integrating that into a different platform or a different application you know and building on what Colin just said there another statement I believe to be true is that there will be some Central repository for all the memory about Greg or about any personal person so Greg Greg's style my writing style my preferences all that will be held somewhere I it my hypothesis is it will not be application specific so for example Salesforce will have a language model that it's going to know how I interact with Salesforce all right that's great so we'll Zoom so we'll probably Chrome right but what's the language model and where's my central repository for all my preferences across all of those apps or whatever it may be so the reason I bring this up is it's still unclear to me if a chat GPT like tool will be that Central repository that knows everything about me or if a Google's just going to try to go in there because if you think about most my activity it's all through the browser right and if you're Google and you did this for me you'd capture 95 of what I have going on what I have going on um um it's still unclear how that's going to play out but I think it's going to be a mixture of both where applications will have their llm but also there's going to be a Greg llm that's going to be personalized to me that everybody else will have as well so you think that'll be cross businesses that won't be proprietary to a single that won't be proprietary to",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 500, "maxCueIdx": 540},
    },
    {
        "content": " of both where applications will have their llm but also there's going to be a Greg llm that's going to be personalized to me that everybody else will have as well so you think that'll be cross businesses that won't be proprietary to a single that won't be proprietary to a single company company I I well so I think that like obviously Salesforce will have their own and gong will have their own and zoom will have their own and all that but then in order to automate my own work I'm going to want something more local to me so I think that because um we won't live in an llm constrained world like there's going to be like an infinite amount as many as many language models as you want models as you want um um so I think that there will be one that is personalized to me that I own that's a little closer to me um and interacting with other llms from other tools it's really I mean it's inspiring me to think about like kind of like the private GPT and that whole topic I know of you know both of you with this kind of like Enterprise B2B experience on these things like yeah like you know I know just from like hanging out with friends outside of the weeviate circle that a lot of them say you know I can't use chat gbt for work because I can't just like you know put my documents into chat gbt because of the security yeah I'm curious like how how you see the emerging Trends in this ",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 534, "maxCueIdx": 574},
    },
    {
        "content": " friends outside of the weeviate circle that a lot of them say you know I can't use chat gbt for work because I can't just like you know put my documents into chat gbt because of the security yeah I'm curious like how how you see the emerging Trends in this how you see the emerging Trends in this like like like are more like you know companies gonna go to open Ai and say like hey open AI we need you to set this up inside of our cloud like the model inference server inside our cloud is that something that maybe you know open AI or cohere you know anthropic these big model providers would look to or would this maybe be the open source language models or will people start you know training their own language models with maybe you know Mosaic and ML and tools like that yeah sure yeah there's a lot there's a lot there um so yeah you're absolutely right a lot of Enterprises are not comfortable with sending data to open AI um there's some ways that open AI is getting around that and when I say open AI that that'll include you know Google's offering Palm whatever any of these language model providers so often the way they mitigate that first objection is by saying okay well now we're in your cloud provider platform right we're in AWS we're in gcp we're in Azure so you can use that and then you don't have to go outside of azure and then the next level is data retention so I think with most most of these systems you can opt out of data retention now that",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 568, "maxCueIdx": 607},
    },
    {
        "content": " provider platform right we're in AWS we're in gcp we're in Azure so you can use that and then you don't have to go outside of azure and then the next level is data retention so I think with most most of these systems you can opt out of data retention now that's a huge deal for infosec another step that I'm not sure exactly where we are on this is dedicated instances right so you can get that I'm you will probably be able to get dedicated instances of some of these super high performing language models pretty soon and then it probably ends there for the managed models right and then you step into open source world and in open source world you have those previous options but you also have private Cloud you have on-prem and you will even have Edge and Edge is also going to be interesting because we're probably we're probably close to a point where your probably close to a point where your um your um your Windows PC or Apple MacBook may end up having a llm built into it right and we saw the Palm models they had one that you could fit on smartphones right so at some point the compute may come with your device and that changes things a lot right because then it doesn't leave your device that's not it doesn't leave your Cloud it doesn't leave your device you can do anything you want with that probably there's still a little friction just getting these infosec organizations to catch up with all these Concepts and understand okay what is safe what isn't safe are these things stateful how do we",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 601, "maxCueIdx": 640},
    },
    {
        "content": " doesn't leave your Cloud it doesn't leave your device you can do anything you want with that probably there's still a little friction just getting these infosec organizations to catch up with all these Concepts and understand okay what is safe what isn't safe are these things stateful how do we know it for sure but um I was just looking at a company the other day called ask Sage and they're doing they're providing open AI for government entities including you know military right so the fact that that is gaining right so the fact that that is gaining traction traction um using those those open AI instances and content retention turned off is a pretty good sign that enterprises and organizations are starting to understand and realize that they need this and they're willing to take some risks or at least understand those risks better in order to do it nice the um I agree with Colin that the ability like these models let me rephrase um Sam Walton has another quote that I really enjoy which is the cost of intelligence will go to zero right and the cost to serve that intelligence will also go to zero now TBD on the timeline for that but that's the direction it'll go so I agree with Colin fully that the ability to have compute uh Intelligence on our Edge devices will 100 be there now we'll we'll the the market adopt that that's a little bit of a different question for me and the example I want to give is um take for example iMessage versus signal signal uh uh uh touts that they're end and encrypted right well are ID",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 634, "maxCueIdx": 674},
    },
    {
        "content": " 100 be there now we'll we'll the the market adopt that that's a little bit of a different question for me and the example I want to give is um take for example iMessage versus signal signal uh uh uh touts that they're end and encrypted right well are we all using signal today not really we still we still use iMessage and I know that there's encryption and everything around there but I think the point is I think that where this will go is I think just the way that we trust Google and all these big on all these other big info companies to handle our data our Gmail our drives and all that I think that'll be the same level of comfortability that we get to with language models we're just um we kind of jumped into a cold pool and we're still feeling the shock of the water right now but I have a feeling that we're going to warm up right to it and once Google or once this becomes the norm in a google-like company starts to serve this for us we're all gonna we're all gonna be okay with it yeah that that whole thing you know all that introduced so many new ideas to me I'd never actually considered llm on the devices like right into the chip like the new M1 chip also comes with a apple gbt in it and that's that's a really cool idea all these things and then think about the market adoption like I think either we could take this this topic further and talk maybe about like the kind of medical use cases and the evolution of that or I ID: ",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 668, "maxCueIdx": 706},
    },
    {
        "content": " apple gbt in it and that's that's a really cool idea all these things and then think about the market adoption like I think either we could take this this topic further and talk maybe about like the kind of medical use cases and the evolution of that or I think we could talk about sort of pivoting topics entirely and maybe step back into our conversation broadly on agent use and before we dove into this um Greg you had brought up the Chain of Thought Auto gbt so let me actually ask you guys both quickly do you think we should yeah why don't we it was just as the interview host I'll hijack the topic and what let's talk about let's talk about Chain of Thought prompting and auto gbt how do you guys currently see that um I'll give just a very quick opinion on this like I said at the beginning of the interview not only are the applications and use cases evolving we still don't know like what's the right way to run these things in our business which is super interesting but the tools themselves are still evolving so what is the best framework for an agent to Think Through you know we're still figuring that out and the the way that we do figure this out is through market adoption and we see what handles most of the use cases and we let the market help us figure out what to do here now the fact that we're coming out with new Frameworks every single week and we haven't yet settled on one I see that as a beautiful way that Innovation happens and you can't ID: ",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 700, "maxCueIdx": 739},
    },
    {
        "content": "733 see what handles most of the use cases and we let the market help us figure out what to do here now the fact that we're coming out with new Frameworks every single week and we haven't yet settled on one I see that as a beautiful way that Innovation happens and you can't speed this process up anymore let the dust settle let's see what kind of things come through here and we need to trust that Lang chain and llama index and grip tape and fixie and all these folks will be the ones who will take advantage of these new Frameworks and provide them for the end users like us yeah grip tape that's it I haven't heard of that one before but I like that name behind it like uh guardrail is another one that I know with like the preventing hallucinations like having layers at the end of that yeah it's also interesting I mean I guess my thing about the auto gbt kind of craze in that is just this idea of like you know coming up with a plan and then sort of executing the plan asynchronously is sort of like the Computing Paradigm that I think is Computing Paradigm that I think is really really really mind-blowing with this kind of idea is like if I say you know I need to I need to come up with I don't know like a way to optimize my code at the lowest level and it's like research about arm processors research about simd instructions it's like it can like paralyze all this research and like coordinate it how do you think about that kind of component of Auto gbt is ",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 734, "maxCueIdx": 771},
    },
    {
        "content": " with I don't know like a way to optimize my code at the lowest level and it's like research about arm processors research about simd instructions it's like it can like paralyze all this research and like coordinate it how do you think about that kind of component of Auto gbt is like letting all these language model thread it's like a new kind of like multi-threaded programming is how I see multi-threaded programming is how I see it it it yeah yeah um so I think there's some challenges to adoption with the rogpt Paradigm and uh it's something that works really well for an ad hoc Quarry right it's fun it's very cool and it demo as well it demos so well right but it lacks the things that make it valuable to a a serious Enterprise an organization and that could be anyone right that could be you doing your job that could be an organization buying it for their for their people that could be a university giving it to their researchers right and what it lacks is um repeatability for one thing and then kind of this auditability observability that we don't quite have great Frameworks for yet but I'm sure that's coming but to flesh out the repeatability portion a little more let's imagine you have some knowledge workers in an organization right um you could say all right look Auto GPT can do everything that they do but that's probably not going to work very well because at some point you're going to need to compare that with a",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 765, "maxCueIdx": 806},
    },
    {
        "content": "atability portion a little more let's imagine you have some knowledge workers in an organization right um you could say all right look Auto GPT can do everything that they do but that's probably not going to work very well because at some point you're going to need to compare that with a similar task that a different knowledge worker has done um so what I think is going to happen in these organizations are people are going to look at these knowledge worker pieces of work work objects that they produce and what you want to do is group them into basically workflows is a term I've been using I've heard a lot of other people use it as well so let's say let's just take a concrete example you're a data scientist and you're doing topic modeling okay should be familiar to our audience but that's something that you want to roughly follow the same pattern every single time because you're going to share that with other people right and they're going to try to replicate it and if they try to replicate it and their Auto GPT does it a different way you're going to get different answers and what are you going to do so I think what's going to happen is um people will gradually approach all these problems of various fields and kind of segment them into workflows and you'll have some very frequent ones and you'll have some you'll have a long tail right so you have some tasks people do a lot topic modeling you'll have other tasks that people do infrequently like training a new llm right and so you",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 800, "maxCueIdx": 840},
    },
    {
        "content": " and kind of segment them into workflows and you'll have some very frequent ones and you'll have some you'll have a long tail right so you have some tasks people do a lot topic modeling you'll have other tasks that people do infrequently like training a new llm right and so you're going to take those high frequency workflows and you're going to try to automate them and that might not be totally deterministic right there there might be some some routing decisions made within there um so that could be thought of as maybe a sub-agent but then you're going to have some supervisory agent that is choosing that workflow or choosing hey this doesn't fit with anything I'm you know really trained how to do so I'm going to go the long tail route and just go full auto GPT um however that's again not as likely to to be as useful number one because it's harder to trust and number two because hopefully if you did this right those are less frequent tasks so if you can use your language models and your tools and your retrieval to automate these high frequency workflows I think that's how we're going to see a lot of a lot of automation adopted in terms of these like knowledge worker tasks that people Colin question for you on that one um for these for these Advanced workflows there's kind of three pieces there's the language model as the reasoning engine there's the task and the prompt that you give it and then there's the memory in the context that it receives right I can ",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 834, "maxCueIdx": 874},
    },
    {
        "content": "in question for you on that one um for these for these Advanced workflows there's kind of three pieces there's the language model as the reasoning engine there's the task and the prompt that you give it and then there's the memory in the context that it receives right I can see one argument that says once you get to a high enough reasoning level like high enough intelligence level for a language model then you could fine-tune that workflow just through the prompt and through the context that you're feeding it so for example the data topic modeling well do you need to have a specialized reasoning reasoning engine for that data topic modeling or do you just need one of sufficient level pass it the best prompt you can pass it the instructions on how to do topic modeling in the first place and then let it run wild that could end up being sufficient yeah it's very possible but even then you know you have kind of added some deterministic information some you've given it a structure so that structure I think over time will probably evolve toward what you probably evolve toward what you described described described um yeah it well I think you know earlier when I brought up uh what Yana is building with craftful and the child GBC Marketplace is very similar to this idea of like you know I compress like Martin grutendors The Bert topic expert in you know topic model the expert into like a set of prompts on how to run topic modeling analysis is like the craftful ideas you ID: ",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 868, "maxCueIdx": 909},
    },
    {
        "content": " 903 craftful and the child GBC Marketplace is very similar to this idea of like you know I compress like Martin grutendors The Bert topic expert in you know topic model the expert into like a set of prompts on how to run topic modeling analysis is like the craftful ideas you take these prompts on how you generally do like user interviews manage user feedback and and yeah so it's so fascinating I think I think of this as kind of like a skill prompt and I got that kind of like skill prompt from looking at Microsoft semantic kernel and that's like the abstraction that came around like um you know like a prompt for how to do question decomposition like our follow-up questions needed this is kind of a topic around skill prompts it's really related to everything on agents is what is the evolution of few shot examples do we still need to give a few examples of how to use agents or with you know because Chad gbt like it you know it seems like a lot of time like I think react was a paper that was like zero shot tool use so it's like you don't need to give it examples or train out how to use a tool so what do you think fuse shot prompting give it a few examples of using a tool is that still needed yeah I think it's it's definitely still needed and you look at how how people build plugins right now like I like you men I like that you mentioned semantic kernel um I think that's a could end up being a good standard going forward because look how they built that they",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 904, "maxCueIdx": 943},
    },
    {
        "content": " it's it's definitely still needed and you look at how how people build plugins right now like I like you men I like that you mentioned semantic kernel um I think that's a could end up being a good standard going forward because look how they built that they look at how everyone was building plug-ins and then they standardized it and generalized it right and that's not something you really get from the open source Community which is kind of just purely expanding it doesn't have a good contract stage yet whereas Microsoft with that framework has done their expand and contract already expand and contract already um um but in terms of if you want to give a system new capabilities with a new tool system new capabilities with a new tool um um it's most likely that you want to do that with fuse shot um you sure you could just describe it but why would you do away with giving it additional information I think there is a place that fails though which is let's say you have multiple tools and the tool could couldn't include a retrieval system uh you know Atomic tool or also a workflow let's say let's say these interact with each other or they're dependent on each other each other in some way then the kind of oh I'm adding a plug-in so here's my few shots and here's my you know interface that kind of breaks because you need few shots that cross between the different tools plugins workflows whatever and um that may be a time where you'll need to either develop a lot more few shots but",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 936, "maxCueIdx": 977},
    },
    {
        "content": " oh I'm adding a plug-in so here's my few shots and here's my you know interface that kind of breaks because you need few shots that cross between the different tools plugins workflows whatever and um that may be a time where you'll need to either develop a lot more few shots but you can also see how that would like the permutations of that would would get out of control pretty quickly or possibly even train a specialized model to do that sort of planning that it needs to do in order to figure out how to use this this environment of tools rather than just thinking about it is you know I can do one or two things I can do one or two things um um yeah I was gonna say I'm with Colin of course nobody knows but my hypothesis is that a few shot examples will still be around because even if you craft the most perfect prompt I don't think you're going to account for every single situation and giving like a picture speaks a thousand words well so does a like the story of a lot of machine learning is you know examples and then just the research has been how do we learn from as little data as possible and now we've seen that um calling you said something though I I hadn't heard that abstraction before open source is about the expanding whereas like a centralized entity is the contraction I think that you know like it makes a lot of sense and I think that is really interesting and then something I think is really fascinating as well is I think ",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 971, "maxCueIdx": 1010},
    },
    {
        "content": "1004 that abstraction before open source is about the expanding whereas like a centralized entity is the contraction I think that you know like it makes a lot of sense and I think that is really interesting and then something I think is really fascinating as well is I think Greg is one of the world's experts on keeping up with this expanding of what people are doing with prompts Greg has a series called early AI signals and you can see the you know notion template really nice organization of these things and I think this would be a perfect transition Greg if you could talk about like this expanding and how you're keeping up with it sure absolutely so um I have a small side project called early signals and it started as an experiment really because there used to be the saying that every spreadsheet template was a future startup and if you looked at the Craigslist home page every link on there was a future startup it's like home rental Airbnb car rental Toro et cetera and I was uh just on just social media in general Twitter Youtube Hacker News all that stuff and I noticed that people were using chat gbt for ways that it was not intended to be used they didn't really know you know how it was going to be used so people saying oh I use chat GPT for therapy hmm interesting I use GPT to write my cover letters to help me with my resume and all this and I thought to myself man is chat GPT really the optimal product ID:",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1005, "maxCueIdx": 1041},
    },
    {
        "content": " you know how it was going to be used so people saying oh I use chat GPT for therapy hmm interesting I use GPT to write my cover letters to help me with my resume and all this and I thought to myself man is chat GPT really the optimal product experience to execute against those workflows likely not so this could be an opportunity to productionalize that that workflow now the hard part about this and the piece I need to emphasize is you do not have a defensible business if you just productionalize a prompt so it's a starting point I I believe and there's the hint of it and somebody needs to go out and go build more defensibility around it but early signals I have a collection of those ideas and um it's about weekly I try to go through and say say my favorite five but then give folks the access to I think we're up to like 70 to or 80 different workflows and the important part for each one of these is that I need to show where a user has said that they do this thing so I don't want it to be somebody's idea I wanted to be a user says I do this right now and so you already have a little bit of user for uh adoption for right there yeah I think it's so useful it's such a cool you know it's so interesting just going through it I think like from like the AI girlfriend to like the uh yeah just like um the whole collection of all",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1036, "maxCueIdx": 1071},
    },
    {
        "content": " user for uh adoption for right there yeah I think it's so useful it's such a cool you know it's so interesting just going through it I think like from like the AI girlfriend to like the uh yeah just like um the whole collection of all these things that people do with it and I mean yeah I I I'm just like I'm I'm still kind of like my mind is blowing through my head thinking about this kind of Open Source expansion kind of idea because I do think like Lang chin like when it first came out the way that it was like open source and this kind of collecting the prompts and it's very similar to what you're doing with the early AI signals is just like maybe if I connected to like hugging face in the model Hub the open source like how they've managed to seize open source and it's like because they have you know it's like what are we gonna do with this new tool and it's so creative and it's just pretty interesting uh quick quick I think another Sam almond quote that I really enjoy and I keep on quoting them here but quoting them here but um um the reason the reason he States why they release slow is because the collective intelligence of the human population is unpredictable it's unpredictable they have no idea what what humans are going to do so it's like all right here's chat gbt what do people do here's plugins what do people do here's API you know",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1065, "maxCueIdx": 1101},
    },
    {
        "content": "5 release slow is because the collective intelligence of the human population is unpredictable it's unpredictable they have no idea what what humans are going to do so it's like all right here's chat gbt what do people do here's plugins what do people do here's API you know Etc et cetera um I think that open source expansion open source moves quick like you're talking about Indie hackers all over the world that are putting out really innovative ideas one of the Prime examples of this is baby AGI the founder of that was not a technical by trade person per se he's a VC so how cool is it that somebody who isn't necessarily technical is building this tool that all people around the world can take advantage of and I think that I think that speaks to the open source types of world on there now um proprietary and closed will all will catch up to it but they're driven less by let's provide um selfless Innovation out into the world and they're more commercially driven but it's all it all it all driven but it's all it all it all follows follows I think it depends on that this stage we're in also right because we're still very early and talking about something like agents no one even agrees on the abstractions right like I I was looking at uh fixie which is a pretty cool company and um they have a you know open source package",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1096, "maxCueIdx": 1133},
    },
    {
        "content": "we're in also right because we're still very early and talking about something like agents no one even agrees on the abstractions right like I I was looking at uh fixie which is a pretty cool company and um they have a you know open source package available for agents as well and they call everything agents so like a plug-in for them is an agent right so we can't even agree on the abstractions and eventually we probably will and at that point we need to contract and at that point we need to contract the the the um um we need to focus right and that's not something we're getting a lot of at this stage from tools like Lane chain for the the general agent stuff and from llama index your other example for the ingestion stuff right I think both of these started out very successful because they gave random people quick cookbooks on how to put things together right that was the value they provided it was simple abstractions a collection of wrappers that was basically it like I think a lot of people ended up starting using Lang chain just because it was marginally you know four lines of code easier to do that and instantiate weeviate than it was to instantiate deviate from the like the weeviate documentation which isn't the fault of webe that's just how software works right so they made a wrapper that shrunk right so",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1127, "maxCueIdx": 1166},
    },
    {
        "content": " code easier to do that and instantiate weeviate than it was to instantiate deviate from the like the weeviate documentation which isn't the fault of webe that's just how software works right so they made a wrapper that shrunk right so they made a wrapper that shrunk it it um and same with the openai endpoint so that was valuable to people for a while and I think a lot of people are still primarily deriving value from it for that reason however as it as it balloons as it gets bigger and bigger you're going to start to lose the cookbook of the system because there's too many options and I think you'll see that happen to llama index really quickly is everybody builds a different document parser right and so all of a sudden I go to this I go to this GitHub and I want to find a document parser and instead of having three options where the differences are clearly articulated I now have 2500 right because that's what you're going to have look at hugging face it even happens on hugging face how many models are on hugging face thousands how many of them are useful very very few we don't trust hugging face to tell us which hogging face models are useful even we often get that from somewhere else so um yeah these these open source expanding Frameworks will need to be expanding Frameworks will need to be careful careful um and",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1160, "maxCueIdx": 1197},
    },
    {
        "content": " 1190 face to tell us which hogging face models are useful even we often get that from somewhere else so um yeah these these open source expanding Frameworks will need to be expanding Frameworks will need to be careful careful um and be sure to do some Contracting at some point or else these Frameworks that are much more opinionated like semantic kernel are gonna eat their lunch because they were developed kind of with the same process originally right these these Microsoft people just built a bunch of plugins but then they took that learning and in an organized way turned it into a true organized way turned it into a true framework framework that people could agree on and was as widely valuable yeah that is that is just gold insights I I feel like I take took away so much from that I mean um like we think a lot about the weevier cookbook and how we want to design this thing and yeah it's like you know Tech search with this data set text search with that slightly different data set where you'd use different properties is that the best way to design a cookbook or do you just end up with like 2 000 examples and it's like that just confuses you compared to like one text one image one multimodal and just keeping it to the point it's pretty fascinating um I guess I kind of like in this topic of Open Source I thought maybe there is a link ",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1191, "maxCueIdx": 1228},
    },
    {
        "content": " it's like that just confuses you compared to like one text one image one multimodal and just keeping it to the point it's pretty fascinating um I guess I kind of like in this topic of Open Source I thought maybe there is a link to jump to this next topic which is multi-agent systems like where we have it's kind of like it kind of is similar to Auto gbt to me but like you know say you have like multiple agents that like live in some kind of simulation I mean I had uh you Shang Wu on the podcast who's built chat Arena and what chattering is about is like you know we Greg Colin Connor we each are like retrieval augmented chat Bots that talk to each other and maybe a third language model is judging like who's saying the best points and stuff like these kind of like chat games but like how do you think about that kind of like multi-agent uh llm systems I um quick comment on that one if you were to ask why do we do this multi-agent thing in the first place and it's really uh deficiency in the current models right now not to be able to handle that type of computation or that type of prediction or whatever it may be right and so I I think that is the use case going to be there in the future where you want to interact with an arena of people sure we're seeing the market already want that right now is the answer multi-agent well it's",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1222, "maxCueIdx": 1258},
    },
    {
        "content": ": 1252 prediction or whatever it may be right and so I I think that is the use case going to be there in the future where you want to interact with an arena of people sure we're seeing the market already want that right now is the answer multi-agent well it's a pretty convenient way to constrain One agent to like think about a certain thing and constrain its memory and all that um is that the only way you can construct that type of application no and so is that the framework that I think is going to be the one that persists uh still TBD I'm not going to make a hypothesis not yet yeah I think you're totally on base Greg yeah I think you're totally on base Greg um um a lot of yeah the reason you do that is to make up for their shortcomings and if you had a smarter model why would you need to have two of them talking to each other if it can just you know understand okay well I've got this stuff in my context and I should do something a little differently because that's all the other one does it's just like they're just swapping contexts in a in a different sort of way I think the place where we might see more of that being necessary is yeah further toward the edge more open source where you you maybe have the smaller uh specialized models like for example that that one we kind of talked about where it's trained to use a certain group of tools together but um",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1253, "maxCueIdx": 1289},
    },
    {
        "content": " see more of that being necessary is yeah further toward the edge more open source where you you maybe have the smaller uh specialized models like for example that that one we kind of talked about where it's trained to use a certain group of tools together but um as you get smarter models it shouldn't be as important I mean I think it's just absolutely fascinating I I think it's very related to just like real companies kind of like like if I think about how like you know if I'm if I'm playing this these roles in this multi-agent system the first person is like looking at the Twitter feed you know doing the early AI signals curation and then sees this thing and says I think this could fit in weeviate just like someone who's just picking things I think could go in webiate then you pass that to like the product manager role playing LM who you know has this particular retrieval and maybe also fine-tuning to use those kind of tools to say okay here's the proposal then the engineer you know who's more familiar with the code base and the internals of the database and stuff like okay and then uses the chains of like the you know code execution tool used to like prototype and develop a prototype and then you know you have like some kind of maybe internal pull request review that happens with role-playing of like different engineer llms and then you have like the marketing and like you know without explaining like all the ID",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1283, "maxCueIdx": 1319},
    },
    {
        "content": " to like prototype and develop a prototype and then you know you have like some kind of maybe internal pull request review that happens with role-playing of like different engineer llms and then you have like the marketing and like you know without explaining like all the roles of the engineering company like do you think you don't think do you think that thing would be superseded by just one large language model that sees the new thing on Twitter have her ingest data however it comes up with ideas and just end to end just I don't need this kind of role playing it's just like uh I think my previous statement was just assuming they're all built in from the same language model and the same model that comes in from there now when you start to speak around specialized you start to speak around specialized tasks tasks I think in in that case it's still TBD but a lot of popular opinion is around that you're gonna have specialized models that come around and then with that if that precipitates specialized agents then you'll have a multi-agent world to complete those multi-agent world to complete those tasks tasks yeah I mean it's like well they're kind of like two emerging topics in large language models I think which is the first of which is fine-tuning is becoming cheaper we see like the Q Laura the quantize low rank adaptation that's making it look like you can you know I ID:",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1313, "maxCueIdx": 1351},
    },
    {
        "content": " it's like well they're kind of like two emerging topics in large language models I think which is the first of which is fine-tuning is becoming cheaper we see like the Q Laura the quantize low rank adaptation that's making it look like you can you know I think they say they fine-tuned a 65 billion parameter or large language model on a 48 gigabyte GPU and so it's model on a 48 gigabyte GPU and so it's like like it's like that kind of thing is going to get a lot easier like way easier than it's ever been right how do you think about that kind of Trends in fine tuning uh yeah I mean they're definitely making progress I think there's still some unknowns there was a paper that came out recently talking about how the non the non-managed models it turns out don't generalize nearly as well as as things like GPT 3.5 so I'm sure we can link that I don't recall the title of it at the moment um but if you if you look at that what is it saying it's saying these open source models aren't as good as we thought they were and they don't generalize as well to unseen tasks that actually makes a case for more fine-tuning right if your business has certain tasks you expect you need to do there's more need for you to fine-tune those models again stepping aside from the the super powerful model is the gpt4s of",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1346, "maxCueIdx": 1381},
    },
    {
        "content": " actually makes a case for more fine-tuning right if your business has certain tasks you expect you need to do there's more need for you to fine-tune those models again stepping aside from the the super powerful model is the gpt4s of the world if you're going toward these smaller models then yeah fine tuning will probably be more important and it does seem to be getting way cheaper and that goes hand in hand with the hosting costs or the inference costs as well right they're kind of tightly correlated so with that that quora paper that was really cool I'm excited about that um yeah you can run inference and training for now it's it's accessible to you know you need a little a couple talented people to do it probably but um that's kind of your only probably but um that's kind of your only obstacle obstacle yeah I think that's exactly correct I mean you need to you need to then have like the you know all the ml Ops skills to take advantage of that kind of thing but then if it saves you money saves you that much money compared to like all these repeated inferences of the super smart thing so then the second big Trend I'm very curious about are these like really long input lengths like anthropics is 100k input lengths how do you think that'll change agents I don't know do you know how they do that either you guys know how they did that did they just pay",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1375, "maxCueIdx": 1411},
    },
    {
        "content": ": 1405 I'm very curious about are these like really long input lengths like anthropics is 100k input lengths how do you think that'll change agents I don't know do you know how they do that either you guys know how they did that did they just pay the price or or did they have some trick I feel like people are still trying to figure that people are still trying to figure that out out well I think with mosaics uh MPT they talked they you know talked about Alibi attention and how you can do this kind of like sparse attention where yeah I mean I don't know the exact mechanics of it and I'm sure they optimize it like all the way down to the Cuda cores and like you know have a lot of engineering that goes into that but yeah one one quick thought about it um and then I'd love to hear what you think Greg but with the longer attention I think training probably becomes a lot more difficult and expensive too so beyond the compute which ordinarily with with attention skills quadratically right um that's a problem but then also if you want to generate fine-tuning examples that um they replicate some long context tasks that you want to do in the wild you need to generate some examples of that right and so if you're having people right and so if you're having people right 80 80 000 word examples then you're going to spend a ",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1406, "maxCueIdx": 1443},
    },
    {
        "content": " some long context tasks that you want to do in the wild you need to generate some examples of that right and so if you're having people right and so if you're having people right 80 80 000 word examples then you're going to spend a lot of money doing that you probably need pretty smart people generating those examples but then the other side of things is with longer context length some applications look different right you don't have to do as much retrieval there's a there's a certain window that opens up of data that where you can just put that in the in the context in the put that in the in the context in the prompt prompt and it's not clear how much further we'll be able to go but that definitely does change okay how often do you need to do retrieval um to yeah you can put some in the um to yeah you can put some in the prompt prompt you know I think maybe I'm wearing the adversarial hat being in a vector database company but we're already seeing papers like large language models are distracted by relevant context calling in your Haystack presentation you talked about n greater than one search result in the prompt you know it becomes trickier so yeah I'm I think that it's the the pro of retrieval is like you could still pack a hundred thousand with all sorts of information sources as you search across classes with different queries and stuff just to",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1437, "maxCueIdx": 1475},
    },
    {
        "content": " 1469 search result in the prompt you know it becomes trickier so yeah I'm I think that it's the the pro of retrieval is like you could still pack a hundred thousand with all sorts of information sources as you search across classes with different queries and stuff just to pack this prompt as densely as possible yeah and then generally I think it'd be hard to train those models I agree with that yeah and for me I think that long context weight length it demos really context weight length it demos really well well it does well on Twitter and I think the reason why people are excited about it because it's storytells really well too it's like oh now pass a book into this whole thing however the minute the benchmarks start to go down I become less interested and so really is kind of a dramatic statement I don't care I don't care as much about context length at all I want improved reasoning cheaper and then longer contact well no improved reasoning cheaper lower latency and then uh longer contacts contacts lengths for that because like Khan said which I agree with it's a bit of a it's a controversial statement but a longer context length allows you to be lazier on retrieval and it almost makes up for your inability to not do retrieval as well as you should be doing in the first place potentially I know it's a bit it's a bit of an overstatement but I think that I am fine ",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1470, "maxCueIdx": 1507},
    },
    {
        "content": ": 1501 allows you to be lazier on retrieval and it almost makes up for your inability to not do retrieval as well as you should be doing in the first place potentially I know it's a bit it's a bit of an overstatement but I think that I am fine with managing a shorter context length and needing to beef up my deterministic retrieval to start then um then somebody's saying oh now you can do a million tokens it forces you to build a better system doesn't it yeah fascinating uh Greg and Colin I thought this was such a great tour of all these topics of llm Agents I mean I learned so much on these podcast uh those podcasts um wrapping it up uh Greg and Colin could you each maybe uh give listeners like where to find you keep up with your content hopefully they're you know that's why I read the podcast and want to just dive into all the online content you have um yeah absolutely so two places on YouTube I run underneath the channel called Data independent you can find me over there with a bunch of uh Lang chain content early signals and all that good stuff and then most of my communication happens on Twitter so I'm just at Greg happens on Twitter so I'm just at Greg camerad camerad hey everyone apologies the recording crashed right as we were doing the outros you can find Colin on his blog at colinharman.substack.com and you can also find",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1502, "maxCueIdx": 1538},
    },
    {
        "content": " happens on Twitter so I'm just at Greg camerad camerad hey everyone apologies the recording crashed right as we were doing the outros you can find Colin on his blog at colinharman.substack.com and you can also find calling on LinkedIn at Colin Harmon one more quick bonus on the outro you can check out Colin's new talk at Haystack us 2023 stop hallucinations and half truths and generative search now uploaded to the open source connections YouTube channel as a bonus you can see the ordis Chrome plugin from Alexa gordick this new AI summarization tool for YouTube another really cool thing uh and then also in the spirit of it here's Greg's Channel data Independence so many incredible videos on lighting chain tutorials uh new things about AI the early signal series all sorts of cool stuff so thank you so much for watching the podcast and please be sure to check out Greg and uh Collins videos as well as well as all sorts of other content",
        "metadata": {"videoId": "iB4ki6gdAdc", "minCueIdx": 1532, "maxCueIdx": 1556},
    },
    {
        "content": " good morning Marty good morning John so we are uh just a few miles away from each other across a body of water I'm in San Francisco you're across the bay in Berkeley at your office at University California Berkeley where you are the head of the school of information and a computer scientist who's been in the game for many decades that's right so um I'm excited to finally do this interview because it's been almost a year in the making we had a great interview here on the show with Oren etcione and former head of ai2 in Seattle and after that interview I asked Oren who would who would be a really good guess who would have something worth sharing with the audience and you were the first person he said well I listen I listened to that interview and it was an excellent interview Oren is so articulate and you're a great interviewer and I'm really honored to be here and I'm really honored that Warren thought it was worthwhile to recommend me and you don't do that many interviews uh from what I from what I gather no I don't I'm a little bit camera shy even though I I do have to be on camera a lot but I'm also I like to be pretty careful about what I say uh kind of more from the scientists perspective I think Aura is really great at linking science to business and where technology is going but yeah I guess I'm just a little bit shy that way and that brings me to kind of the big ID",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 0, "maxCueIdx": 41},
    },
    {
        "content": " like to be pretty careful about what I say uh kind of more from the scientists perspective I think Aura is really great at linking science to business and where technology is going but yeah I guess I'm just a little bit shy that way and that brings me to kind of the big story here um so we we for those listening at home Marty and I had a chat um recently before in advance of this interview just to talk about what we might talk about and something really striking was that there's this moment let's call it the Chachi BT moment um it's really the large language model um it's really the large language model moment moment where artificial intelligence seems to be at some kind of inflection point be at some kind of inflection point and and um you told me about your your long um you told me about your your long career career and how you have kind of seen seen these moments before and you're more cautious about speaking publicly to add to the hype cycle because it's often disappointing and often regrettable you know it's easy to say um say things that you later think were um say things that you later think were overhyped overhyped why is this different yeah so I I have seen a lot over the think that part of AI and you know it's just been a slog in terms of making progress and having machines be able to process language the way people do I entered it really because I was ID: ",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 35, "maxCueIdx": 77},
    },
    {
        "content": " 70 why is this different yeah so I I have seen a lot over the think that part of AI and you know it's just been a slog in terms of making progress and having machines be able to process language the way people do I entered it really because I was interested in the brain and interested in language and I thought it'd be kind of neat if we could have a computer do something with language maybe you know make cartoons speak something like that animation interested me as well but it was so uh we're so far from accomplishing anything that would be realistic that it was more of a scientific Endeavor and I think I'm more of a scientist at heart than you know I'm not an entrepreneur for example so I've seen claims for example I remember I guess in the early 90s there was this claim that Oracle bought some NLP company and it was going to transform everything you know it was just so obviously ludicrous but you also see you know I remember when Webb Fountain came out with IBM and that was going to transform everything or how about IBM Watson well you know Watson it talk about that a bit more but then there was the claim that it was going to transform health care and again that there was no path from that to directly to healthcare being transformed in the immediate future so I you know learned that if you read the New York Times regularly as I do technology is in the business section as opposed to the science section and that's kind of how technology is talked about in at least ID",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 71, "maxCueIdx": 111},
    },
    {
        "content": " from that to directly to healthcare being transformed in the immediate future so I you know learned that if you read the New York Times regularly as I do technology is in the business section as opposed to the science section and that's kind of how technology is talked about in at least in the US and of course there is scientific reporting on it in your uh this this podcast I think is wonderful and that it goes into a lot of technical details which is really exciting but you know there's there's always the business angle when it comes to technology even when I started out in the late 80s and you know at most there were PCS well um in the late 80s and into the 90s you became one of the main researchers in search and search really defined the era that I think is probably coming to a close the Google era the era of search search driving everything and so you know you you did really see the business side of your research explode and change the world are we in a moment like that now well I would wouldn't mind talking about search for a few minutes since it is close to my heart I mean I was interested in search because I wanted to be able to find things uh I didn't like the library catalog when I was a little kid and in fact when I was an intern I tried to be an intern in my public library in high school and I was rejected because I wasn't fast enough with filing alphabetically in the card catalog but I but I never thought that makes sense made sense so actually I always",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 105, "maxCueIdx": 144},
    },
    {
        "content": " a little kid and in fact when I was an intern I tried to be an intern in my public library in high school and I was rejected because I wasn't fast enough with filing alphabetically in the card catalog but I but I never thought that makes sense made sense so actually I always wanted to do a dynamic smart version of the card catalog which is what I did in search user interfaces and and kind of fighting the there's only one spot in the bookshelf for the book representation and so I'd say I what I focused on was search user interfaces I wouldn't say I was the leading person in search but I was a leader in search user interfaces which was a kind of a hybrid Topic at the time because most of the search field was more on algorithms and not so much on the user interface so I brought those two together and that was super exciting because the the technology or the uh kind of framework that I advocated for and and showed empirically worked it did become the standard for it's still a standard faceted interaction like what you see on a website when you're shopping or Library catalogs where you can slice and dice and filter in different ways uh to find the items that you want and that uh getting that interface to work well was a big Challenge and that was sort of the Breakthrough what was the what was the big problem with search interfaces before you got into the game well when I got into the game most search full stop I mean if you had an application you couldn't search for material within it it was it was",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 138, "maxCueIdx": 177},
    },
    {
        "content": "a big Challenge and that was sort of the Breakthrough what was the what was the big problem with search interfaces before you got into the game well when I got into the game most search full stop I mean if you had an application you couldn't search for material within it it was it was just rare it just didn't happen much when I got into the game Library catalogs were searched by saying you know PN uh bottoman uh comma J to to find the personal name of the author I mean it was command line and then there were uh Westlaw and these uh very expensive tools that you could subscribe to say if you were a lawyer it was all keyword based but the interface there was no thought to the interface was just a listing of the output that you got usually in chronological order and so there was just was no there there uh you know the web changed things but even with the web the initial search was you know the 10 Blue Links which has actually been really hard to improve on and I I would say it's still until now which we could get to the new moment uh you know Google's interest towards showing answers to questions but I remember talking with someone there saying that they would they were conservative initially because they didn't want to show incorrect information and I I thought that was that was the right way to go isn't that isn't that one of the big shifts it's like Once Upon a Time search the purpose of search was to find a document or find a resource but nowadays it's really you you want the answer",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 171, "maxCueIdx": 210},
    },
    {
        "content": " incorrect information and I I thought that was that was the right way to go isn't that isn't that one of the big shifts it's like Once Upon a Time search the purpose of search was to find a document or find a resource but nowadays it's really you you want the answer to a question it's almost a shift in intention actually uh to that I think I think people always wanted to ask questions but it wasn't possible to get an answer so we were just adapting to a bad system well yeah exam ask questions to get answers and it didn't work because the technology didn't work but people kept using it and always said they liked it because they liked the idea of being able to get ask a question and get an answer and do I have some old screenshots of it it just didn't work it's like someone's saying oh people like the mouse but now we have touch screens and their tastes have changed I'm like no no it's that we didn't know how to do touch screens we didn't know how to do gestures technical technologically in the early days it was a a bridge to that so often the interface we see now is the interface people always wanted but we didn't have the technology to support it and I'd say that's true for question answering now there's an exception for Scholars and people doing research who want to see the documents and primary resources but that's always been a minority yeah so that brings us to the current moment where the the machine behind your screen that's going to try and answer your questions is suddenly and I",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 204, "maxCueIdx": 243},
    },
    {
        "content": " 236 there's an exception for Scholars and people doing research who want to see the documents and primary resources but that's always been a minority yeah so that brings us to the current moment where the the machine behind your screen that's going to try and answer your questions is suddenly and I really mean suddenly able to answer it almost like a human it feels like at times I agree I think it's a sea change so I did give a I gave a keynote talk in October to the information visualization Society the IEEE society and in that talk part of what I did was talked about you know this is coming uh we are going to see instead of people developing visualizations manually it's probably going to be done with a text interface and that's a pretty radical thing to say and it was a month later that chatgpt came out and again I told the audience at that time that I've been in the NLP field for more than 25 years maybe 30 years and I've never said this is a major change and I'd say it now I was saying it right before chat GPT and it is transformational in terms of what we can do with processing language and producing language it's not transformational in everything as some of the hype says but it's we just did it just like we had a mouse and then we had a touch screen and we had keyword query or statistical ranking or we had these very complex pipelines for making natural language processing systems and now it's kind of one route you know relatively simple architecture that does ",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 237, "maxCueIdx": 276},
    },
    {
        "content": " did it just like we had a mouse and then we had a touch screen and we had keyword query or statistical ranking or we had these very complex pipelines for making natural language processing systems and now it's kind of one route you know relatively simple architecture that does everything as opposed to specific algorithms and it's kind of head spinning really well simple schematically but very complicated in terms of what might what structure might be hidden in all those billions of be hidden in all those billions of neurons in terms of what the program is doing I actually have an example that I I was just trying last night because uh in the same talk I gave an example of comparatives being very difficult to process automatically if you so if you have say a review of a camera and and someone in their regular casual languages saying oh the dlsr has a wider angle but the pixels are not as crisply retained you know what what are they saying is better than what there's a lot implied there and you know there's an implicit comparison of between kind of the overall merits of some camera and then these specific components that the pixels and so on and I use that as an example of something that it would be very hard to write an algorithm to process automatically and one of the reviewers of the paper that I wrote said yeah that was true but I just put this in Chachi PT and it worked really well so last night I put all these super complex descriptions of you know reviews of cameras in chatp and it did an ID",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 269, "maxCueIdx": 309},
    },
    {
        "content": " process automatically and one of the reviewers of the paper that I wrote said yeah that was true but I just put this in Chachi PT and it worked really well so last night I put all these super complex descriptions of you know reviews of cameras in chatp and it did an amazing job of saying what was being compared to what but I still say that it would be very hard to write an algorithm to process the language to do that it it's a general purpose tool that does that as a side effect of what else it does yeah it's sort of an all-purpose reasoning machine it's something I don't know what it is so I I watched your keynote and found it really really remarkable and um something that was gestating in my mind as I um watched you walk through all the latest uh research that you could that you could dig up on the human computer interface and also you know language and the visual component of people trying to the visual component of people trying to understand understand complex topics was that we're probably soon heading into a world where you can essentially go to a whiteboard with a model like Chachi PT so you know at work when I need to understand something really complicated or communicate something really complicated or collaborate with someone on a really complicated problem we go to the Whiteboard it's sort of the best the best environment to do this what that means is you have all the affordances of means is you have all the affordances of language ID:",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 303, "maxCueIdx": 344},
    },
    {
        "content": " or communicate something really complicated or collaborate with someone on a really complicated problem we go to the Whiteboard it's sort of the best the best environment to do this what that means is you have all the affordances of means is you have all the affordances of language language you know just speaking one-on-one and you also have this whiteboard next to you that you can diagram things correct things Point things out visually and so it's sort of Maximum bandwidth and it feels like the most comfortable way to navigate really complicated way to navigate really complicated things things I think that we've clearly gone way down the road of the chat side of this the language side of this you can interact with Chachi PT and talk about really complicated things maybe even solve problems together but there isn't yet that whiteboard but I think it's coming we saw a hint of it with the demonstration video of gpt4 so it's it seems safe to say that we're headed towards AI whiteboards and you have been grappling with the nuts and bolts of how you communicate both visually and with language and how the two play off each other sometimes uh synergistically I'd love to pick your brand just on what it's going to mean heading into a world of AI whiteboards and of course it goes Way Beyond whiteboards I could show you arbitrary images videos it generates things it finds from the internet and actually you know points things out and illustrates it yeah yeah I think that there's ID:",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 338, "maxCueIdx": 379},
    },
    {
        "content": "'s going to mean heading into a world of AI whiteboards and of course it goes Way Beyond whiteboards I could show you arbitrary images videos it generates things it finds from the internet and actually you know points things out and illustrates it yeah yeah I think that there's there's or these tools these large language model based tools to be collaborators in thinking I think that's what you mean by the whiteboards Yeah but you know I I did um after I'd done my keynote I did actually ask up to chat topt too make an outline of a talk on the subject that I had selected and it was not very creative it said things that made sense but it would have been I guess somebody who kind of knew the field but was not innovating was not seeing the future and and so I don't know that it's capable of doing that yet I listened to the interview with Sergey uh uh and he uh here at Berkeley Sergey Levin on uh reinforcement learning and he kind of pointed out that it's not using technology to kind of do future sequencing and so but but they're working on it I guess or they might work on it so we can see that no doubt the human is going to have to do most of the intellectual heavy lifting in the intellectual heavy lifting in the beginning beginning but I mean what is it gonna what is it gonna mean for information sharing and explaining when we can use something as powerful as chat gbt in the language regime also in the visual regime yes so and referring back to that keynote a bit ID: ",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 373, "maxCueIdx": 411},
    },
    {
        "content": " in the beginning beginning but I mean what is it gonna what is it gonna mean for information sharing and explaining when we can use something as powerful as chat gbt in the language regime also in the visual regime yes so and referring back to that keynote a bit that the topic is the intersection of language and visualization because the information visualization Community focuses you know reasonably on how to visualize data how to visualize information and there's been less of a focus of how those language of text overlay on that or interact with that but and I mentioned this in our earlier conversation with John that for many semesters or many years I was teaching natural language processing in the fall and information visualization in the spring and thinking about what sort of information can be represented in each modality and you know can you convert one to the other directly and I think the answer is no they they show or they explain different things visuals explain different things then text and if you think about the movie versus the book you know that's like the best example there are some books written to be made into movies you think about the Harry Potter series for example and they're very true to the original I think but there's a lot that don't trans for so well and a lot of it is about interiority and and mood and things like that that mood is expressed differently with words than with images and they complement each other of course which is why the soundtrack is so important for the film uh but we don't use you",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 405, "maxCueIdx": 446},
    },
    {
        "content": ": 439 well and a lot of it is about interiority and and mood and things like that that mood is expressed differently with words than with images and they complement each other of course which is why the soundtrack is so important for the film uh but we don't use you know when you become a grown-up you don't have pictures in your novels anymore right so except except you pointed out in your keynote that really lovely classic book by Scott McLeod on how comic books work and you really you you pointed out that there's a there's a there's a method to it there's a kind of balance between the visual and the language and sometimes one can do most of the work and sometimes the other couldn't a model learn to do that well I could have model learned to do that I mean I think you I'm interested in how best to express information so that you promote understanding and you don't promote misinformation or you try to combat misinformation and so I think it's really important that we understand how and this is the human computer interaction the HCI side of the AI HCI coin as I think about them understanding how people understand things so that we know what to tell the computers to do and you know right now we have people designing visualizations and they don't necessarily know how to put the language on the design and neither will probably the computer or if the computer does know we at least need to know how to assess if it did a good job or not which I think we",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 440, "maxCueIdx": 480},
    },
    {
        "content": " right now we have people designing visualizations and they don't necessarily know how to put the language on the design and neither will probably the computer or if the computer does know we at least need to know how to assess if it did a good job or not which I think we need to do more work on yeah but just to just to go out one step out onto the limb I know you're very wary of speculation but this one feels like a safe speculation I think that there are going to be emergent capabilities with multimodal models that can deal both with the visual and the language side and we don't know exactly what they'll be but if we follow the trend with gpt3 on solely on the language side I I wonder what kind of capabilities even are there to acquire on the visual side something that comes to my mind is um you know simplifying something um you know simplifying something visually visually sometimes as simple as underlining something can make something Salient that helps explain the whole you have a project called scholarify um with Andrew head at Berkeley is he a student of yours he was a student at a postdoc and now he's a professor at UPenn and it was awesome yeah it was a collaboration with people at ai2 you know hence the Oren reference too yeah yeah I saw this I saw a breakdown of the project it's so neat and one of the really neat insights is when you read something that's got a lot of complicated mathematics in it um your brain is doing a ton of work",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 474, "maxCueIdx": 513},
    },
    {
        "content": " ai2 you know hence the Oren reference too yeah yeah I saw this I saw a breakdown of the project it's so neat and one of the really neat insights is when you read something that's got a lot of complicated mathematics in it um your brain is doing a ton of work behind the scenes and if you had a better interface for example click on a variable in a formula and just have it automatically pop out and say this is what that represents so you offload some of that cognitive work you have to do I wonder if those kind of skills could be learned yeah I hope so and you mean the skills of visually showing the information yeah yeah all those tricks that a good visual explainer just knows effective we worked on you know algorithms to do it automatically that PDFs are really tricky to process if you're looking at the Image level and it's very hard to find definitions within a scientific paper because not everything is defined in a crisp way and so really what you want to do is is generate uh your own text but you want it to be accurate that's based on the text of the paper uh so and so we are actually looking to see if the latest models can help with the automation of that task but talking a little going back to a point you made earlier about creativity or new new synthesis with these models uh I think the one of your earlier someone who was hosted earlier on this uh podcasts put it out just even the avocado sofa is a Synergy of image I mean the a human had to ask the query ID",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 507, "maxCueIdx": 546},
    },
    {
        "content": " 540 back to a point you made earlier about creativity or new new synthesis with these models uh I think the one of your earlier someone who was hosted earlier on this uh podcasts put it out just even the avocado sofa is a Synergy of image I mean the a human had to ask the query but then thus the system was able to you know is able to blend these images together into something new although it doesn't blend well if they don't go well together yeah yeah in case anyone listening doesn't know what the avocado uh chair is uh this this was the sort of amazing Dolly moment so the dolly model came with a paper and in that paper they had some images as examples of what it could do and one of them was make a a chair made of an avocado something like that and it was sort of amazingly convincingly good it really was they are a little cherry-picked because if you try to combine two things that don't often go well together or don't appear together it doesn't work or at least it didn't work when I was playing playing with it work when I was playing playing with it yeah yeah yeah it'll flub it it'll flub it co-pilot these these systems that Aid in programming rather than there's been a long debate in HCI about should you develop when you're developing say a user interface or doing data analysis should it be a command line or should it be a graphical user interface a GUI and of course the answer is neither works perfectly and people who are pr",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 541, "maxCueIdx": 580},
    },
    {
        "content": " a long debate in HCI about should you develop when you're developing say a user interface or doing data analysis should it be a command line or should it be a graphical user interface a GUI and of course the answer is neither works perfectly and people who are practitioners use a blend of both but it seems now you know as I said about ashgs what people really want to do is just use language to say do this do that and have the program get written and then tweet and then point and use gestures in the interface to tweak it a bit this multimodality and again there are tools to do that but they're just are tools to do that but they're just not not perfect and the more that the algorithms approve like with Chachi PT the more effectively will be able to help people uh design visualizations where they don't have to do a lot of coding but it's still um there it's again because it works you know this this general purpose tool that we were talking about as a side effect of being you know produce the next word it's able to do all these other things and I think we don't understand why but that includes writing code or you know being smart about adding things into code and so on it wasn't designed for that but it seems like it will be very effective at making it easier to design visualizations the problem is will it design good visualizations and you know that's where we still have the human component well I think you know the safe the safe way to use",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 573, "maxCueIdx": 613},
    },
    {
        "content": "606 it wasn't designed for that but it seems like it will be very effective at making it easier to design visualizations the problem is will it design good visualizations and you know that's where we still have the human component well I think you know the safe the safe way to use these things is to generate first drafts and iterate but that you have to be the human editor who makes the final be the human editor who makes the final call call and do the driving yeah I agree yeah and scientists you know the work that we all do in the viz field can help determine what makes a good design help give guidelines so we we write we do research Empirical research and then we produce guidelines for practitioners to follow guidelines for practitioners to follow so so bringing this all back to this moment um you know you're a natural language processing practitioner you've spent years trying to teach machines to do useful things with language and here we are suddenly in a moment where I don't know about you but I feel like wow a lot of the things we solved you don't have to worry about it anymore just sort of more and more and more of all that hard algorithmic hand-rolled feature engineering world is getting eaten up by large language models that can simply models that can simply speak speak and they seem to have cognitive abilities that you know we would never have dreamed would be in a machine I'm not going there with you on the what should we call them what should we ID",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 607, "maxCueIdx": 648},
    },
    {
        "content": " 640 models that can simply models that can simply speak speak and they seem to have cognitive abilities that you know we would never have dreamed would be in a machine I'm not going there with you on the what should we call them what should we call them behaviors uh you know terminology I guess I don't have my favorite word for it yet capabilities uh you know it can it's it works a lot better than it used to work there's a lot of people looking into you know why does it work but you know each time people start to make some progress on that then a new model comes out that's even harder to understand because the scale is so much larger and we're not good at thinking at very large scale so I don't I think it's going to take years before we understand what's going on I don't think it's cognition I'm very skeptical about that it's really I mean yeah you know we get into philosophy and the Chinese room which uh that's that old uh John Searle thought experiment uh I mean it's unfortunate I guess the use of Chinese in that particular example but the idea being if if you replace each piece of your brain with a little like component Electronic Component and you eventually replace every piece is it still a brain you know are you still thinking yes these philosophy thought experiments so you you might want to say oh all this this model that basically just a bunch of numbers a bunch of Weights that have been trained is thinking because you can say that about the brain",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 641, "maxCueIdx": 681},
    },
    {
        "content": " still a brain you know are you still thinking yes these philosophy thought experiments so you you might want to say oh all this this model that basically just a bunch of numbers a bunch of Weights that have been trained is thinking because you can say that about the brain but you know I I'm not convinced I think there's a lot more going on in the brain that's than is going on in these models but they are very they're very good at mimicking you know at producing language and because language is distinctly human uh it feels you know to a lot of people like like it's human but you know when people are driving in their cars they name their car even old cars that had no electronic components they would name their cars they would anthropo 45s their cars they feel a part of their cars this is what we do with technology people are going to get used to it and then it's going to become old news uh and so and I think it's great that we don't have to write all these you know tokenizers and you know that's the pipeline the lp pipeline did at work it was a mess and there's always new problems and new questions to investigate from a research perspective researchers will not be out of business but you know of course it does raise even more societal issues and dangers and uh you know because of the ability to fake information to spread misinformation and for people to not know what's real and what's true so we're living through a very chaotic moment right now and I think we",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 674, "maxCueIdx": 713},
    },
    {
        "content": " does raise even more societal issues and dangers and uh you know because of the ability to fake information to spread misinformation and for people to not know what's real and what's true so we're living through a very chaotic moment right now and I think we're going to look back 10 years from now and we'll go wow that was a chaotic time and technology that was a chaotic time in politically and hopefully be able to look back and say thank goodness we made it through okay I'm optimistic we will well the the curve you're describing is pretty smooth um you know it implies that there's going to be another side to this but if things keep exponentially changing then they're not there won't necessarily be that moment because it'll it'll always feel like it does right now well the technology that this breakthrough with these models and really with training on huge amounts of compute huge amounts of data I think it can only go so far right we don't know the limits of it but it's not going to be everything uh you know if you look at people that are trying to study the brain you know it just there's other things going on there different kinds of structure and so on you think you think we're running out of data no no I don't think that's it I think that the the think that's it I think that the the technique technique that alone I don't think is going to be sufficient for mimicking you know for being the same as humans I",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 706, "maxCueIdx": 747},
    },
    {
        "content": " 740 we're running out of data no no I don't think that's it I think that the the think that's it I think that the the technique technique that alone I don't think is going to be sufficient for mimicking you know for being the same as humans I don't say we could ever do it but some people do argue that um sequence prediction which is essentially what is driving this whole craze might be all you need what do you think about that well it's it's we're seeing that now it's it's really quite amazing I mean there's I mean you there is sometimes fine-tuning on the other side but you know again that's who knows I think that I I personally have been wrong about this particular technology I think like a lot of people I just didn't know how to think in terms of billions of parameters and and we're just not good at that and you know there were some very ambitious people that just sort of went for it and surprised all of us and I admitted I I admitted I did not see this coming and I was surprised by it and you know we we have certainly in the research Community it's been developing gradually so where did that came along so going back even farther again when I was doing you know early early in the statistical NLP time uh people were looking at SVD singer singular value decomposition and LSA latent semantic analysis which is similar in a lot of ways it was putting words in a matrix and you know oh well words by document matrices and trying to ID:",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 741, "maxCueIdx": 779},
    },
    {
        "content": " doing you know early early in the statistical NLP time uh people were looking at SVD singer singular value decomposition and LSA latent semantic analysis which is similar in a lot of ways it was putting words in a matrix and you know oh well words by document matrices and trying to find similarities even before that you know I was trying to solve the the thesaurus or the synonym problem to help with search so it search you you know you look for cat and it's really feline and you don't find anything and this was the going back to the beginning of our conversation and they want users to have to put in every synonym imaginable for a cat just to find text about cats well Library catalogs had had synonyms in the early days they weren't that good and we weren't dynamic they didn't handle new technology and they were hard to use so wordnet came along and you know developed as a linguistic tool and I was the first person to download it actually when they had an ft FTP available uh did work on that uh as and it was like oh we can have a thesaurus but you know it never worked you either whenever you had automatically recommended terms for a term some of them were right and some were wrong and that was true of SVD and LSA as well they worked in some cases they didn't work in other cases and it wasn't until word Tibet came along and then people actually then refined it to have different senses that it actually started to work and so I was saying wow this actually works and I've seen 20 years of this not working and",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 773, "maxCueIdx": 811},
    },
    {
        "content": " in some cases they didn't work in other cases and it wasn't until word Tibet came along and then people actually then refined it to have different senses that it actually started to work and so I was saying wow this actually works and I've seen 20 years of this not working and of course that kept you know being refined and being made more sophisticated you know with the Transformers came along and now the really large things so in the research Community it's been happening gradually there were a lot of debates about you know counting versus probabilities and all this uh so it's not out of the blue but I do again I admit that in this last year between you know the the combination of the image plus text generation and these language models where the input could be text we never thought the Epic could be text and then the output would be all these things right we thought we had to program things so that and I don't think the people who developed these models expected that either it was I believe it was a surprise to them so it is different now I don't think everything's solved I don't think it's I don't think it's you know AGI but the tools are much more effective than they used to be well like you said it's all about capabilities and it turns out if you teach a very big neural network how to predict the next word on a huge amount of internet text all these really neat emergent capabilities come into your hands couldn't have been predicted in fact no one really thought it would work as well ",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 805, "maxCueIdx": 844},
    },
    {
        "content": "837 about capabilities and it turns out if you teach a very big neural network how to predict the next word on a huge amount of internet text all these really neat emergent capabilities come into your hands couldn't have been predicted in fact no one really thought it would work as well as it does I'm sure but it does I wonder what happens when you teach a model to predict the next image in every YouTube video what capabilities emerge yeah it's going to capabilities emerge yeah it's going to be going to these already work on I feel like generating generating videos is kind of like that unicorn story moment so remember in the early days of GPT 3 where they were trying to show how great it was they said look it can it can you can start a the first sentence of a story about something that it definitely has never seen it was something about unicorns and it could just write a story and it's coherent and you know it's a story well I think there will be that video moment where you start with uh an image and it and you just say hey finish this make make this a one minute video from this scene and that'll happen but just like with gpt3 the thing that's going to blow us away are the things we can't predict it'll be able to do it's going to have capabilities that just emerge yeah well I have to admit that I was not at all impressed by the Unicorn story and in fact that's why I was skeptical I was like this is clearly cherry-picked and ",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 838, "maxCueIdx": 877},
    },
    {
        "content": "are the things we can't predict it'll be able to do it's going to have capabilities that just emerge yeah well I have to admit that I was not at all impressed by the Unicorn story and in fact that's why I was skeptical I was like this is clearly cherry-picked and it's like you know from a fairy tale and you put anything else in also not so useful it's just not useful generating what do you do you do LLP right there's different kinds of tasks and some tasks are easier to evaluate than others like information extraction did you identify the right you know that a company is an organization or or is it a rock band or whatever but if you are doing search it's very hard to know if you have the best ranking in a lot of cases or if you're doing summarization there are many legitimate ways to summarize a paper and so it's really hard to evaluate summarization and if you're generating a story you could generate almost anything and it's a story so this is why I was not at all impressed by the Unicorn example uh but you know it turned out that actually there was more behind it than the Cherry Picked example although gpt3 I wasn't impressed with gpd3 myself until the instruct GPT version came out and this and the thing actually did your bidding yeah well they until then yeah they really improved on it and so I think that's coming the problem is that the problem is initially they were hyping it in ways that weren't how that now they're being more careful I ID: ",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 872, "maxCueIdx": 910},
    },
    {
        "content": ": 903 actually did your bidding yeah well they until then yeah they really improved on it and so I think that's coming the problem is that the problem is initially they were hyping it in ways that weren't how that now they're being more careful I mean open AI so or maybe they did have more behind the scenes they kind of said oh well we know stuff that you don't know and we can't share it so you know to me that's whatever so uh you want to see you want everyone to be able to test things you know that's you know what happened with uh uh Thera what's the um the fake blood testing company and all that where where they wouldn't let anyone test their you know I it was clear from the beginning it was fraud so you know you have to if you're going to make big claims you need to be able to show your cards show your cards yep yep all right so zooming out a bit what do you think is uh going to be the most exciting things to pay attention to on the research side of your Fields you really have more than one field um but I'd love to just hear you thought what's what's in your mind these days uh given this kind of big sea change as you describe it which I agree but there's a lot of people doing a lot of stuff there's a lot of people really interested in AI safety and uh AI anti-bias all very important I think there's also a lot of people looking at the AI human interface which is",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 904, "maxCueIdx": 943},
    },
    {
        "content": " sea change as you describe it which I agree but there's a lot of people doing a lot of stuff there's a lot of people really interested in AI safety and uh AI anti-bias all very important I think there's also a lot of people looking at the AI human interface which is something I've been interested for a long time and that's super important uh people doing driving car self-driving cars have a bit of a head start mainly on seeing how hard the problem is uh actually I had a PhD student at Cecilia Aragon who looked at projecting lidar visualizations for helicopter pilots on the screen and how could we make that work and have them not crash because this could show them if say a Squall was ahead and they might potentially crash if they went into it and we found that the simplest most Bare Bones interface was the very best so that they weren't distracted so I've always had questions about self-driving cars and that you know the problem of the the attention of the driver and it that's really not solved and the studies I have seen on automatically generated language in interfaces even some we've done the scholar fight semantic scholar project uh semantic reader project we don't have good answers for that people just start to rely on the automatically generated output it's natural and so that's a huge problem that needs to be solved I think that's a big one what are some of the ways that we could help people if if everyone comes to rely on chat t for day-to-day work what are some of the levers we",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 937, "maxCueIdx": 976},
    },
    {
        "content": " automatically generated output it's natural and so that's a huge problem that needs to be solved I think that's a big one what are some of the ways that we could help people if if everyone comes to rely on chat t for day-to-day work what are some of the levers we can pull to help them I mean I I haven't solved this problem so I I mean I mean certainly good user interface design understanding people so HCI shows us how to study people and how they work and how they work with technology so using HCI methods to deeply study that and in different contexts it's different in a medical setting there's a colleague that uh Nila Faris salehi here at the high school at Berkeley who is looking at machine translation in a medical setting and when information does not translated correctly and how that can adversely impact marginalized communities when the translation isn't really the right thing and how to get the context right so each I think each setting is probably going to need some specialized research and you know furthermore you know what are your podcast is about how do people inject you know poison the um the training data and so on and so you're gonna have to be very careful about attacks like that it's not a field that I'm in uh you know obviously that's that's important uh perhaps it'll be important to have diversification in the different models so that there's ways to check them make sure that they are safe and appropriate for a particular use uh and uh but I",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 970, "maxCueIdx": 1009},
    },
    {
        "content": " I'm in uh you know obviously that's that's important uh perhaps it'll be important to have diversification in the different models so that there's ways to check them make sure that they are safe and appropriate for a particular use uh and uh but I think that the techniques of HCI and ethnography really work independent of the context it's not AI you know people in AI don't necessarily want to sit down with people humans and see their their details and what they do and and so on but that's the only way to have really working systems that are good for society yeah I've noticed that there there's this there's this kind of mindset of people who build AI generally people who build AI systems it's it's the engineering mindset sort of uh the more you can take the person out of the equation the better because you know I want my development environment to be nice and clean and straightforward and I want to build something that I understand and as soon as you get people involved people are complicated but what you're saying is you have to you have to include the person yeah and that's why I'm heartened by the new interest in NLP plus HCI I've given you know there's been workshops I've asked because I've been thinking about time but it's true that a lot of people who are making the biggest advances in the NLP AI field are mathematicians our physicists and it's just not what they think",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 1003, "maxCueIdx": 1039},
    },
    {
        "content": " know there's been workshops I've asked because I've been thinking about time but it's true that a lot of people who are making the biggest advances in the NLP AI field are mathematicians our physicists and it's just not what they think about they like to think in an abstract way and and they're brilliant and they're really improving these these systems but you know everybody you meet we need teams to work on technology no one for you know this the one-person band just you know doesn't exist in this space so what would you say to uh students coming into these fields uh just just now what what are what are the most you know has the advice changed at most you know has the advice changed at all I say to all students is what are you passionate about what really interests you do that don't do the trendiest thing for its own sake uh you know it's it's definitely a big question mark right now for research universities and AI labs and other research groups you know if there's a big microscope that some people have and you don't you know how do you compete and uh you know there's open source efforts you know things that a hugging face and others are doing I think the government's just the US government's interested as well and giving everybody a microscope meaning these large language models and the ability to to run them and I think that you know people are very aware of that issue",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 1033, "maxCueIdx": 1070},
    },
    {
        "content": " hugging face and others are doing I think the government's just the US government's interested as well and giving everybody a microscope meaning these large language models and the ability to to run them and I think that you know people are very aware of that issue but then if you want to do Advanced research on this you know you get brilliant people like agent Choi at University of Washington and ai2 that are showing that you can do a lot with much less you don't need to have these all these parameters and so on and that's where the university can help the university people are also going to be looking at how do you save energy well I mean so is industry but how do you save energy when you use these it's very wasteful right now so you know these are all great areas for research and of course understanding what these models are doing understanding the Mind better can they help us understand the mind in some way I'm sure psychologists are thinking about that and you know this there's work already I've seen work in linguistics on say using Gans and adversarial methods to study uh to model Linguistics in you know other species so there's always more research questions and but you shouldn't you know if you're interested in being in industry and business then go do that and if you're interested in a research then then find a problem that just really interests you because that's how you can finish your PhD and just to just",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 1064, "maxCueIdx": 1100},
    },
    {
        "content": ": 1094 and but you shouldn't you know if you're interested in being in industry and business then go do that and if you're interested in a research then then find a problem that just really interests you because that's how you can finish your PhD and just to just to bring it to a close what what's coming up in your life uh that listeners might be interested to to know about is there a project or or a um an event on the horizon well I think the project that I'm most excited about is working with my PhD student Chase Stokes on understanding this interaction between language and visualization and we've we just finished a paper that we submitted on uh if you Place text on a chart and and the goal of the chart is to make a prediction how does text impact that prediction like some who's going to win an election by looking at this chart and we actually found surprisingly that the text did not influence the prediction all that much uh in this case where people relied more on the visual input but in another study we did where it was more what are you taking away information wise then the use the the way the text was used did have an influence so what we really need to do is understand this interplay more and I'm just very excited about that topic I know it's kind of a niche topic but it's what interests me oh far from Niche we're going into uh a very momentous political year and uh these these little uh ID: ",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 1095, "maxCueIdx": 1130},
    },
    {
        "content": "to do is understand this interplay more and I'm just very excited about that topic I know it's kind of a niche topic but it's what interests me oh far from Niche we're going into uh a very momentous political year and uh these these little uh interactions between a person and a piece of information can have massive massive effects and you're right we don't really understand how they work do we no I I like to work at topics where there isn't a lot of work at that time like search interfaces and so on and then when it becomes popular I tend to move on I think I I can't compete or something so I have to find a new thing that nobody's thinking about oh I might have just ruined your picnic now everyone's going to get interested in uh Marty thanks so much for talking with us",
        "metadata": {"videoId": "NdEpYO9J_e0", "minCueIdx": 1125, "maxCueIdx": 1145},
    },
    {
        "content": " llms are language models so they really Thrive at any language specific task um so imagine any sort of tasks that you are performing on a daily basis whether it's writing something talking to someone um maybe scanning through the text looking for information by reading searching for Stuff um they're like there's so many things that we do on a daily basis that involve that we do on a daily basis that involve language language uh that large language models will be able to assist us with able to assist us with um um tremendously and sort of augment the way we are currently process search systems for sure will be augmented very soon with large language models with large language models um um storytelling the way we build the story the way we um create a character with language model you can have you basically have a creative assistant that can help you brainstorm ideas for your story for your character for your setting create different iterations of setting create different iterations of it it um I can imagine in the future also stories that are sort of personalized to a user where you're able to choose how your story unfolds depending on you know who you are as a as a reader of this story and what interests you the most hello everyone welcome to another episode of 34 data Channel podcast I'm your host Deepak and with me we have Sandra kubli Sandra is a digital Creator author YouTuber and developer relations at cohere AI she's the co-author",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 0, "maxCueIdx": 43},
    },
    {
        "content": " of this story and what interests you the most hello everyone welcome to another episode of 34 data Channel podcast I'm your host Deepak and with me we have Sandra kubli Sandra is a digital Creator author YouTuber and developer relations at cohere AI she's the co-author of the book titled gpt3 The Ultimate Guide to building NLP products with openai API today we'll hear a lot about large language models and their Rising applications it's a pleasure to have you here today Sandra and thank you for accepting my invitation sweet thanks for having me very excited to be here so let's start with the uh book itself so could you talk about your book on gpt3 and how we and your experience with expressing the model's experience with expressing the model's potential compare it to running a marathon because it's like running a marathon because it's like this this intense effort over a long period of time in this case it's an intellectual effort and it's a really One of a Kind experience I loved being able to write a book and dive deeper into book and dive deeper into um um architecture of the model API design different types of use cases it tackles very well we've been doing a lot of interviews with folks that are actively using gpt3 as part of their product design uh whether in Enterprises or in startups and with so many different use cases so I've learned tons both like in terms of the sort of limitations downsides but also",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 37, "maxCueIdx": 79},
    },
    {
        "content": " tackles very well we've been doing a lot of interviews with folks that are actively using gpt3 as part of their product design uh whether in Enterprises or in startups and with so many different use cases so I've learned tons both like in terms of the sort of limitations downsides but also how much value gbt3 can actually bring to your business to your business um um and so I think especially like talking to users uh of of the model was particularly insightful and uh yeah there are also these huge ethical questions ethicals like sociological questions also around the model that are very interested interesting and that's where um a good opportunity I guess to explore in the book so we dived into that as in the book so we dived into that as well well overall um the process left me very hungry for actually seeing more and more deeply implementations in the real in the real world and I don't know why they're scared I'm really like impatient in terms of when will my Gmail actually start writing emails for me and stuff like that you know I'm just like waiting for this moment to happen um yeah and uh so so it's been it's been a blast since and it's been a huge learning experience right so how long it took actually the whole process a little bit over a year yeah and it's actually ongoing because here I am talking to you about the book and so part of it is promotion but also sort of the outcomes of it so it",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 73, "maxCueIdx": 115},
    },
    {
        "content": "and it's been a huge learning experience right so how long it took actually the whole process a little bit over a year yeah and it's actually ongoing because here I am talking to you about the book and so part of it is promotion but also sort of the outcomes of it so it's still like it still continues even after you have or isn't it and published it it's still um going on yeah great great so uh according to you like why llms are considered to be having a better natural language understanding okay so there's um there's a couple factors here factors here um um first of all the secret sauce is the architecture called Transformers which was published in 2016 sorry 17 by Google brain researchers uh actually one of the folks that published the paper attentions all you need with Transformer architecture is a CEO of here where I'm working at is a CEO of here where I'm working at Adan Adan Adan um um so Transformer was a really big breakthrough in terms of the type of language model architecture that can Thrive at I think at the time primarily translation based at the time primarily translation based tasks tasks uh but then with different types of uh but then with different types of experiments experiments um combining Transformers with you know huge data sets and huge amounts of compute uh to be able to train models it turned out that models based",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 109, "maxCueIdx": 154},
    },
    {
        "content": " tasks tasks uh but then with different types of uh but then with different types of experiments experiments um combining Transformers with you know huge data sets and huge amounts of compute uh to be able to train models it turned out that models based off of this architecture can show a very interesting uh capabilities with every iteration of GPT models so there was before gpd3 and before chat GPT there was gpt1 and gpt2 um so every time this model got bigger every time the number of parameters number of layers got bigger and every time the model showed sort of more time the model showed sort of more General General um capabilities of tackling wide variety of language-based tasks rather than specialize in only one narrow task as as it was the case up to the point of llms with language models with language models um um so I would say that these are these are important elements of it another thing is that is that um um GPT is a model that's pre-trained on a large data set and because it's pre-trained on this like large data set that has a variety of different sources it's sources it's um um pretty flexible and it's really pretty flexible and it's really um um sort of able to adapt to your use case um it was trained on most of the internet that we have today and other sources as well books and stuff but ",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 146, "maxCueIdx": 192},
    },
    {
        "content": " um pretty flexible and it's really pretty flexible and it's really um um sort of able to adapt to your use case um it was trained on most of the internet that we have today and other sources as well books and stuff but thanks to that is just very easy for the model to grasp and emulate certain communication patterns that you might need for your particular particular case so um that's another thing that you can you can take this like more General model and then very easily adapt it with fine tuning or with a bunch of examples to your particular fintech or marketing or like whatever whatever use case you may have case you may have um um so that's GPT there is also architecture architecture called birds and here the big uh sort of change came with came with um um with the introduction of embeddings um embeddings is this very powerful mechanism for numeric text representation that the model performs that allows it to Encompass a lot of the context a lot of the meaning the semantics behind a given sentence um and having these numeric representations of particular sentences that are that sort of encapsulate so much meaning you are then able to manipulate with it and sort of compare it against each other and against other types of text and have very very interesting insights that were just not possible before because we were not able possible before because we were not able to to ",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 184, "maxCueIdx": 230},
    },
    {
        "content": "much meaning you are then able to manipulate with it and sort of compare it against each other and against other types of text and have very very interesting insights that were just not possible before because we were not able possible before because we were not able to to to capture capture so much meaning in the form of numbers so much meaning in the form of numbers before before before um um yeah I think I think that sums it up for yeah I think I think that sums it up for me me me great great so uh so this is something which came to my mind actually so do you believe that large language models are being withheld by a few question I think there's a lot of sort of anxiety about keeping the models behind the closed doors um in my experience I think what happens right now on the market is like the contrary sort of market is like the contrary sort of trend trend it's not it's not true that large language models are only provided by folks that uh keep us private keep the IP private so we have huge open source Community movements and we have models like Bloom which was you know created by open source community and completely public and available to to sort of play with um opt from from meta uh and and just a number of Alternatives that are open source so if you want there there's nothing that stops you from using",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 223, "maxCueIdx": 270},
    },
    {
        "content": " like Bloom which was you know created by open source community and completely public and available to to sort of play with um opt from from meta uh and and just a number of Alternatives that are open source so if you want there there's nothing that stops you from using GPT or bird architecture and creating some sort of variation of and creating some sort of variation of it it um having said that I work with cohere which basically our mission is to build an API that allows folks to access large language models without the knowledge of how it works and why it works and how to make it happen so that it works the only thing you need to understand is how to make the API call and a little bit about the nature of models that are probabilistic in nature let's say probabilistic in nature let's say um um so actually the purpose is not to withhold the models but make it easier for people without the background in machine learning or data science any sort of you know AI background so to any sort of you know AI background so to say say say um um to be able to use them and to use the highest possible quality of them not to worry about training about retraining about hosting about maintenance because these things are super painful and you need a you need to dedicate a lot of effort in your organization if you want effort in your organization if you want to to um sort of have the",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 263, "maxCueIdx": 307},
    },
    {
        "content": " to worry about training about retraining about hosting about maintenance because these things are super painful and you need a you need to dedicate a lot of effort in your organization if you want effort in your organization if you want to to um sort of have the in-house models and not every organization wants to you and not every organization wants to you know know know um um worry over it I personally wouldn't would like wouldn't like to worry it over it and I think over it and I think um um it's it's it's just it's fair to say that it's useful to have this alternative for you don't have to um so yeah um so yeah um um I think what these providers of apis are are trying to do what we are trying to do is go here is to remove the barrier and not withhold it but like making it more and more accessible we want to see the models being used everywhere around the world in any application possible um and anyone with you know internet um and anyone with you know internet connection connection can basically now access these models with a click of a button so uh yeah I would I would just like reverse the thinking around it because because in my experience that's what's that's what it's about right right so in this contest it's a like there are a lot of popular large language models and like which one it's easy to actually work at ID: ",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 300, "maxCueIdx": 344},
    },
    {
        "content": " the thinking around it because because in my experience that's what's that's what it's about right right so in this contest it's a like there are a lot of popular large language models and like which one it's easy to actually work at well I would say that uh all of them are pretty easy to work with especially if you're using an API if you're training your own model then it really depends on the type of you know architecture that you're using and also the it all depends on your level of knowledge it all depends on what what is your end goal what kind of tasks you want this model to solve Etc but like the easiest easiest is just to use the API and you know color generative model call up embeddings model and make it do things for you out of the box of the box um um and uh yeah so so depending on your level of knowledge I would say if if you're trying to make things stupid simple and and don't want to worry over sort of training and hosting and maintaining your model API is your way to go right right so uh uh when it comes to applications or like basically the Enterprise level Solutions so in these kind of applications like there will be like not just one model or not just one variant there will be a sequence of the models actually so in this regard like do you think these llms can be used in large applications and like it definitely can be used but like what is the",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 337, "maxCueIdx": 380},
    },
    {
        "content": "so in these kind of applications like there will be like not just one model or not just one variant there will be a sequence of the models actually so in this regard like do you think these llms can be used in large applications and like it definitely can be used but like what is the feasibility actually do you anticipate like is it is it going to be a major headache to the deployment or like when it comes like let's set aside the apis so let's treat them as a bundle of models actually so in that regard like what is your take so um again it the answer is always it depends it depends on your use case on what you're trying to achieve on what kind of already existing setup you have uh what I have seen in larger scale projects is that it's usually a mix of um sort of In-House models and using an external API to be able to tap into like specific capabilities of of llms um and certainly they are doing they're performing really well at that scale performing really well at that scale um um one example of a customer that coheres working with is hyper right so this is a platform for uh creating copy of all kinds you know like an email copy or marketing copy or what like whatever copy you need whatever writing headache or challenge is ahead of you hyperite is helping you to automate it um and you know these are like Bailey there's like a massive scale of hitting the API from hyper right customers and it works very well so they they definitely can perform on that",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 374, "maxCueIdx": 414},
    },
    {
        "content": " headache or challenge is ahead of you hyperite is helping you to automate it um and you know these are like Bailey there's like a massive scale of hitting the API from hyper right customers and it works very well so they they definitely can perform on that scale there's no issue with that okay okay so uh do you think with these latest Innovations in L alums the artificial general intelligence are yeah so um I guess I guess it depends on how you define AGI because uh if AGI for you is equals human level intelligence um then I think we are getting closer and closer to it and large language models are a significant but not exhaustive step um towards it and I think you know a few few years down the road it's it's going to be our reality that we will have models that are as capable at solving like a general variety of tasks as humans which is a pretty exciting Vision exciting Vision um um but but what you can mean by AGI is also this sort of super level intelligence you know like AI that is smarter than humans potentially overtakes humans gets out of the box and starts ruling the out of the box and starts ruling the world world world um um and here in this case I think no one knows if it's ever going to happen or when it's going to happen if so uh I myself don't even try to you know make any many make any sort",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 407, "maxCueIdx": 451},
    },
    {
        "content": " box and starts ruling the world world world um um and here in this case I think no one knows if it's ever going to happen or when it's going to happen if so uh I myself don't even try to you know make any many make any sort of predictions around it but I think that generally the scientific Community the community of people that are building AI um is divided on that one great so uh over to the applications aspect of these llms so like where it will impact the most and could you talk some of the interesting use cases which you have actually witnessed right so llms are language models so they really Thrive at any language specific task um so imagine any sort of tasks that you are performing on a daily basis whether it's writing something talking to someone um maybe scanning through the text looking for information by reading searching for Stuff um they're like there are so many things that we do on a daily basis that involve that we do on a daily basis that involve language language uh that large language models will be able to assist us with able to assist us with um um tremendously and sort of augment the way we are currently process language and text in particular language and text in particular um um I think yeah as I mentioned search systems for sure will be augmented very soon with large language models soon with large language models um um storytelling the",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 444, "maxCueIdx": 489},
    },
    {
        "content": "we are currently process language and text in particular language and text in particular um um I think yeah as I mentioned search systems for sure will be augmented very soon with large language models soon with large language models um um storytelling the way we build the story the way we um create a character with language model you can have you basically have a creative assistant that can help you brainstorm ideas for your story for your character for your setting create different iterations of setting create different iterations of it it um I can imagine in the future also stories that are sort of personalized to a user where you're able to choose how your story unfolds depending on you know who you are as a as a reader of the story and what interests you the most um I think there's a lot of documentation and generally like processing of of text in organizations that will be augmented for sure that will be augmented for sure um um chat Bots chat gbt is a great example that you have you you will be able I think on a wider scale soon we have be having just like a very nice Small Talk human level conversation with your chatbots in order to fix something your chatbots in order to fix something um um because this is already possible because this is already possible um um um yeah yeah um that that's actually something that I'm using on a daily basis so this autocomplete sort of function Where You ID:",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 481, "maxCueIdx": 526},
    },
    {
        "content": " um because this is already possible because this is already possible um um um yeah yeah um that that's actually something that I'm using on a daily basis so this autocomplete sort of function Where You Are trying to write an email or response to somebody or like just like read an to somebody or like just like read an email email um and then respond to it but you don't necessarily have time for it and you want just like the gist and also you want somebody to like somebody or something create a draft create a skeleton for you so you can just maybe adapt it a little bit and and send it this is like such a such a productivity hack to have something like this helping you throughout your day um you know battling through emails particular emails or something that I'm struggling with recently so yeah that's that's my favorite example but honestly that's my favorite example but honestly um um their their list is long and it's certainly not exhaustive we are just at the beginning of this um large language model Revolution and I think we were just be seeing more and more Innovation with it so currently maybe these are the the most impactful areas but I think we will discover more and more with with years to come right right true so over to the other aspects actually so like training these kind of models is extremely complex and time time consuming often like so do you believe it is always worthwhile to train ID",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 517, "maxCueIdx": 561},
    },
    {
        "content": " 554 areas but I think we will discover more and more with with years to come right right true so over to the other aspects actually so like training these kind of models is extremely complex and time time consuming often like so do you believe it is always worthwhile to train these kind of models in every single use these kind of models in every single use case I think I think um um I guess it's like we're coming back to the question whether it makes sense for me to like train my own model since the process is so complicated it is true by the way it's like it's complex it's painful it fails so many times and you just start over four reasons that you don't understand it's it's such a it's such a difficult task to do and working at cohere I'm close to you know this process of like trying to create the best models uh the state of the art models and it's such a challenging task and so I guess you need to ask yourself um whether you have capability to do that whether it makes sense for your use case whether whether your use case and your sort of resources justify doing that or whether you want to Outsource it and have somebody like tap into somebody else's foundational model and then adapt it to your particular use case both are you know good options it really depends on what you're dealing with for example right now I can imagine that uh when you're in medical facility some sort of or Matchstick startup dealing with",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 555, "maxCueIdx": 596},
    },
    {
        "content": " 589 into somebody else's foundational model and then adapt it to your particular use case both are you know good options it really depends on what you're dealing with for example right now I can imagine that uh when you're in medical facility some sort of or Matchstick startup dealing with sensitive personal data you might just need to use a hosted model uh just because of the data protection right and and just because of the responsibility for your customers so it's really it really depends on what you're trying to do um sometimes I think having your own models is Justified at least now looking at at what the technology is at right now but I think in many cases it's just it to avoid headache of of you know having to deal with that and just focus on perfecting your product and talking to your customers and just like trying to make the best product possible yeah yeah I I completely agree to that point actually so uh another aspect which I would like to discuss so people fear AI advancements and what is your message to them yes I think uh I think it's very natural that people fear that people fear um um I think uh it's also something that happens in in general progress technological progress every time there is a big change coming because it's uh it creates this really big uncertainty around it around it um um my Approach was always to sort of embrace it and dive into it to try to ",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 590, "maxCueIdx": 633},
    },
    {
        "content": " in general progress technological progress every time there is a big change coming because it's uh it creates this really big uncertainty around it around it um um my Approach was always to sort of embrace it and dive into it to try to understand it as much as possible rather than here and that actually you know diving into the source of what makes you scared actually sort of frees you from that fear because you realize that that it's a not so easy to create um super intelligent monster that will take over the world or be not so easy to do so many uh tasks that humans are currently uh tasks that humans are currently um performing um performing and so it's it's it it's not that easy to automate everything and you know get rid of humans all together and and leave them jobless um and also I think it's it's always a dance between sort of technology and humans and even if AI starts automating the more mundane tasks in my case let's say it's writing emails like I hate sort of spending big chunk of my day going through the email communication and having to answer emails and stuff like that so um AI will certainly be it's already taking more and more of these tasks and helping us automate it and and get rid of that sort of burden and then freeze us to do more high-level creative strategic thinking um around it and I I think that's the sort of that that's how it's going to be",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 626, "maxCueIdx": 669},
    },
    {
        "content": "662 taking more and more of these tasks and helping us automate it and and get rid of that sort of burden and then freeze us to do more high-level creative strategic thinking um around it and I I think that's the sort of that that's how it's going to be but that that's how it's going to be but like like leaving that a little bit uh behind I leaving that a little bit uh behind I think think think um um yeah just like if you fear it make sure to learn as much as possible about it because you will be surprised how your sort of take will change while you're learning more about it and um how many challenges there are you know in in just developing these very smart AI systems uh it doesn't mean that there is no sort of reason for concern uh certainly there is and there are big questions that you know research labs are tattling are tattling um um and and I don't like one one great example is a bias right when when llms were released when GPD was released it turned out that it started spitting out a lot of toxic content and it then it turned out it was because there was a lot of toxic content in the data set that was trained on so a lot of like credits um Pages a lot of subreddit different forums and I don't know if you're familiar with Reddit but there's a lot of sort of very specific troll like",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 663, "maxCueIdx": 706},
    },
    {
        "content": " because there was a lot of toxic content in the data set that was trained on so a lot of like credits um Pages a lot of subreddit different forums and I don't know if you're familiar with Reddit but there's a lot of sort of very specific troll like communication there and so the model learned it and then was even amplifying it in Amplified these types of sort of toxic patterns and biases in the communication and but but this you're sort of able to see once you train it and then release it and let humans actually play with it and then once you see something it's off you need to act immediately in order to you know limit limit the harm the possible harm done possible harm done um um and uh so so there is some reason for concern but again it's it's a ongoing conversation and companies that are dealing with these powerful models are really sort of up to date in terms of the type of harm the the potential damage that they can do and they're trying to do everything they can to prevent it right right so in this particular context actually like I just want to ask so companies are sometimes afraid to adapt to full AI so what is your take on adapt to full AI so what is your take on that you already um but but that's very true like each each business is different each requires a different process and each requires a different process and um um and I don't I I I I see nothing wrong ID",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 699, "maxCueIdx": 742},
    },
    {
        "content": " adapt to full AI so what is your take on that you already um but but that's very true like each each business is different each requires a different process and each requires a different process and um um and I don't I I I I see nothing wrong with the fact that some organizations take longer to adapt to technology and just because of of their nature just because of the because of the um um just like like we mentioned the medical applications I mean you need to be like super super certain that there's absolutely no harm being done with your absolutely no harm being done with your system system to be able to use this new technology and while it's still in its sort of verb while we're still discovering the potential downsides and stuff um it takes some time so so these these organizations that are withholding from adapting I think what they're doing is that they're observing the more sort of pioneering folks startups the brave Enterprises that are tackling tackling the llms and uh and seeing what happens and and I think but but I think it will be inevitable that at some stage uh they will need to start to understand a little bit how to use this technology in their organization because other people other organizations will be using it and you will want to stay sort of on The Cutting Edge on The Cutting Edge um um so yeah I I think I think you you've got to do ",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 735, "maxCueIdx": 780},
    },
    {
        "content": "use this technology in their organization because other people other organizations will be using it and you will want to stay sort of on The Cutting Edge on The Cutting Edge um um so yeah I I think I think you you've got to do what you do for your for what's best for what you do for your for what's best for organization organization um and think about also the the business value that you can get out of it because AI can deliver this business value to you you just need to understand how to utilize it to its best um it's best advantage right right so these AI models are definitely evolving around time so what what I think it's such an interesting process to observe just like I mentioned there there were a handful of iterations of GPT before it became GPT 3 and before it became chat GPT uh and there was a lot of Hit and Miss as well in that process it was a messy messy process which is a which is a fun thing to observe which is a fun thing to observe um um um so so I think we are constantly in this process you know of the progress of elements and there will be lots of experiments with the architecture with the new types of data with the size of the models not necessarily going bigger but maybe smaller but then you know more robust and and more effective uh using less computes uh using less computes um um also",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 772, "maxCueIdx": 817},
    },
    {
        "content": " experiments with the architecture with the new types of data with the size of the models not necessarily going bigger but maybe smaller but then you know more robust and and more effective uh using less computes uh using less computes um um also a lot of human feedback is being Incorporated and reinforced in in the next iterations of these models so uh you can really tell the difference between interaction with chat GPT and gpt3 right because you you don't really need any prompts you don't need to even know what the prompt is you can just have a small top conversation with with chat GPT in order to get what you want out of it and it's a zero shot thing it's not you don't give it a handful of examples it will just be able to perform on the go um and this is thanks to the fact that you know with with the usage of gpe3 open AI got more and more data from from Human feedback from users using it and um and where a and and was able to sort of make the model more in touch with how humans communicate what they need uh what they expect and so now it's it's able to the models are able to really perform beautifully with a single sentence natural language instruction so I think it's they're just going to get better and better um and it it's it's very exciting to observe uh this trend right right this is something which came to my mind on uh how we are essentially consuming these kind of language models consuming these kind of language models",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 809, "maxCueIdx": 849},
    },
    {
        "content": " I think it's they're just going to get better and better um and it it's it's very exciting to observe uh this trend right right this is something which came to my mind on uh how we are essentially consuming these kind of language models consuming these kind of language models so so there are so many large language models which have been created nowadays and at one point at one point we have creators and at one point we have consumers and consumers are actually kind of converting these created models into different API services and with different usable services but the underlying algorithms remains unchanged actually at every single point so it's the same algorithm which is being actually translated into different services so and they are actually selling it in varied price range or has a varied uh product itself so what are your thoughts on this usage yeah I mean this is I mean this is the dream come true for that for the companies that are developing these foundational foundational models for others to use um and and also I think this is a testament to how flexible these models are that you are able to take this General model developed by coher or open AI or another um organization and then you know throw in a bunch of examples and build an icy around it package it in a nice UI and then ship it to the world and and have a very unique sort of use case where that's a lot of how these uh marketing content platforms for example that are using generative models work ID",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 843, "maxCueIdx": 885},
    },
    {
        "content": " throw in a bunch of examples and build an icy around it package it in a nice UI and then ship it to the world and and have a very unique sort of use case where that's a lot of how these uh marketing content platforms for example that are using generative models work um and uh yeah I think it's phenomenal phenomenal that that they're doing it and that they're using it to build new businesses because that's how we are able to make use of it and you know provide business value provide provide practical value for people uh for using these models models are being developed for others to use them so it's it's a really good Trend and I hope there will be more and more organizations that will think of basing organizations that will think of basing their their uh offering off of llms coming from another organization right right so uh towards uh ethics and responsible side of all these language models so like when gpd3 was released there have been a lot of questions regarding the uh ethical consideration or like the bias which is being shown and over the period of time we could see that there are some efforts or like significant efforts made to actually ghost correct these kind of issues by like maybe by actually introducing some more human involvement to kind of uh speculate okay this is kind of like bias or like and most most importantly like there have been some good efforts like from Allen AI in the in like they have a model called ask Delphi so which which clearly",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 879, "maxCueIdx": 920},
    },
    {
        "content": "913 like maybe by actually introducing some more human involvement to kind of uh speculate okay this is kind of like bias or like and most most importantly like there have been some good efforts like from Allen AI in the in like they have a model called ask Delphi so which which clearly speculates okay this is more like a wise content or something like that but in charge video also like we could see like I'm not saying it's completely remote but like there are some good efforts which is being carried out so like do you believe like it is really what to say it's it's really taken into consideration while training this kind of large language models yes yes I know it for a fact because I work as an organization who does take it super seriously um it's a very important topic for all the sort of leading apis cohere open AI uh a20 21 lats uh and others actually those three a couple of months back released a shirt statement and sort of guidelines shared guidelines three companies would like you know different business models Etc they came together and they were like okay so this is this new industry and new technology and it's very important for the newcomers new upcoming apis and models and services that will be that will follow services that will be that will follow to to sort of go like to to really take the responsibility for these models seriously and to take the ethical concerns seriously and make sure that your data set is as clean as possible in terms of the bias in terms of toxicity ID: ",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 914, "maxCueIdx": 954},
    },
    {
        "content": " will follow to to sort of go like to to really take the responsibility for these models seriously and to take the ethical concerns seriously and make sure that your data set is as clean as possible in terms of the bias in terms of toxicity um but there is a good representation in that data set that you block that data set that you block um um the use of your API for any sort of harmful misguided purposes so I don't know spreading misinformation or um promoting hateful speech or whatever whatever it is you know language is such a powerful uh powerful tool in itself that we are using as humans and so if you have a language model you have this again another tool on top of it that augments many of these things that we're already able to do with language and there are so many like bad things you can do with language as well and can do with language as well and um um as I mentioned the organizations that are providing a lens are taking it very seriously and are um really sort of strict in terms of strict in terms of um um what kind of world they want to see with the with the API being created versus what kind of world they do not want to see being created and uh and yeah they're very open about it very very public about it as well um and I'm really happy that um there is such a consideration already at the beginning of of sort of this",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 947, "maxCueIdx": 991},
    },
    {
        "content": "the with the API being created versus what kind of world they do not want to see being created and uh and yeah they're very open about it very very public about it as well um and I'm really happy that um there is such a consideration already at the beginning of of sort of this technological Revolution technological Revolution um um so yeah I I think uh this is this is one thing that's like super positive I mean there are many positive things but uh this one thing in particular in in the context of possible implications of this technology implications of this technology um um that uh the companies are are very serious about just minimizing the harmful harmful effects of potential harmful effects and uses of it right right so yeah so as my last question actually so what are your future aspirations in this particular Rising field and how you are actually looking at this all of this developments um so I love to explore different use cases and I'm really interested in just working on wider um market adoption of Lance um market adoption of Lance um um I'm I I made this progression even talking talking on my YouTube channel from like looking at cool demos to looking at cool products and now these products many of them are you know raising millions of dollars of financing and like there's even one unicorn Jasper um that's based off of large language",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 985, "maxCueIdx": 1027},
    },
    {
        "content": " talking talking on my YouTube channel from like looking at cool demos to looking at cool products and now these products many of them are you know raising millions of dollars of financing and like there's even one unicorn Jasper um that's based off of large language model so it's an actual industry it's an actual business and not only startups are tapping into it but more and more uh mature organizations are playing with it experimenting with it and seeing how they can use it and so and seeing how they can use it and so um um my focus is to support this effort to to adopt large language models and to also continue learning about them because they they continue to change you know they're as I mentioned iterations in terms of the beta or architecture being used in terms of the human feedback as well so um I'm both learning and sort of trying to create helping to create this robust industry and uh yeah outside this is what I'm focusing on right now great great so that got all my questions and and thank you so much Sandra for sharing your experiences and working in this awesome field actually particularly in this large language models and shredding light on how things are actually progressing over period of time and once again congratulations on your new book and I wish you all the best Sandra awesome thanks for having me it's",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 1021, "maxCueIdx": 1057},
    },
    {
        "content": "1053 shredding light on how things are actually progressing over period of time and once again congratulations on your new book and I wish you all the best Sandra awesome thanks for having me it's",
        "metadata": {"videoId": "Ixk7CTyyrk0", "minCueIdx": 1054, "maxCueIdx": 1057},
    },
    {
        "content": " you had been developing these natural language models that were capable of interacting with human players so convincingly that the algorithm is able to convince them to be involved in teaming up against other countries so the project started about three and a half years ago what is the hardest board game that we could possibly do and landed on diplomacy the trick is regularized towards human behavior and then we just turned up the regularization parameter and the planning and then basically from there it was very very good like close to it was very very good like close to perfect Alex welcome to the super data science podcast awesome to have you here live with me in New York thank you for making the Trek downtown although I guess not far from that is office well and I'm just 15 minutes up in the West Village so it's easy um and we've got a really exciting episode today I've wanted to film an episode with you for a long time we were scheduled to do an episode in Spring of 2022 a year ago and you got kovid right before it did so there's this episode that came out with Nolan Brown Episode number 569 where we're live on stage at ml conf in New York and because we were really down to the wire on whether your covid would go away enough because it was like days before we were waiting to get like a negative test back and very last minute gnome uh stepped up was able to do it it's an amazing episode and luckily he has expertise that is ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 0, "maxCueIdx": 42},
    },
    {
        "content": " 35 really down to the wire on whether your covid would go away enough because it was like days before we were waiting to get like a negative test back and very last minute gnome uh stepped up was able to do it it's an amazing episode and luckily he has expertise that is quite different from yours so we were able to dig deep into different topics than we will today but it was really funny filming it live because we'd uh paid to have this video made that was in a loop um alongside the stage for all the audience members there and so I had your face and name and title huge beside me um but Alex Holden Miller I didn't get your name and face for my apartment here on some big screens but we'll still we'll make it work I guess I could have um so we know each other socially we met at a brunch actually in New York um I guess a little more than a year ago and it seemed like a great idea right off the bat to have a podcast episode with you because we got talking about what you're doing at meta and it's so what you're doing at meta and it's so fascinating fascinating and we're actually the timing now is even better because a year ago when we were chatting a lot of what you could have disclosed about what you're working at at meta would have been under wraps because it was it hadn't been published yet but now it's been published to great yet but now it's been published to great success success super exciting and congratulations so your team recently",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 36, "maxCueIdx": 76},
    },
    {
        "content": " could have disclosed about what you're working at at meta would have been under wraps because it was it hadn't been published yet but now it's been published to great yet but now it's been published to great success success super exciting and congratulations so your team recently published a model called Cicero which could play the board game diplomacy describe the game of diplomacy I hadn't candidly heard of it before we met at that brunch a year ago but it's clearly a very popular game around the world um to me it's sounded a lot like Risk when I first heard of it yeah so I actually hadn't heard of it before this team started either um so diplomacy we kind of like to say it's it's a combination between risk where you have a map in this case of where you have a map in this case of Europe Europe um there's different territories that have either fleets or armies in them and your goal is to take over more territory um but then also maybe some combination of Poker as well because there is this aspect where um people are all kind of doing things at the same time there's hidden information you don't really know what's going to happen in the future um unlike risk where it's just turned based like you each do your move and you can see exactly what the board say it is at all times apart from you know you're like bonus cards um and Survivor uh where there's this aspect of like diplomacy and negotiation and even the times backstabbing that um you",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 69, "maxCueIdx": 110},
    },
    {
        "content": ": 103 based like you each do your move and you can see exactly what the board say it is at all times apart from you know you're like bonus cards um and Survivor uh where there's this aspect of like diplomacy and negotiation and even the times backstabbing that um you kind of have to deal with at the same time as the rest of the board um and so the project started about three and a half years ago um when uh gnome and some others um who you had on the podcast before um were gnome had just been working on poker before uh which you can hear a lot about it's definitely very interesting and it's kind of looking to say like from poker where do we go now um and Ken said what is the hardest board game that we could possibly do um and landed on diplomacy um for a variety of reasons uh that we can talk about but can talk about but um um basically each of these different aspects of like risk of of Poker of Survivor uh different elements of challenge to AI um and so decided like okay you know this is something that could take 10 years to solve like let's get working on it like get cracking and and solve this problem and uh fortunately it didn't take time yeah that's wild but just three years and even a year ago you weren't sure at least you can tell me like how well it seemed to be going um and yeah it is an immensely hard game because of how you have all of this natural language dialogue happening so ID: ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 104, "maxCueIdx": 144},
    },
    {
        "content": " take time yeah that's wild but just three years and even a year ago you weren't sure at least you can tell me like how well it seemed to be going um and yeah it is an immensely hard game because of how you have all of this natural language dialogue happening so we just in the last couple of months has been a lot of popular press obviously about algorithms like chat GPT that are capable of carrying on a compelling conversation but that is brand new and that's around the same time that your paper came out so you'd have you had been developing these um these natural language models that were capable of interacting with human players so convincingly that the algorithm is able to uh convince them to to be involved in teaming up against other countries um uh and it has to be able to think very far ahead so unlike something like chat GPT which is just using past bits of the conversation and information within its uh parameter weights from all the information that it's tuned on in this case with your model with Cicero there's this in my view much more complex aspect where it needs to be able to be planning ahead and thinking about how it can strategize with natural language with all these other human players and win the game which also um I I remember when we were talking a year ago you were at that time it seemed like mostly focused on a version of the game that did not have the natural language aspects yeah so I I think everything you described is definitely the hardest part ID",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 138, "maxCueIdx": 179},
    },
    {
        "content": " win the game which also um I I remember when we were talking a year ago you were at that time it seemed like mostly focused on a version of the game that did not have the natural language aspects yeah so I I think everything you described is definitely the hardest part like the the language that interacting with other people like this is the hardest part uh that being said um maybe I can even like walk back to some of the uh Parts without that right exactly and say the the version of the game without language because I think it helps to also introduce like all these other aspects that are very difficult about the game um because first of all the uh well there aren't that many pieces on the board compared to say something like the board compared to say something like go go um the every single unit on the board has a bunch of different choices for for what it can do right um so you have different types of like you can you can move a unit you can keep it where it is you can have it support another unit um you can have fleets like Convoy armies across bodies of water um and these moves can be done to any of the territories that are around them and so because of this the um action space hugely explodes right so instead of something like 100 200 possible action supports it and go it's something like 10 to 20. and like the number of possible board States is like more than go then go is compared to chats uh oh wow um and",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 173, "maxCueIdx": 214},
    },
    {
        "content": " 207 um action space hugely explodes right so instead of something like 100 200 possible action supports it and go it's something like 10 to 20. and like the number of possible board States is like more than go then go is compared to chats uh oh wow um and so even just starting with that right super Clump kit this is I don't want to completely derail everything that you're saying but you uh obviously know this game really well now and when you started working on this project three years ago you didn't know it are you yourself now a decent diplomacy player I I think I'm a decent diplomacy player I actually had um I I got into playing quite a bit online on web diplomacy.net um one of the more popular sites for for playing the game online um and had the great pleasure to go to a couple in-person diplomacy tournaments um what we're actually is it or as a competitor as a competitor No Limit played in them um it was actually the North American championships this year and last year and the world championships this last year I'm sorry in 2021 and 2022 right and I did not Place highly um but I would absolutely recommend anybody who's interested to to try out these tournaments there's quite a few all over um and the players are amazing and it's like it's a very intense and emotional experience and I think I even feel like I like learn things about myself and like my personality that like I really had to Grapple with when you're like",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 208, "maxCueIdx": 247},
    },
    {
        "content": " these tournaments there's quite a few all over um and the players are amazing and it's like it's a very intense and emotional experience and I think I even feel like I like learn things about myself and like my personality that like I really had to Grapple with when you're like sitting across this board with someone and you're like trying to convince them to work with you and you're like how do I convince you that like you should work with me and then I'm not lying to you and how do I know that you're not lying to me and like all of this um was actually it was a big Challenge and it was uh wow quite a lot of fun to get into it it hasn't I I said I didn't want to do real you know I am derailing you a bit but when you're in one of these big tournaments these human tournaments how is it set up like there's individual rooms with like uh yeah so you have you'll have a board and seven of you sitting around the table um each of you playing one with great powers in Europe in the year 1900 um so it's it's kind of like leading up to World War One this idea that like diplomacy could actually be what uh prevents like the the Bloodshed and like the failure of diplomacy led to off the conflict and so here you are with the chance to come to a diplomatic solution um the founder of the game actually said like the ideal outcome is that everybody just hides um and in fact many if not most games actually end in the tie and not a ID:",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 241, "maxCueIdx": 278},
    },
    {
        "content": " led to off the conflict and so here you are with the chance to come to a diplomatic solution um the founder of the game actually said like the ideal outcome is that everybody just hides um and in fact many if not most games actually end in the tie and not a natural winner oh um like a seven-way tie so a seven-way tie is very uncommon uh and and that's it that's kind of the ideal diplomatic setting because nobody is able to actually overpower anybody else because everybody just maintains like diplomatic stalemate right um it's kind of a boring game if it goes that way um I play it in one one that did um and usually everybody is angry and then satisfied um but yeah so you you stand around the board and then um for each turn there's 15 minutes on the clock and you can like pair off um and just grab someone go talk to them away from the board and then come back make your deals and create your alliances and then you all write down your moves you put them in the center and then the timer stops and all the moves just happen all at the same time so everybody just has to sit and watch while like all the pieces are moved around the board then you find out whether you're a potential ally has actually gone through with what they promised they would do or if instead they've moved all their units up to your border and are about to just walk into the centers that you left open right because you trusted them too much that's ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 272, "maxCueIdx": 313},
    },
    {
        "content": " then you find out whether you're a potential ally has actually gone through with what they promised they would do or if instead they've moved all their units up to your border and are about to just walk into the centers that you left open right because you trusted them too much that's the complete information part that you're talking about whereas in go in chess in Risk you can see at any given time you know what the state of play is but because people make their moves in advance secretly and then everybody kind of exposes their moves after they've decided on what they will be that there's this there's this hidden element that's more like poker exactly nice cool well it's great to understand that kind of broader context around how the game is played especially these in-person human tournaments in order for this uh diplomacy AI Cicero to be able to play I guess that was only that's only ever been used in uh online tournaments right where there's no way for people to know that it's a machine yeah that's exactly right yeah um we did not have the ambition to try and hook it up to like a speech-to-text system with like proper like Prodigy and emotions and all that in order to annoy try and negotiate with people yeah yeah live so uh we kept it all to text um just put it in sunglasses in a trench coat and general notice um or put one put like you know the uh the like Monument next to the the table although you need to then also give it wheels so it can can drive away to have private",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 307, "maxCueIdx": 346},
    },
    {
        "content": " so uh we kept it all to text um just put it in sunglasses in a trench coat and general notice um or put one put like you know the uh the like Monument next to the the table although you need to then also give it wheels so it can can drive away to have private conversations um yeah so online and I guess so is it did you say net diplomacy web diplomacy web diplomacy.net yep recently in episode number 655 Keith McCormick and I discussed the importance of managing the machine learning life cycle effectively to allow you to learn about Keith's approach to All Phases of the life cycle he's kindly making his Predictive Analytics Essentials course available for free all you have to do is follow Keith McCormick on LinkedIn and follow the special hashtag sdskeefe the link gives you temporary course access but with plenty of time to finish it mastering machine learning project management is just as important as learning algorithms check out the hashtag SDS Keith on LinkedIn to get started right away started right away I recommend it go there try out the game and and if people do go there they won't now theoretically know whether they're playing against a human or Cicero so our we do not actually have our AI running on this site although it's possible that somebody has uh stood up a copy of it um our model weights are available by requests in our GitHub requests in our GitHub um um but there is you can play against a copy of our no press uh one versus one bot ID:",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 340, "maxCueIdx": 381},
    },
    {
        "content": "374 on this site although it's possible that somebody has uh stood up a copy of it um our model weights are available by requests in our GitHub requests in our GitHub um um but there is you can play against a copy of our no press uh one versus one bot um so we in order to simplify the game we actually I think we need the no press yes so no press just means there's no conversation between people right um whereas full presses is what we used to say that you can talk to other players say that you can talk to other players right right um it's kind of meant to uh uh speak to an older version of the game where people would uh play by mail and and you would call like the conversations like press releases from the countries press releases from the countries um um that's wild so people would play over the course of months yes yeah yeah the games around since like the 1950s um apparently very early online version um apparently very early online version um um yeah yeah yeah yeah um um yeah apparently Kissinger really left the game and um I think maybe JFK too yeah it sounds like there's like real life skills you can be learning from playing this game yeah become more diplomatic all right so the last time that I interrupted you uh you were about to tell us about how anybody can go and play the no press version of this algorithm right now right yeah so this specifically is a version of the game called France versus ID:",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 375, "maxCueIdx": 417},
    },
    {
        "content": " playing this game yeah become more diplomatic all right so the last time that I interrupted you uh you were about to tell us about how anybody can go and play the no press version of this algorithm right now right yeah so this specifically is a version of the game called France versus Austria where there's only two players and we kind of went back to this because this simplifies the game a little bit it still has uh the much higher scale than go that I already mentioned um but in this setting then you can still use uh a modified version of Old techniques of uh self-play reinforcement learning to teach the about the game um there we had to do tricks to deal with the scale um there there's a model that we developed called Dora uh because particularly ways that this model introduce exploration techniques um you know when you have to how do you how do you get a model to sample from uh 10 to 20 possible actions so it actually like has any learning signal to choose which uh moves should it should get better from um and there's ways that you can kind of like narrow this down to the moves that are most likely right most of those moves are terrible to play in like uh a human would never even play them right um and so first kind of solved like the one versus one scaling problem and indeed you can train the model from self-play from scratch uh to play one versus one and it can do very well and you can play against this and no you'll lose every time with no language right ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 411, "maxCueIdx": 451},
    },
    {
        "content": " um and so first kind of solved like the one versus one scaling problem and indeed you can train the model from self-play from scratch uh to play one versus one and it can do very well and you can play against this and no you'll lose every time with no language right um then even just adding the multiplier component now makes it extremely difficult if you train the model from scratch using self-play it cannot compete at all with uh if you put it against six humans um whereas the one versus one bot can destroy you um like very good players can can compete with it but it's very very very compete with it but it's very very very good good um and this is because even in the setting where you don't talk to each other um there is both competition and cooperation and you have to actually play in line with the human Norms in order to be competitive so for example um two Powers who are next to each other um even without talking to each other can still Ally just by moving their Pieces away from one another right and then after doing so uh and let's say each one takes territory now they have another choice they build a new unit do they send it to attack the other person or do they say no this is working great and keep pushing units to the other front line you don't have enough units to cover all of your sides and so a lot of times it's very appealing to like keep them moving in the same direction so that uh and ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 445, "maxCueIdx": 486},
    },
    {
        "content": "attack the other person or do they say no this is working great and keep pushing units to the other front line you don't have enough units to cover all of your sides and so a lot of times it's very appealing to like keep them moving in the same direction so that uh and just like Bank on that trust right well maybe leaving just enough of a guard for us to like deter them being tempted to turn around and attack you right um and so this like interplay between like this this trust that is barely established right because there's there's not even a promise there's no conversation on it and like how you're moving your units around the board um this comes from a lot of human Norms around like reciprocity and trust and like what uh when you see somebody move a unit in this way what does it mean what are they signaling to me um and so actually no press diplomacy because of this is often called gunboat because of this is often called gunboat diplomacy diplomacy um because it's like it's just about where where do you put your guns and not like what are you actually saying uh directly to the other person really it's kind of obvious from the way that the board is set up at any given time like oh you have all of these units right up against this one border and this other border you haven't needed them so far because this other power has been leaving you alone so you just kind of assume that that momentum will continue until maybe you start to notice oh that other power is now like it's taken over ID: ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 480, "maxCueIdx": 518},
    },
    {
        "content": " up against this one border and this other border you haven't needed them so far because this other power has been leaving you alone so you just kind of assume that that momentum will continue until maybe you start to notice oh that other power is now like it's taken over the territory of all of the other territories he was butting up against now and the only one left right I have to attack them to stop them from attacking me and um this definitely is all at play um and in general diplomacy actually does have a strong like stop the leader aspect um because if there's a tie everybody shares the score um but if one person gets more than half of the board that person wins out right and everyone else gets zero yeah I don't play diplomacy but I do play Settlers of katana which is on my shelf here uh viewers can see in a YouTube version so like my board games are limited to chess backgammon Settlers of Catan and exploding kittens uh which you got into as a family of Christmas and is a very short fun game that you can play with people of all ages um but in Settlers of Catan I have I I tend to be strong early which ends up being to my detriment because then everyone gangs up on me oh definitely um but yeah so if you if you want to be competitive in in this uh in this game even without telling each other you have to follow these human dorms right like a self-play agent um a lot of times we'll learn things ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 512, "maxCueIdx": 551},
    },
    {
        "content": " gangs up on me oh definitely um but yeah so if you if you want to be competitive in in this uh in this game even without telling each other you have to follow these human dorms right like a self-play agent um a lot of times we'll learn things like uh just attack everybody on all like uh just attack everybody on all sides sides sides um um or you have an alliance like it seems like a human would think that they're an alliance and like just betray it right away because who cares because that's how the bot plays like the bot doesn't take it personally if it gets betrayed it just keeps playing from from where it stands right like it doesn't it hasn't learned this uh kind of human behavior of uh like Vengeance right like a human when betrayed often will then spend the rest of the game just trying to make the player who uh betrayed them lose instead of actually like trying to maximize their scores anyone care to win exactly and across multiple games this is actually a winning strategy because it teaches people to be very careful about betraying other humans right um but the bot doesn't learn that in the self-play so when the Bots are playing online they have like a name that is a um bought three thousand um and so so then people can end up even in these online tournaments do you end up playing you would keep noticing that buff 3000 uh was like in the same games as you yeah so all of the online games ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 545, "maxCueIdx": 586},
    },
    {
        "content": " online they have like a name that is a um bought three thousand um and so so then people can end up even in these online tournaments do you end up playing you would keep noticing that buff 3000 uh was like in the same games as you yeah so all of the online games um were played where the game takes place anonymously um and so you don't like the other powers are just names for their powers right like they're playing against France England Germany and not uh not against like bot one two five zero right against like bot one two five zero right um um yeah and so the the names are revealed yeah and so the the names are revealed afterwards afterwards um and so afterwards player people were able to look back and see like these were the bots so then then you could maybe know this right um and in fact basically to deal so we dealt with this basically to deal so we dealt with this problem problem um we basically the the trick is um we basically the the trick is um um regularized towards human behavior so take a data set of human behavior um and regularize two a couple aspects of the model so first is the uh planning procedure so the uh we have a you know in in Chester go you would have multicolorage research um and you can apply this algorithm there too um in diplomacy it's more complicated because you can't just like roll out forward when you can't when it's non-deterministic right when all the moves are hidden",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 580, "maxCueIdx": 622},
    },
    {
        "content": " Chester go you would have multicolorage research um and you can apply this algorithm there too um in diplomacy it's more complicated because you can't just like roll out forward when you can't when it's non-deterministic right when all the moves are hidden you don't know what the other players are going to make you can't roll out into the future in the same way oh yeah you have to do this more complex planning process um and in that planning process we do regularize towards what humans have done in all of the training games um and that that helps you to predict like what is likely gonna happen uh on the human side and also moves that like might be better for you to do because it's more like one human would do right so self-play alone doesn't work with these multiplayer games in those cases you need to rely on training on human data to have some idea of exactly from all of like the almost infinite number of possible moves at any given point what kinds of moves are relatively plausible relatively likely um and part of why you have to do that is because the multi Monte Carlo tree search won't work like it does in other games where you have full information yeah and and so even in chess or go where you have full information you can actually still benefit from this in that it will make the planning process um more accurately predict what humans will do right um like your you're incorporating this like even if this wasn't like what the model thinks was the optimal move to do a",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 615, "maxCueIdx": 656},
    },
    {
        "content": " have full information you can actually still benefit from this in that it will make the planning process um more accurately predict what humans will do right um like your you're incorporating this like even if this wasn't like what the model thinks was the optimal move to do a human may be more likely to still play that move for some reason um it may be that that is actually more optimal move and like the self-play model didn't actually like learn that or it just might be that like humans are likely to play moves like that even if it's maybe not what the model thinks is optimal um and so we actually had the first paper on this uh that um came out like uh about a year ago the no press version um yes and they were specifically making this change to the planning process um but what you actually also need to do uh to get to work really well is also make the change to the self-play process so during self-play you can also sample from uh human actions so that the model is trained to play against what humans would actually play would actually play um um and more or less like the combination of these uh like there's more there's more new ones there to make it all work well but more or less the combination of these where like you are both training against human behavior and planning uh conditioned on human behavior um enables you to play much more effectively in this ending where you're going to end up playing with humans um like these B",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 649, "maxCueIdx": 691},
    },
    {
        "content": " well but more or less the combination of these where like you are both training against human behavior and planning uh conditioned on human behavior um enables you to play much more effectively in this ending where you're going to end up playing with humans um like these Bots can play well against other copies of bots right but right um when you're gonna have to play against humans you need to incorporate human um Behavior specifically in these multiplayer settings and particularly when there's cooperation that's involved as well um because you can't like you can't follow human Norms of cooperation when uh you haven't seen any human behavior mathematics forms the core of data science and machine learning and now with my mathematical foundations of machine learning course you can get a firm grasp of that math particularly the essential linear algebra and calculus you can get all the lectures for free on my YouTube channel but if you don't mind paying a typically small amount for the udemy version you get everything from YouTube plus fully worked solutions to exercises and an official course completion certificate as countless guests on the show have emphasized to be the best data scientist you can be you've got to know the underlying math so check out the links to my mathematical foundations of machine learning course in the show notes or at learning course in the show notes or at johncrone.com johncrone.com um have other people tried like do are there other Bots that people have had ID: ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 684, "maxCueIdx": 726},
    },
    {
        "content": "so check out the links to my mathematical foundations of machine learning course in the show notes or at learning course in the show notes or at johncrone.com johncrone.com um have other people tried like do are there other Bots that people have had for playing diplomacy historically which obviously could not couldn't come near the level that you guys are playing at but is that something that you tested against as well that they're like in the same way that um you know that with chess algorithms or go algorithms you have these competitions against like simulations against other Bots yeah so there's been um a number of more like handwritten uh diplomacy bots in the past um all all of this no press all of this without language without language um um um they're they're the first um like deep learning based approach for diplomacy AI came uh from Mila uh from diplomacy AI came uh from Mila uh from Montreal Montreal um and they published that a couple years ago um and then basically about a year later um both us and deepmind um then also publish uh different uh approaches to applying uh deep learning to no press diplomacy um so we did we do compare against um their AI but there's not it's not like a a like super rich uh field of uh bots in a way that like go is a little bit more like there's more available chess there's more available ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 720, "maxCueIdx": 763},
    },
    {
        "content": " 756 to no press diplomacy um so we did we do compare against um their AI but there's not it's not like a a like super rich uh field of uh bots in a way that like go is a little bit more like there's more available chess there's more available and part of why I thought of this question is that when I was a kid I had this chessboard with uh magnetic pieces and so I could play against a chess computer on this physical board like it wasn't I didn't there wasn't a screen except that it had this little LED display which would say you know move something from this Square to this other something from this Square to this other Square Square and one of the frustrating things for me playing I never really got super into playing against this chess computer despite me wanting to be better at chess because I was at the super nerdy school where there were lots of kids that were great at chassis and play at lunch and we'd have tournaments and stuff I was like oh I'll get this chest computer but it would take so long between moves to it would take so long between moves to compute compute um so when you guys are designing this and it has to be able to compete in real and it has to be able to compete in real time time that must be a consideration that comes up a lot like the compute like does is it effectively real time or does it does it need time to process yeah so um the first uh so first a lot of this has to be done uh offline right so ID",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 757, "maxCueIdx": 796},
    },
    {
        "content": " time that must be a consideration that comes up a lot like the compute like does is it effectively real time or does it does it need time to process yeah so um the first uh so first a lot of this has to be done uh offline right so um in order to actually fully understand these models where the point of them is playing against humans you know it's expensive to have a human game you have to get six people together uh it's going to take two hours um and so a lot of the work is first of all fine we'll like play the bot tickets each other and measure things like this um and then finally when um we're ready we would set up a series of games um and the culmination for this uh for the no press models was um a tournament uh at the beginning of last year um so I think this may have already happened uh just or have just finished when we met um where the bot actually won the um where the bot actually won the tournament tournament um and we started with a version of the bot that was like lightly conditioned uh on human play um and it turned out that like people could actually recognize it it was like doing things that were slightly awkward and things like this um and then we just turned up the regularization parameter and the regularization parameter and the planning planning um and then basically from there it was very very good uh like close to perfect um the best human in the tournament said ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 789, "maxCueIdx": 832},
    },
    {
        "content": " slightly awkward and things like this um and then we just turned up the regularization parameter and the regularization parameter and the planning planning um and then basically from there it was very very good uh like close to perfect um the best human in the tournament said like the only way that you could tell which player was the bot by just looking at the moves was who's doing the best it's probably the bot um and sorry I'm interrupting you again but that's it's interesting that's so different from a game like go where different from a game like go where um um the alphago algorithm that deepmind created was described as having like alien moves and in that kind of situation where you know you don't need to be negotiating and forming alliances it doesn't matter that the algorithm comes up with completely foreign kinds of moves but in a game like diplomacy where even in the no press game you're still picking up on subtleties of how people are playing to try to figure out who you should be forming alliances with or whatever there's if one of the players you're playing with is doing these kinds of alien moves you probably are inclined to kind of as a group pick on it yeah and I do think at that point in the tournament Players may have been intentionally looking for it and intentionally banding together to destroy it because they knew they were playing in the tournament against a bot um but uh then so to actually answer your question this",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 825, "maxCueIdx": 867},
    },
    {
        "content": " it yeah and I do think at that point in the tournament Players may have been intentionally looking for it and intentionally banding together to destroy it because they knew they were playing in the tournament against a bot um but uh then so to actually answer your question this tournament was uh five minute turns um and so it's pretty quick and it does have to make its moves in a reasonable amount of time on the other hand five minutes for a neural network to return to move like not super terrible especially when it's not doing anything else like there was no language at this point right um and so um you know it's not like super cheap but it's also it's okay um yeah five minutes is like a reasonable amount of time to think cool um what may where that got more difficult is with the language model right uh because then you have to respond fast enough for people to respond back to you um and back and forth so that yeah so once you jump to the Press version that when you say like let's say I don't know how standard this is but I guess let's just assume that like a five minute between five minutes between moves is standard and um just to recap for listeners why that's significant is that they have seven players playing I guess it's every five minutes that you submit on a yeah piece of paper I guess in real life or something what your move is going to be is going to be um um so that whole",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 860, "maxCueIdx": 903},
    },
    {
        "content": "for listeners why that's significant is that they have seven players playing I guess it's every five minutes that you submit on a yeah piece of paper I guess in real life or something what your move is going to be is going to be um um so that whole time throughout that five minutes I guess any amount of conversation can be happening yeah exactly exactly so um this this is really the hard part of diplomacy right everything I just diplomacy right everything I just described described already hard right but like the the real hard part is now do all of that while having strategic convincing conversations with people uh that can go basically as fast as you can send messages back and forth right um and with six people at once um and of course in person um the norm is usually 15 minutes because then you can have time to pull people's side talk to them then go pull somebody else aside but when you're playing online you can just type away talk to all six players at once and it can be a little overwhelming you only have typically two or three players who are actually like neighboring you and so those are usually the people you focus on um but there's a lot of conversations to be had there's a lot to do in the turn to like have those conversations and then actually come up with the move that you're gonna play you're gonna play um um so yeah so like I guess in Broad Strokes how did you guys make that jump ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 896, "maxCueIdx": 938},
    },
    {
        "content": " had there's a lot to do in the turn to like have those conversations and then actually come up with the move that you're gonna play you're gonna play um um so yeah so like I guess in Broad Strokes how did you guys make that jump from a year ago having a success in the tournament in the no press tournament it might have even seemed at that time like the Gulf from being able to play at expert level in no press to press would be enormous and yet here we are sitting a year later and you've published on this enormous success of being able to compete in a top decile right of yes exactly yeah and so fortunately we were actually working on full press diplomacy in parallel um and so had already been making progress on how how do you set up these models to actually say intelligent things to the other players and things are really grounded and and accurate and precise right because I think that's a big weakness of these other really large language models is they're very they're like unbounded in a lot of ways they have they get a very small amount of have they get a very small amount of context context um which is like the prompts that you provide to it and then they're expected to output something that is like high quality ideally accurate and things like this and this is like obviously a huge challenge to do um but how how do you actually get those to work better in the setting where there is more grounding right uh there's more context there",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 931, "maxCueIdx": 973},
    },
    {
        "content": " expected to output something that is like high quality ideally accurate and things like this and this is like obviously a huge challenge to do um but how how do you actually get those to work better in the setting where there is more grounding right uh there's more context there's um like in the case of diplomacy you have you know the game board the conversations that you've already had the rules of the game the rules of the game um um and like then actually like what does the agent want to accomplish in that and how does it do things that will actually help it with that um there's a lot more Nuance there but then hopefully you can use that to get the models to actually say something like better than you know spitting out a message that just looks like it could be from a game of diplomacy which that's what you get if you just fine-tune a large language model and diplomacy Theory though right it'll say things that sound like diplomacy uh but it'll it'll do things like it'll suggest convoying a fleet uh which is definitely not possible it will suggest moving to territories that are unreachable and things like this so completely contradicting the rules of game the moves that have happened so far because that llm would have initially been trained on like a sense of global geography not just the geographies of this game and yeah it would yeah its parameters would be tuned on what's possible with a real-life Fleet as ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 966, "maxCueIdx": 1006},
    },
    {
        "content": " the moves that have happened so far because that llm would have initially been trained on like a sense of global geography not just the geographies of this game and yeah it would yeah its parameters would be tuned on what's possible with a real-life Fleet as opposed to what's possible in just the game yeah and I think there I don't think there exists enough diplomacy data to fine-tune these models for long enough to actually get them to like 100 accurately uh say things about the game um not that I think we got to 100 but the the way that we were able to train these models I think I got them a very large portion of the way there and kind of showed how you can in a more grounded of showed how you can in a more grounded setting setting get the models who behave much better um and and I think more like intentionally uh rather than just like likely tokens after a prompt um right so uh you didn't start with like a a regular llm that's just trained on internet language but we've heard a lot in recent years and about Transformer architectures a particular kind of deep learning architecture that is capable of contextualizing over very uh long uh passages of text and can carry on Long conversations compellingly like Chachi PT can so uh does your language architecture involve Transformer architectures yeah yeah so there's there's uh kind of a bunch of different pieces to our model ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1001, "maxCueIdx": 1038},
    },
    {
        "content": " contextualizing over very uh long uh passages of text and can carry on Long conversations compellingly like Chachi PT can so uh does your language architecture involve Transformer architectures yeah yeah so there's there's uh kind of a bunch of different pieces to our model um on The Language sign the foundation is a Bart model so this is a Transformer based model which is an encoder decoder unlike uh GPT um it so it takes in a context it encodes a state and then it can attend to that context in order to fully generate a new uh and kind of they're so there's a few different pieces to how we actually use this so uh we have that language model um but that model needs to know what to talk about right so the naive thing that I kind of mentioned before is just feed in the conversation history and the game board State try and fine-tune the model to produce the messages that a human would have produced in that setting would have produced in that setting um um this like starts to look like it's working but it says things are working but it says things are inaccurate inaccurate um the other thing is if you're asking that to produce the moves that you're going to make um it also is hugely exploitable um and this is kind of like uh somewhat known already um in the language model like negotiation later ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1032, "maxCueIdx": 1071},
    },
    {
        "content": " other thing is if you're asking that to produce the moves that you're going to make um it also is hugely exploitable um and this is kind of like uh somewhat known already um in the language model like negotiation later um say papers from Mike Lewis where if you put the language model negotiation task and you train it in human data and then say model thank you for agreeing to this deal that is amazing for me like I'm so glad we had this conversation and thank you for agreeing to this um humans actually only say that to each other after having agreed to something um and so the model thinks that it has agreed to something and then just gives you whatever you just said right um it's like kind of amazing to actually see this happen to the model back door um yeah it is America I mean you know it's like the the like safety skirt prompts uh but for negotiation Bots um is just tell them that they've already agreed and they'll just give you whatever you ask for um but so that that was kind of an obvious problem and so it's kind of like we had to go back and say okay what are we going to feed into uh the language we going to feed into uh the language model model um and so this is where actually the no press models come in so we can use those models that are like this models that are like this um ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1065, "maxCueIdx": 1103},
    },
    {
        "content": " 1096 we going to feed into uh the language we going to feed into uh the language model model um and so this is where actually the no press models come in so we can use those models that are like this models that are like this um um to generate plans for the model and then if they can condition on those plans then they can now talk about that in order to have a more guided conversation no press model weights were useful in your press model sort of um it required a few more improvements um it required a few more improvements like like um in no press if you're trying to do planning you don't have to factor in the fact that other people are talking to each other um like other people's moves are are relatively like well they are like uncorrelated because they can't plan them and so you have to adjust your planning procedure to uh handle like correlated behavior um and a few other nuances like this that like we had to adapt it um uh quite a bit for uh the the language setting um but then you can output plans um and say like look this is what I want to do now let's talk about this and in fact we actually would create per player plans so if you're France and you want to talk to England the model will actually output a plan that is here's what I want to do here's ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1097, "maxCueIdx": 1135},
    },
    {
        "content": " this is what I want to do now let's talk about this and in fact we actually would create per player plans so if you're France and you want to talk to England the model will actually output a plan that is here's what I want to do here's a move that England is somewhat likely to do and this is what you should talk to them about like it's actually plans both for you and for your conversation partner I mean so it makes the conversations much richer because not only does it have these actually like strategically sound plans to work with uh that don't have to be stuck in the language model but also all this information about like how things are working what like valid moves are on stuff like this doesn't have to be as carefully encoded into the language model because if it is told these are the moves you should talk about then it doesn't talk about illegal moves because it is looking at the moves it should be talking about um and this grounding helps a lot and it even helps the model to better model the language like uh if you look at language like uh if you look at um um the like perplexity right or measure of how well a language model has learned a piece of data um providing the model with plans to condition on actually um lowers the perplexity by quite a bit it's easier for the language model to learn the language when it's not also trained to learn the",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1130, "maxCueIdx": 1168},
    },
    {
        "content": " how well a language model has learned a piece of data um providing the model with plans to condition on actually um lowers the perplexity by quite a bit it's easier for the language model to learn the language when it's not also trained to learn the rules right trained to learn the rules right um um um which which so I kind of skipped to the the output of the model which is you give it plans it can condition on them to produce it can condition on them to produce language language but you actually have to teach the language model to do that too right um that means we have to stick plans into the training data and this is actually also hard right um like the data you start with is here is the conversations that people had and here is the move that they made but like the move that they made does not necessarily what their plan was when they sent that message um and so we have to kind of do this like uh inference of what was the person likely to do in the like what were they trying to do in this moment wow um and I kind of say like you know what moves increased in likelihood after this move it's often it's like a way that we we kind of framed it and well by inserting that into the training set then you can condition the language model on those plans and then at test time you know when you're playing a game ID: ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1162, "maxCueIdx": 1200},
    },
    {
        "content": " increased in likelihood after this move it's often it's like a way that we we kind of framed it and well by inserting that into the training set then you can condition the language model on those plans and then at test time you know when you're playing a game you can actually feed the plants in um so it's like kind of a complicated yeah modular architecture here with like all these different steps but um by doing this then you actually get this like very powerful language model um and yeah yeah the science paper which will include a link to in the show notes uh the science paper that reveals Cicero and describes this uh top decile performance in press diplomacy uh it talks about different sub modules coming talks about different sub modules coming together together in order to form the overall Cicero in order to form the overall Cicero architecture architecture um or you've obviously alluded to some of them here um are you able to kind of give us an overall sense you know we we can't have the podcast episode go on for hours and hours and hours people can refer to the science paper to get all the details but just at a high level what are kind of the key sub modules and how they interact yeah and so that you I kind of already hit those at the at the high level right which is like you have a language model that needs to be trained to condition on plans which you had to ID: ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1195, "maxCueIdx": 1232},
    },
    {
        "content": " high level what are kind of the key sub modules and how they interact yeah and so that you I kind of already hit those at the at the high level right which is like you have a language model that needs to be trained to condition on plans which you had to get a separate model to do uh to infer those then you have a the planning um like strategic reasoning if you will model which consists of both self-play reinforcement learned model which was regularized towards human behavior then there's a planning app around this on top of that also regularized towards human behavior um and then that produces plans that go into the language model the language model produces a bunch of outputs and then we have a bunch of filters on top that help to clean up those outputs before we send them so right um maybe that is doing like one final check for uh uh like saying things that don't make uh like saying things that don't make sense sense um or like are illegal um and or are like offensive and we tried to filter out things like that tried to filter out things like that um um that's the gist of the architecture um at some point you were like you know what we need to make sure that we're filtering out offensive things that your diplomacy does that happen is that a way that we could tell that we're playing against uh your agent because ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1227, "maxCueIdx": 1265},
    },
    {
        "content": " gist of the architecture um at some point you were like you know what we need to make sure that we're filtering out offensive things that your diplomacy does that happen is that a way that we could tell that we're playing against uh your agent because um humans might just be like all right F um humans might just be like all right F off off but yours wouldn't um I mean we did the best we could it's definitely not always perfect and some of it is even just like irrelevance like uh there was this one funny example uh there was this one funny example where where um the model either somebody sent it messages too quickly for it to respond or they just like uh the model had filtered out all of the messages it was going to reply with the first time um and then send me this message like where are you like uh like I need to hear from you and the model replied like oh sorry I was on a call with my girlfriend like and it's like okay that's clearly not true right like that's wild and does it make any sense so we did try to filter out things that like we're not actually like in context correct and even like real players would talk about things like Discord channels and stuff that like we don't want to refer to this kind of meta stuff either so the the bot needs to talk about Discord channels in order for it to seem realistic if it",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1260, "maxCueIdx": 1297},
    },
    {
        "content": " correct and even like real players would talk about things like Discord channels and stuff that like we don't want to refer to this kind of meta stuff either so the the bot needs to talk about Discord channels in order for it to seem realistic if it talks about a girlfriend yeah but so that's kind of like a bunch of the things the filters were targeting as well right just like irrelevant messages that like didn't really make sense because it's so easy for that to hallucinate and make a mistake hallucinate and make a mistake um um super cool Alex congratulations on this tremendous accomplishment I I don't know if you heard this particular episode but in my recap of so I guess my final episode of 2022 I recapped the enormous achievements and some of those were achievements and some of those were obvious obvious um AI models in our space that everyone's heard of like chat GPT or like Dolly too but I included sister on the list because this is tremendous and everybody should know about this achievement because it's about this achievement because it's incredible incredible um so congratulations Alex what's next um for you what kind of research is lined up like what you know having achieved this you set out on this 10-year project that took three years to uh to be able to compete at a high level at the most challenging game that you ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1291, "maxCueIdx": 1329},
    },
    {
        "content": "3 um so congratulations Alex what's next um for you what kind of research is lined up like what you know having achieved this you set out on this 10-year project that took three years to uh to be able to compete at a high level at the most challenging game that you could think of so yeah I mean was there even like as an emotional state once you like published a paper and stuff were you kind of like like I don't know when I trained when I spent two years training for a marathon and then you finish it and you're like all right so now what yeah I'm totally totally um yeah maybe I will slightly go back and uh give just a tiny bit more detail and uh give just a tiny bit more detail on on like how did we know this was actually good right um I think I don't think I actually mentioned that uh you mentioned it within the Top decile If the players that played against right um but I I think that's that's like a good that's a good start right like it it was able to play well it was able to win games he was able to perform consistently at a high level um definitely not like is nowhere near superhuman like we would not claim that um there are players that beat it in the tournament that they played in um but I think the other thing that we we really appreciated was it was actually able to play in 40 games so that's",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1324, "maxCueIdx": 1361},
    },
    {
        "content": " is nowhere near superhuman like we would not claim that um there are players that beat it in the tournament that they played in um but I think the other thing that we we really appreciated was it was actually able to play in 40 games so that's about 72 hours of gameplay total sends uh thousands of messages um we mentioned in the paper I think it's something like six or seven thousand messages um and was not actually recognized as an AI right um so this is something in particular we're very proud of so I just wanted to throw that in there throw that in there um um but anyway so we got to the end of these 40 games uh we were able to publish the results and absolutely I like I felt a definitely a huge content of like oh my gosh we made it um and honestly I I wasn't even in the project for the full three and a half years I actually have just been a part of it for the last couple um and so other members of the team have worked harder and longer than me so uh I hope they feel it just has relieved and proud and that would actually be a really good time maybe even just to mention in that context so you're a senior research engineering manager at fair so what does that mean in the context of being involved in a project like this yeah for sure so my role in the project like this is more to uh make ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1355, "maxCueIdx": 1392},
    },
    {
        "content": " good time maybe even just to mention in that context so you're a senior research engineering manager at fair so what does that mean in the context of being involved in a project like this yeah for sure so my role in the project like this is more to uh make sure the project is running smoothly that people know what each other are doing they know what they're doing and why they're doing it they um are like getting all the contacts that they need to do while they're getting the help that they need to do it um all of like the the apparatus around it is moving forward like as we're preparing for the launch working with our product manager our marketing team our comms team um our video team and like all of these different roles that uh come together to actually make the launch successful uh uh kind of helping to make sure that our team is coming to them with all the content that they need like the uh all of that of that um um so you know helping to grow the careers of everybody in the project as they're going through it and like right all of going through it and like right all of that's that's um kind of normal managementy stuff exactly exactly um and so then so this is a project uh was already going on to some extent and you began working on this perhaps alongside other research projects that you're also managing",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1387, "maxCueIdx": 1426},
    },
    {
        "content": ": 1419 that's um kind of normal managementy stuff exactly exactly um and so then so this is a project uh was already going on to some extent and you began working on this perhaps alongside other research projects that you're also managing simultaneously so yeah I had two projects that I was yeah I had two projects that I was supporting supporting um during this time so uh diplomacy was one uh the The Cisco project um and then the other was a project based in France that I was working on uh automatically proving mathematical automatically proving mathematical theorems theorems um so yeah they have resulted in Europe's uh last year in iClear this year wow um yeah they they were able to get to a point where they were able to solve 12 uh International math Olympian problems um wow using Ai and yeah so that's exciting as well um obviously a different topic but yeah um so all right so I I kind of want to give it the I wanted the audience to kind of have that context around uh you know how you fit into this uh Fair puzzle but I interrupted you as you were just explaining kind of what was next just explaining kind of what was next um um yeah for sure so I think um obviously we're really excited about and proud of this result um I think there were a few things that we were able to start seeing some signal ID",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1420, "maxCueIdx": 1458},
    },
    {
        "content": " kind of what was next just explaining kind of what was next um um yeah for sure so I think um obviously we're really excited about and proud of this result um I think there were a few things that we were able to start seeing some signal that they would be interesting but didn't get to fully explore them um and I I think um one big area of that is like how do you bring reinforcement learning techniques uh and like planning techniques more to Bear uh in getting good results of language models um I think like kind of the like one aspect of this is kind of just like how do you pour more compute in at inference time and actually get something more out of it in some ways this is what we're able to do with our model though that's way oversimplifying it is like by putting all this compute in in the planning we can then give the language model something uh much more like grounded and intentional to work with so that the language model outputs look more grounded and intentional um and I think they're they're still more room to dig into that um like one one even just interesting technique that that we tried and were able to get a little bit of initial success in is um this like value based filtering so we train a value model on the messages that the the model was sending and we would say like if the message that was sent say like if the message that was sent um ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1452, "maxCueIdx": 1489},
    },
    {
        "content": " were able to get a little bit of initial success in is um this like value based filtering so we train a value model on the messages that the the model was sending and we would say like if the message that was sent say like if the message that was sent um um the bike was rated as drastically lowering the model's value um don't send that message um and this is actually able to filter um and this is actually able to filter out out um messages that were like strategically um messages that were like strategically catastrophic catastrophic um so for example if let's say you have a unit that is neighboring two of an opponent centers and they also have a unit that's neighboring two of their centers their centers um um because our model is always conditioned on the actual plans that he's going to do it doesn't really lie um not intentionally and so it will what what can happen is the model can actually like accidentally tell the other player what move it's actually going to do and if they know that then instead of a 50 50 shot blocking they can actually just go ahead and block the move that the model was going to do um and there's a huge mistake for the model to send these messages and the value-based filtering connection detect this that like the by sending this message I will more likely have a lower score at the end of the next",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1484, "maxCueIdx": 1523},
    },
    {
        "content": " move that the model was going to do um and there's a huge mistake for the model to send these messages and the value-based filtering connection detect this that like the by sending this message I will more likely have a lower score at the end of the next turn than if I don't send this message so don't send it um and then you know we weren't able to get that to a point where uh you could actually use that to like choose which message you generate or things like this but I think there's more there and I think in general there's like a lot of room for continuing to look at how reinforcement learning uh based techniques and how at least like planning techniques can improve the outputs of language models I think we're already seeing this with uh uh like RL HF uh work um that's happening to tune the outputs of language models like chat gbt to say things that are more of what humans are expecting of them right uh an example is maybe like if you if you ask a model like a math problem um it maybe is just as likely to to finish the answer with like a quote finish the answer with like a quote right right um I'm actually borrowing this example from Serge AI uh who does annotations in the space um where they you know if you say two plus two equals blank a language model might say uh like two plus two equals blank four ID:",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1517, "maxCueIdx": 1555},
    },
    {
        "content": " 1548 right um I'm actually borrowing this example from Serge AI uh who does annotations in the space um where they you know if you say two plus two equals blank a language model might say uh like two plus two equals blank four plus four equals blank Sam couldn't remember the answer to either one right um rather than actually just outputting four which is what you want um and so you know all these techniques to try and push language models more towards like what what is the human actually expecting uh you know their supervised learning of like instruction fine-tuning there's rohf to like rank uh outputs that are like as the entirety good that are like as the entirety good outfits outfits outfits um um but I think there's still a lot more work to do in the space cool well that's exciting um and at the beginning of this conversation one of the things that I learned is that a lot of this what seemed to me on the surface to be relatively basic research basic AI research does in fact tend to have a lot of applications uh within the real world including within meta itself so how could this technology how could Cicero the work that you've already done and published on be applied to the real world or the metaverse say yeah I think yeah I think um um ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1549, "maxCueIdx": 1589},
    },
    {
        "content": " 1582 including within meta itself so how could this technology how could Cicero the work that you've already done and published on be applied to the real world or the metaverse say yeah I think yeah I think um um you know obviously we only applied to diplomacy the actual agent Cicero could only play the game diplomacy but um I think what we see here is a really convincing example of a grounded language model that actually can have goals and actually execute on them um and so I think uh other settings where we might see that is like there could be uh like digital agents in the in the metaverse there or you know even NPCs in the video game is maybe uh more approachable example where like you know you you could think of something like you know the you're playing Skyrim or something the guard at the gate perfectly fine for him to just be you know uh large like gbt model or something like spounding things that sound like what a guard would say but you don't really need to interact with him but if you talk to like you know the the king of the uh of the city you want him to actually be able to have like a back and forth with you of like here are the things that he wants you know he wants uh someone to go kill this monster he wants more information on his lost son um like all this and you want I don't ID: ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1583, "maxCueIdx": 1620},
    },
    {
        "content": "you want him to actually be able to have like a back and forth with you of like here are the things that he wants you know he wants uh someone to go kill this monster he wants more information on his lost son um like all this and you want I don't know Treasurer uh new equipment uh like the next piece of information moves you to the next stage of the quest and so you could actually train models knowing that these factors are at play and that conversation should be grounded on them um and actually generate like much more nuanced grounded conversations um wow I mean that's maybe like a gaming example but you could also think of other settings where there's like a virtual assistant of some client that needs to understand all of the actual context that is at play what the human is actually wanting um and not just be able to produce things that sound like they make sense uh but actually like take actions and talk about those actions and talk about those actions and um um yeah rather than just kind of like the scripted commands that we have today which are more precise uh but it's because we can't do things like this yet that is super fascinating yeah so that is a big limitation that you know anybody who spend a lot of time in chat GPT sometimes you're getting bits of conversation that seem totally relevant but other times it's going it ends up going off-piste and so what you're ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1615, "maxCueIdx": 1653},
    },
    {
        "content": " yeah so that is a big limitation that you know anybody who spend a lot of time in chat GPT sometimes you're getting bits of conversation that seem totally relevant but other times it's going it ends up going off-piste and so what you're saying is that this research the Cicero saying is that this research the Cicero research research is helpful because it it shows that given the right constraints you can have a grounded natural language model that is uh specific to some particular kind of task whether it's virtual like you're describing some conversation in the metaverse uh in some video game or like a virtual assistant and this conversation will be grounded and factual and helpful and action oriented in a way that the other kinds of incumbent llms uh often Veer Australia yeah I I hope so yeah and of course you need to to like find data that can actually like teach them all through this right like we talked about having to infer the plans that humans had before they sent a message um like they're they're still like work to do to actually get it to apply to a particular setting um but I think the techniques we showed kind of give you tools in the toolbox for actually doing that for actually doing that um um super cool all right so we've learned a little bit now of your role in the whole project so your your role as an engineering manager ID:",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1647, "maxCueIdx": 1685},
    },
    {
        "content": "1678 kind of give you tools in the toolbox for actually doing that for actually doing that um um super cool all right so we've learned a little bit now of your role in the whole project so your your role as an engineering manager so some specific questions that occur to me as as you were talking about that are related to how we tackle big long-term r d projects like this so when you set out on what's potentially a 10-year r d on what's potentially a 10-year r d project project how do you decide what to do first who is needed how is the project structured how do you decide on your r d roadmap yeah that's a great question I mean in in this case you know I was not I was not there for the beginning of the project uh so I'll kind of I can infer some of that and then talk about my experience in other projects too um I think here um I think here the the starting point looks like a harder version of promise that we already had version of promise that we already had right right um right like diplomacy no press diplomacy in particular was introducing a bunch of difficult problems um but that we they didn't look so different from problems in poker in go in some of these other uh games that we'd already work on so we kind of like can see already the kinds of techniques ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1679, "maxCueIdx": 1717},
    },
    {
        "content": "plomacy in particular was introducing a bunch of difficult problems um but that we they didn't look so different from problems in poker in go in some of these other uh games that we'd already work on so we kind of like can see already the kinds of techniques that we may need to develop to get that we may need to develop to get started started um and also uh to our advantage like other researchers were also working in the space right so Mila had published their results in that kind of gives some starting points to the kinds of things that you can try that you can try um um I think with a research project like this you don't you don't need to necessarily know the answer to how long it's going to take and like everything that you're going to need now but you you can start to look at the problem and like okay what are the challenges that we're going to face and what kind of talent are we going to need like okay this problem is a lot higher scale we're going to need uh strong research Engineers who can handle that scale right like who can help us to scale up our reinforcement learning algorithms who can help us to scale our planning algorithms make those faster make them work better um we are going to need access to gpus because we're going to need to train like a model for longer in order to deal with this with this um",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1712, "maxCueIdx": 1750},
    },
    {
        "content": "3 who can help us to scale our planning algorithms make those faster make them work better um we are going to need access to gpus because we're going to need to train like a model for longer in order to deal with this with this um um but also like ah like just training it for longer or bigger or whatever like isn't going to actually enable that full leap like you're going to have to come up with clever ideas to actually do that and so um in our case like the team also had like clever uh like game theorists uh who could come up with like equilibrium finding techniques that like don't you need to to use when you can't just you know use mtuts like you can in chess um and so there's like research Talent there's engineering talent that you need and then of course you know looking at what was there that still only covered no press right uh there there wasn't really like substantial language modeling expertise on the team and so modeling expertise on the team and so then then um The Next Step was uh bringing in uh research scientists a research engineer uh who had expertise in that space um and giving them the runway to work on that product of the problem and then that product of the problem and then okay okay now we need more Talent on that side to like bring in another research engineer bring in another uh research scientist ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1744, "maxCueIdx": 1782},
    },
    {
        "content": " um and giving them the runway to work on that product of the problem and then that product of the problem and then okay okay now we need more Talent on that side to like bring in another research engineer bring in another uh research scientist and like give them more uh uh bike capacity to to keep working on that problem that problem um um so I don't I don't know if that was like a very nuanced answer to the problem but yeah there was a huge amount yeah it's kind of like finding finding the mix of talent that you need both uh like on the scientific side and on the engineering side um you know getting hold of the compute you need getting all the data you need but maybe that's always the answer right yeah but it's kind of nice to hear you talk through it and think through it um yeah I I learned a lot from that um so speaking more a bit about your background and how you ended up being a research manager why did you choose to do research at a big tech company as opposed to say in Academia yeah so I actually joined the team um straight out of my undergrad um and in this case I I kind of had kind of a software engineer generalist but with uh great interest in machine learning uh profile and the team was basically looking for more engineering muscle to build into the team so the at that point there were",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1776, "maxCueIdx": 1815},
    },
    {
        "content": " um and in this case I I kind of had kind of a software engineer generalist but with uh great interest in machine learning uh profile and the team was basically looking for more engineering muscle to build into the team so the at that point there were a lot more research scientists than than Engineers um and a lot of the engineers were a little bit more focused on infrastructure obviously critical to AI work actually happening um but I I think they were seeking to build a little bit more of a model where there is a daily collaboration between engineers and scientists um and so joined in that role um particularly uh working in MLP and conversation like I question answering this kind of uh work this kind of uh work um um um and and yeah I think for me like you know I didn't I never followed the path to the academic research lab right um like I think the The Next Step would have been to Masters your PhD right right right right and uh but instead like what's really excited about machine learning I found this team that was somehow willing to take me on to uh be a part of that and get into it and I I've honestly I've loved it it's been an amazing lab um their ability to still create a ton um their ability to still create a ton of of um autonomy for the researchers uh so ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1809, "maxCueIdx": 1849},
    },
    {
        "content": "2 part of that and get into it and I I've honestly I've loved it it's been an amazing lab um their ability to still create a ton um their ability to still create a ton of of um autonomy for the researchers uh so that they can really like carefully choose the problems that they're working on there's like the right problems to push and save their Nai forward and still being held accountable for doing that right um but like having the freedom to to really like carefully make those choices themselves and not have everything just pushed top down um well then being able to have a strong engineering Talent working alongside that um has been exciting and yeah you get access to enormous Human Resources as well as compute resources of course academics probably wouldn't have access to super cool and then you're directly to super cool and then you're directly tied tied um in a way that I wasn't even aware of before we began this conversation today you are directly tied to real world applications even in the relatively short term unlike an academic might be yeah exactly there there is always the pull to try and find uh a way to actually apply your research to a real world application within the company if you're working on something that feels appropriate to that um there's definitely you know there's some research that is super long term um and to be honest",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1843, "maxCueIdx": 1882},
    },
    {
        "content": " to try and find uh a way to actually apply your research to a real world application within the company if you're working on something that feels appropriate to that um there's definitely you know there's some research that is super long term um and to be honest I actually have not had any impact uh on that specific product the entire time I've been working there uh myself um I think my next project may be but um the yeah not yet um but plenty of my colleagues have um and I think it is a rewarding opportunity and um it kind of obviously it like way further validates your research if it actually is uh helpful to to a product and sound yeah it sounds like it's just a matter of time especially with something like this Cicero project so how does somebody become an AI research manager like you have in a big tech company and related question why have you decided to pursue a masters now in computer science despite getting all of this valuable Real World experience it seems like the work you've been doing over the last year since your undergrad you know now coming on eight years at meta doing research you've surely learned a ton that you would have done in a master's or PhD but you have you are formally pursuing now you're nearing the end of a master's in computer science at NYU so there's two different parts of this question I don't know which you want to tackle first but like ID: ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1876, "maxCueIdx": 1913},
    },
    {
        "content": " you would have done in a master's or PhD but you have you are formally pursuing now you're nearing the end of a master's in computer science at NYU so there's two different parts of this question I don't know which you want to tackle first but like yeah I can start with the major question yeah I can start with the major question so so um I think for me I really enjoyed the opportunity to shift my focus a little bit from just like how to get things to succeed technically and and focus a little bit more on how to help people to succeed um and like I think there's always especially especially in an environment that is uh giving so much autonomy to people um but still needs to hold people accountable for making research progress um I think there's there can almost be a little bit of a trick to like how do you do that well and like how do you show the work that you're doing is impactful how do you even like structure your work in a way that like you can uh describe well how what you're doing is making advancements and things like this and I think uh uh right like rightly rewarding the people for their for their good work but like that takes a little bit of narrative too and I think sometimes think sometimes um um I think I enjoyed like that part of the process helping people to be successful and that helping the people to grow ID",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1908, "maxCueIdx": 1946},
    },
    {
        "content": ": 1939 for their good work but like that takes a little bit of narrative too and I think sometimes think sometimes um um I think I enjoyed like that part of the process helping people to be successful and that helping the people to grow their careers helping people to like make connections with other colleagues who are working in similar space um spending a bit more of my effort like even tracking what my colleagues were doing rather than like focused on what I was implementing um working with more different types of roles within the company and then I think I necessarily would get to do if I was just uh doing engineering work um and I think in a lot of ways got to be exposed to a lot broader set of research projects and supporting engineers in different domains and uh different parts of the world like I was able to learn a lot more I think um in a broad sense than they would have uh focused directly on their research engineering work engineering work um um love doing research engineering work uh when I find a chance to do a little bit but these days that's not that much um but yeah a different career path like a lot more focused on the people than on the technical side and then that makes the second part of my question kind of even more interesting which is so if in this research manager role you're shifting a decent proportion of your attention towards helping other people ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1940, "maxCueIdx": 1979},
    },
    {
        "content": " a lot more focused on the people than on the technical side and then that makes the second part of my question kind of even more interesting which is so if in this research manager role you're shifting a decent proportion of your attention towards helping other people succeed as opposed to the technical challenges why do a masters in computer science instead of like I don't know like management yeah I mean I think the I think I felt like there was still room for me to grow technically um that was hard to do alongside the people work fully um even just the first time I trained a convolutional network was actually in the computer revision class at NYU and not in my work okay and so having that gave me a little bit more like depth in other areas of computer of computer science and specifically machine learning that I wasn't really going to dig into um I think it's also giving more uh engineering depth outside of machine learning like um this semester I am doing classes and uh distributed computation and multi-core computation um so kind of like core engineering topics that I haven't had as much of a chance to really dig into but still uh are critical topics for like working in with a lot of data working efficiently with uh the compute machines that you with uh the compute machines that you have have have um um and so and I",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 1973, "maxCueIdx": 2013},
    },
    {
        "content": " to really dig into but still uh are critical topics for like working in with a lot of data working efficiently with uh the compute machines that you with uh the compute machines that you have have have um um and so and I think like technical managers can make other managers um so I think making sure that I'm still like technically honed and like can really understand what my reports are doing and why they're doing it and like help to counsel them in the right direction and like makes me a better manager and so um I kind of wanted to make sure that yeah so I think that's all of the yeah so I think that's all of the reasons reasons reasons um um me yeah and those are great reasons so then uh for our listeners a question that I'd love to ask our guests and since you are a technical manager you'll be able to answer this is what kinds of software tools do you use regularly uh day to day day to day yeah yeah um so I'm I'm mindful of the episode that you just had that you just had  um um with Keith I think it was um yeah Keith McCormick yeah and kind of talking about how uh you guys spent some time talking about uh no uh or low code time talking about uh no uh",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 2006, "maxCueIdx": 2048},
    },
    {
        "content": "that you just had  um um with Keith I think it was um yeah Keith McCormick yeah and kind of talking about how uh you guys spent some time talking about uh no uh or low code time talking about uh no uh or low code um um and I don't disagree with everything with anything uh the two of you said with anything uh the two of you said yeah yeah yeah um um that being said I think we we definitely fall into the like cool guys camp where um we're really like full code like there's very little automated tooling we're we're like very Bare Bones in a lot of what we're using um I mean we're using pytorch um and then apart from that like it's up to individual researchers sometimes they're they're using uh like a little bit of flavor on top of my torch like pie torch lightning or something like pie torch lightning or something like this this um there's like of course other libraries and machine learning that we'll we'll pull from um but there's there's not much on top of that uh we have some things like slurm we use for scheduling jobs right but like uh other like data analysis tools like it's there's not that much there uh it's a lot of like custom pie torch because I think in the research something we really want to ID:",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 2041, "maxCueIdx": 2081},
    },
    {
        "content": " things like slurm we use for scheduling jobs right but like uh other like data analysis tools like it's there's not that much there uh it's a lot of like custom pie torch because I think in the research something we really want to have control over every single aspect of what's Happening um and the parts that are abstracted away and more anime tool which can be actually quite good to abstract away because uh like you point out like you know it's easy to introduce mistakes on accident in those parts um and if you don't do this very carefully then uh your results May literally mean nothing um and those things can make you able to explore complex data in a much quicker explore complex data in a much quicker way way um I think for us it's like we may want to even be changing those pieces um and so like it has to be very much in our so like it has to be very much in our control control but so you're using a bit of the pie torch Library so it assumes that kind of the lingua Franca like in much of AI and data science is python absolutely yeah um it's close to 100 python every once in a while somebody will like dig under the hood with something in two plus circuita uh to get better performance um but uh yeah well awesome Alex this has been an amazing conversation I've thoroughly enjoyed it and we've covered ID",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 2075, "maxCueIdx": 2112},
    },
    {
        "content": " it's close to 100 python every once in a while somebody will like dig under the hood with something in two plus circuita uh to get better performance um but uh yeah well awesome Alex this has been an amazing conversation I've thoroughly enjoyed it and we've covered so much ground I am a much uh wiser AI practitioner having gone through this conversation with you no doubt lots of audience members out there enjoyed it a lot as well but all good things must come to an end uh and so uh you get to my final questions now the penultimate one is do you have a book recommendation for us yeah a lot of the books I've been reading are textbooks and I don't necessarily recommend those um but I the one I enjoyed most recently uh was Starship Troopers uh I spent like a full people we we can just diving into Starship Troopers read the book watched uh the movies and played through the whole Campaign which was on uh for the video game which was on sale on team uh and just like got into it so that was quite fun and that's my recommendation nice uh and then how should people follow you you're a deep researcher so maybe you know you're not posting on LinkedIn every day like someone like me is so maybe it's like Google Scholar yeah you um you can definitely I'm happy to take pings on LinkedIn or Twitter but I do not spend that much time posting on them Google Scholar it definitely is the most up-to-date ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 2107, "maxCueIdx": 2142},
    },
    {
        "content": " 2136 LinkedIn every day like someone like me is so maybe it's like Google Scholar yeah you um you can definitely I'm happy to take pings on LinkedIn or Twitter but I do not spend that much time posting on them Google Scholar it definitely is the most up-to-date um yeah not a huge online presence but nice uh very cool Alex thank you so much for coming downtown recording with me in person and making this amazing episode on AI research particularly the Cicero algorithm congrats again huge accomplishment and yeah hopefully we can have you on again in a couple years when you have another landmark AI paper to share with us thanks Sunshine appreciate share with us thanks Sunshine appreciate it what an episode and an honor to be able to hear about these state-of-the-art AI research right from the horse's mouth in today's episode Alex filled Us in on why meta invests in fundamental AI research how diplomacy Blends risk and poker to create a game that that is suspected it might take 10 years to master but they build Cicero to perform in the top decile at diplomacy in just three years Alex then detailed how the Cicero algorithm Works including its most important sub modules and the encoder decoder Transformer architecture that is involved in its natural language understanding and generation he talked about how low-level python is the lingua Franca of AI research with medicine ubiquitous pythors Library playing a key role and he talked about",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 2137, "maxCueIdx": 2174},
    },
    {
        "content": " and the encoder decoder Transformer architecture that is involved in its natural language understanding and generation he talked about how low-level python is the lingua Franca of AI research with medicine ubiquitous pythors Library playing a key role and he talked about how Cicero could prove useful in the metaverse as well as real world applications where actionable strategic and highly targeted natural language conversation is desired as always you can get all the show notes including the transcript for this episode the video recording any materials mentioned on the show The URLs for Alex's social media profiles as well as my own social media profiles at Super data science.com 663 that's super data science.com 663 if you enjoyed this episode I'd greatly appreciate it if you left a review on your favorite podcasting app or on the super data science YouTube channel and of course subscribe if you haven't already I also encourage you to let me know your thoughts on this episode directly by following me on LinkedIn or Twitter and then tagging me in a post about it your feedback is invaluable for helping us shape future episodes of the show thanks to my colleagues at nebula for supporting me while I create content like this super data science podcast for you and thanks of course to Ivana Mario Natalie Serge Silvia Zara and KIRO on the super data science team for producing another extraordinary episode for us today for enabling that super ",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 2168, "maxCueIdx": 2205},
    },
    {
        "content": "ing me while I create content like this super data science podcast for you and thanks of course to Ivana Mario Natalie Serge Silvia Zara and KIRO on the super data science team for producing another extraordinary episode for us today for enabling that super team to create this free podcast for you we are deeply grateful to our sponsors whom I've hand selected as partners because I expect their products to be genuinely of interest to you please consider supporting this free show by checking out our sponsors links which you can find in the show notes and if you yourself are interested in sponsoring an episode you can get the details on how by making your way to johncrone.com podcast and thanks of course to you for listening it's because you listen that I'm here until next time my friend keep on rocking it out there and I'm looking forward to enjoying another round of the super data science podcast with you very soon podcast with you very soon foreign",
        "metadata": {"videoId": "ZhGadgiHFCg", "minCueIdx": 2200, "maxCueIdx": 2224},
    },
    {
        "content": " thank you welcome to manifold my guest today is Sahel lavignia he is the founder of gumroad an e-commerce platform and also the author of The minimalist entrepreneur sahil welcome to the podcast thanks for having me excited to help you talking to having me excited to help you talking to you you I am as well because I've listened to you in some other contexts and read your book and being an old guy who's founded multiple startups I'm always interested in hearing from the younger generation one of the things that I think impressed me the most about your story was that I think you got funded by Kleiner when you were 19 years old for an a round yeah which is just unbelievable I'd like to start with your early life I think you mentioned that you grew up in Singapore and attended USC maybe you can just tell us what your background is totally so my parents grew up in India moved to the U.S in the late 70s early 80s I was born on Long Island when I was five or four we moved abroad my dad got into they came to the US for their their master's degrees went to Baruch College and then my dad got a job in banking and we moved to Singapore which is where I primarily grew up grew up and and when I was yeah 17 graduated high school moved back to the U.S in 2010 and for computer science degree and only lasted four months before I dropped out and ended up moving to the Bay Area ID: ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 0, "maxCueIdx": 41},
    },
    {
        "content": ": 34 grew up grew up and and when I was yeah 17 graduated high school moved back to the U.S in 2010 and for computer science degree and only lasted four months before I dropped out and ended up moving to the Bay Area joining a startup called Pinterest working there building pictures for iPhone starting my own company after that and yeah it was pretty crazy because you know in basically in a year and a half I went from like yeah graduating high school to raising a series a from Kleiner which was was not on my yearbook goals or anything you know incredible now I just have a couple questions so you know the the what you told me answers one question I had is that which is that you know you had a very American you have a very American accent and I thought wow kid who grows up in Singapore that's a little bit unusual but you've answered my question there when when you went off to SC were you thinking you were gonna just complete the program you were not thinking at all that you wanted to be an entrepreneur right away were you I don't think I was thinking about it you know I feel like I spent a lot of time trying to figure out like what did what was I thinking at all sorts of points in my in my past and I think it's so tempting to insert your present self and all of your existing sort of biases and and you know knowledge that you have but I think at the time I just wanted to I think my goal was to get a job at Google I",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 35, "maxCueIdx": 74},
    },
    {
        "content": " 68 thinking at all sorts of points in my in my past and I think it's so tempting to insert your present self and all of your existing sort of biases and and you know knowledge that you have but I think at the time I just wanted to I think my goal was to get a job at Google I'm pretty sure that was like the the the the the sort of you know the ideal the reach right where if if getting into Stanford was the reach and I I failed to do that and got into USC that the goal was to you know to get to get a job as a software engineer at Google anyway right I did not expect to drop out I don't think I think I was really there to like graduate you know do a couple internships perhaps and then and then you know eventually I did I think want to start a company I felt like that was you know making apps independently was was something I was already doing so I think that was on the roadmap but I felt like you needed more information more knowledge in order to actually do it well and succeed and so yeah I don't think it was on the on the table and just like frankly I think when like when I joined Pinterest I don't think starting a company was on the table either I think these these things kind of happen you know pseudo randomly yeah I wanted to ask you which was the bigger leap leaving college for Pinterest or leaving Pinterest to start that's a good question that no one has ever asked me so I don't know if I've ever considered that before well just ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 69, "maxCueIdx": 108},
    },
    {
        "content": " of happen you know pseudo randomly yeah I wanted to ask you which was the bigger leap leaving college for Pinterest or leaving Pinterest to start that's a good question that no one has ever asked me so I don't know if I've ever considered that before well just think about how I felt at those various yeah yeah that's true I mean I do think that like leaving USC was probably the bigger leap and statistically too you know I know very very few even though the stories are popular everyone knows The College Dropout stories but there's not very many examples I have of people actually doing it and so I think that that is probably like the the sort of thing that was harder to do it was the thing that you know I had to do on my own there was nobody around me that was agreeing with my decision I was the only person that thought this was a good idea even Pinterest was like are you sure you want to do this which is you know kind of kind of crazy in hindsight because I feel like we tell people all the time that this is a great idea and I think it is and and yet you know everyone was against it so yeah I think that was the big decision I think that was the one that is the one that you know you kind of have to face your parents and say Hey you know that college degree that you know you moved halfway around the world for me to get 30 years later is not happening at least not in the time frame that that you kind of expected so I think that was the bigger the bigger leap",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 101, "maxCueIdx": 140},
    },
    {
        "content": " to face your parents and say Hey you know that college degree that you know you moved halfway around the world for me to get 30 years later is not happening at least not in the time frame that that you kind of expected so I think that was the bigger the bigger leap once once you're kind of disconnected it's kind of like the umbilical cord is severed you're in San Francisco you're in the Bay Area you know there's like people going to burning man like you know you start your openness I think starts to go up you know as a product of your of your environment a little bit so yeah I think I think leaving leaving College was definitely I think the bigger the bigger one yeah I could kind of imagine that you know if your dad was a financier and you know doing International banking or working in Singapore you might have this attitude which a lot of financiers have is that you know the Grass Is Always greeners they always think the startup guys are the ones who have it easy and they're going to get the quick billions so maybe I thought this is a reasonable risk son yeah go ahead yeah well I've thought about that a little bit right where I was you know growing up in Singapore going to an international school you know content warning for privilege but you know like I did have that feeling of like wow I really don't want to go into Finance which was the default path because everybody and their parents were kind of you know doing that already and I didn't it didn't seem fun ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 134, "maxCueIdx": 172},
    },
    {
        "content": " 166 school you know content warning for privilege but you know like I did have that feeling of like wow I really don't want to go into Finance which was the default path because everybody and their parents were kind of you know doing that already and I didn't it didn't seem fun you know it did seem fun like just being on a plane you know three or four days a week and and just doing you know they just didn't seem appealing like I still never really know what what what the value ad is necessarily you know sometimes like talking to folks in in that industry but you know and so yeah I I kind of agree with you like you know I think for me it was like maybe software and Tech will be will be different but when I apply that it it it seems like well that should have been the same decision that other people would have made too right I was not the only person who grew up in that environment and would have felt the grass is only Greener thing but yet most of the folks that I know did go into Finance right so why why is that like why why me you know and I don't yeah I don't really have a good answer I think for that yeah my my experience in you know I because I come from this weird background I'm a physicist but I've started multiple tech companies and most of my friends from physics work in finance hedge funds and things like this the way I would describe it is Finance is still the best risk-adjusted route to getting to a net worth of 10 or 20 million by the time you're saying in ID: ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 167, "maxCueIdx": 204},
    },
    {
        "content": " multiple tech companies and most of my friends from physics work in finance hedge funds and things like this the way I would describe it is Finance is still the best risk-adjusted route to getting to a net worth of 10 or 20 million by the time you're saying in their 40s and maybe not the fastest Finance could I mean the startups can be faster but I know very few financiers who love their jobs I mean they do their jobs but they're doing their jobs to to make the coin whereas a lot of startup guys love their jobs yeah that's true and that that was always super important to me I remember the first time I hung out with my high school friends after you know a couple years of college I had you know was working at Pinterest I think at the time and they were still in college and you know some some of them were maybe doing internships and yeah I was like the only person there that loved what they did for work you know or or like had that expectation even that I should and it was it was it was definitely kind of jarring to be like no I think yeah I'm probably optimizing like Risk adjusted yet you know joining Pinterest at the time didn't look maybe the smartest thing doing Gum Road certainly for many years did not look like the smartest thing after Pinterest did you know and but yeah I just I don't know what the you know what the sort of the Big Five personality that aligned with that is but I just I don't have a lot of ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 198, "maxCueIdx": 238},
    },
    {
        "content": " 231 certainly for many years did not look like the smartest thing after Pinterest did you know and but yeah I just I don't know what the you know what the sort of the Big Five personality that aligned with that is but I just I don't have a lot of patience I guess for you know people I don't like and and and processes I don't like in the finance industry and frankly the secondary you know education system generally is like full of that so I now it feels like startups were kind of an inevitability for me you know but yeah it's kind of the story that I tell myself right you can't help it to a myself right you can't help it to a degree degree I think you know from an EVO psych perspective if you're a you know open to experience and the kind of person who's some something of a leader and creative you know leading a small team that you hand-picked at the age of 20 and not having a boss I mean you have a board but you don't really have a boss that's a peak experience a lot of people will go through their whole lives and never be able to do that it's true yeah I mean it's it's kind of crazy because I I grew up in you know I feel like I grew up in San Francisco you know culturally even though I didn't because I was on Twitter so much I think as a kid but now I live in Oregon and it is interesting to like you know talk to the average 19 year old you know talk to the average 19 year old here here ID: ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 232, "maxCueIdx": 268},
    },
    {
        "content": ": 262 San Francisco you know culturally even though I didn't because I was on Twitter so much I think as a kid but now I live in Oregon and it is interesting to like you know talk to the average 19 year old you know talk to the average 19 year old here here here and and feeling like oh my gosh like I really feeling like oh my gosh like I really didn't didn't really did not appreciate like how unique my experience was you know being able to raise seven million dollars at 19. it's just like yeah it doesn't happen very often but for you know when you when you do it and then there you know three other people who've done it you know because you had dinner yesterday you know in Soma yeah you just you tend to think that it's a lot more it's a lot more normal than it than it really is you know one of the reasons I want interviews I I as I read your article on medium and we'll talk a little bit about this I know the listener may not be understand what we're talking about just in the second but when I read some of the stuff you had written and listened to your talks I realized you're a super grounded guy even though in a way your experience thus far in your life is easily one in a million right it's not I don't think there's more than one in a million people who actually have gotten to experience what you have over the last you know whatever tennis years so super awesome that you're humble still ID",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 263, "maxCueIdx": 301},
    },
    {
        "content": " your experience thus far in your life is easily one in a million right it's not I don't think there's more than one in a million people who actually have gotten to experience what you have over the last you know whatever tennis years so super awesome that you're humble still about it and you have a very developed humble philosophy because what happened with with gumrah let me just jump in there and just get some of the basic facts which I learned from I think from your article or from listening to your talks just out there for the audience so you founded gumroad which is an e-commerce platform which allows I would say you were going to say this better than me but roughly allows creators of digital things or services to monetize them by by directly selling them on the platform is that fair exactly yeah so we started in 2011 and I think that the kind of key Insight you know nowadays lots of ways to sell content on the internet substack patreon gumro teachable Etc and all awesome products but I think at the time people people started to build basically they started to build audiences before they were building websites which is very strange because you know not too long ago you needed a website to have any presence on the internet and so that was kind of the the inside the Epiphany was like wait what what happens when you have 100 000 followers and no website right all of a sudden you have like basically the hard part about building a business but not the easy part about building a business",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 295, "maxCueIdx": 335},
    },
    {
        "content": " on the internet and so that was kind of the the inside the Epiphany was like wait what what happens when you have 100 000 followers and no website right all of a sudden you have like basically the hard part about building a business but not the easy part about building a business and that just felt kind of you know the easy part felt too hard in a way for me and and so yeah that was kind of the the Insight was like we just want to be this the simplest way for anyone who wants to simplest way for anyone who wants to sell sell you know music or a PDF or a set of PDFs or a zip file or any any any binary kind of object that you you can make on your computer we want to make it really easy for them to just make a dollar on the internet and I think even even I didn't really realize why I think I picked gumroad specifically of all the things I could have worked on because I had a bunch of side projects but I think I picked it because it was it was very reminiscent of of the App Store and you know growing up in Singapore accepting payments online was basically doing freelance and having a PayPal account and then trying to use that PayPal account to like buy other things on the internet that you know accepted PayPal and the App Store was the first time that I could like become an entrepreneur because I could actually sell things on the internet and then Apple for their 30 you know would would take care of everything else right legal and tax and I would just get a check you",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 329, "maxCueIdx": 367},
    },
    {
        "content": "internet that you know accepted PayPal and the App Store was the first time that I could like become an entrepreneur because I could actually sell things on the internet and then Apple for their 30 you know would would take care of everything else right legal and tax and I would just get a check you know three months later you know with with my 300 bucks or whatever right and I felt like oh yeah like this the internet is is for this you know it's for Connecting People of course but once people get connected you know payments is is is a big is going to be a big part and so that's kind of and we we still like to think that we're like the simplest fastest way to get set up you know if you want to sell something on the Internet and you've never done that before you don't have a website or or any presence beside maybe a Twitter account or an Instagram account or something like that once you connect next you have to be able to transact I think so I think I think that you know that might be sort of a lesson from human history or something where yeah you know it's sort of speech and then money you know and and money money is sort of a form of of speech a form of communication that you know took a lot longer to develop conceptually I think but yeah to me it's sort of it's sort of like the internet without you know peer-to-peer payments you know it would be like Society you know without without money right like it would not really function super well it",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 361, "maxCueIdx": 401},
    },
    {
        "content": " longer to develop conceptually I think but yeah to me it's sort of it's sort of like the internet without you know peer-to-peer payments you know it would be like Society you know without without money right like it would not really function super well it would be a lot right so so you had left College you were working at Pinterest but you're still doing some side projects then you had a inspiration moment where you conceived of you know this building this functionality so people could transact and then you set about raising money and you were able to raise an a round of seven or eight million from Kleiner Perkins which for the audience is one of the top one of the most prestigious funds in Silicon Valley could you just talk about that fundraising process like at what point did you decide you go from okay the built this project it's going to be a company now I gotta go raise and 19 year old kid raises an a round from the top fund yeah so I was at Pinterest this is April so I'd been there for maybe four or five months and this was you know like I dreamed about living in Palo Alto okay like one does when they're 16 years old but I was finally here and so I you know I was I was spending weekends building stuff hacking with other people on stuff meeting people and so yeah I just had like just like so many just different side project ideas and gumroad was the first one that I I sort of worked on two weekends in a row and so I think that was probably",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 394, "maxCueIdx": 434},
    },
    {
        "content": " was I was spending weekends building stuff hacking with other people on stuff meeting people and so yeah I just had like just like so many just different side project ideas and gumroad was the first one that I I sort of worked on two weekends in a row and so I think that was probably the first signal that there was something kind of more meaningful here where I kind of wanted to work on it to work on it instead of just to learn something new or to build something generally and then really what happened was like I started getting emails from people basically saying like when are you starting a company you know just presuming that I was a founder or had presuming that I was a founder or had that that aspiration or desire to and I remember getting an email from I think it was Craig Shapiro from collaborative fund who ended up being the first investor in gumroad he saw gumroad on Hacker News I had titled it my weekend project and yeah he sent me an email he basically said hey if you ever decide to start a said hey if you ever decide to start a company company you know I'll give you 10 grand and I think I replied saying what if I started an LLC you know like I have no interest in like raising Venture I'm happy at Pinterest but you know if I spun up like an LLC on LegalZoom you know would you take a million dollar valuation is what I said and I think the reason I said that was because I wanted to Angel invest and Angel Investing requires a net worth of a million and so I was",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 428, "maxCueIdx": 467},
    },
    {
        "content": " happy at Pinterest but you know if I spun up like an LLC on LegalZoom you know would you take a million dollar valuation is what I said and I think the reason I said that was because I wanted to Angel invest and Angel Investing requires a net worth of a million and so I was like oh if I can like start you know I didn't realize at the time that this doesn't matter at all no one checks this information but I thought it was it was almost like a hack in order to start Angel Investing and really just like deepen my you know my tentacles in Silicon Valley as quickly as feasibly possible I thought Angel Investing was the best way to do that and he said yes he said yeah if you spin out you know if you send me a bank account and so I created you know went to LegalZoom spent 300 bucks created little big things LLC and then you know took his 10 grand did nothing with it really I got you know two or three four more of those emails and and you know yeah I sort of realized like wait a second like I could actually be a Founder you know and so yeah you know eventually that virus kind of got to me and I said you know why would I even though Pinterest was awesome you know why like I the the the the experience of being a Founder being able to experience that as you mentioned at such a young age effectively skipping like 10 years of career growth being able to raise it you know and the people wanting to give me it you know to write money into the startup were really great ID: ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 461, "maxCueIdx": 499},
    },
    {
        "content": " experience of being a Founder being able to experience that as you mentioned at such a young age effectively skipping like 10 years of career growth being able to raise it you know and the people wanting to give me it you know to write money into the startup were really great people there were people that if I had done every single thing right I didn't dream of them ever being on my cap table right people like Max lefkin the co-founder of PayPal who I had read about you know but didn't expect to ever meet and so when I was able to do that at 18 or 19 it was yeah it was kind of a no-brainer in a sense where I was like why would how could I say no to something like this to be honest I think foreshadows some of my problem which is like so or you know generally it may be some problems is what Society is like you kind of just go for it because so few people do get that shot you sometimes don't actually question like should I have taken the Venture Capital should I have committed for you know that long but I think at the time it was like wow I really can sort of you know I think of it almost like uh like climbing or something where you can fall but you can only fall so far back and once you raise a series a from Kleiner like that's you know forever in a way right and so if I if even if I failed even you know it's sort of gonna anchor me to to being able to do something that I think will will sort of have Perpetual value and so I think that ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 493, "maxCueIdx": 530},
    },
    {
        "content": " once you raise a series a from Kleiner like that's you know forever in a way right and so if I if even if I failed even you know it's sort of gonna anchor me to to being able to do something that I think will will sort of have Perpetual value and so I think that was that was also part of I think why why I did that but I think along the way I was I was very clear with people and I think I still am about like look this is who I am like I like to build stuff this money is going to allow me to build stuff without having to think about making money so that's primarily why I'm doing it you know if this thing starts to work you know we'll see what happens and I think as long as you you know you do you have the skills to actually build what you say you want to build the sales pitch is not actually that complicated I think what happens when people say that you know they struggle to raise money is often that they don't actually have the skills to raise money or or to actually build the thing which is why they're raising money so they can go hire people to build a thing and that that's tough that often you know leads to a no right because VCS don't want to feel needed they want you know they want to feel like they are not needed and and that's when they really want to participate so I think I was able to give it to them right a young founder who knows how to code can design a little bit is not reliant on anybody else you know young also means you know my cost of living ID",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 525, "maxCueIdx": 561},
    },
    {
        "content": " 555 like they are not needed and and that's when they really want to participate so I think I was able to give it to them right a young founder who knows how to code can design a little bit is not reliant on anybody else you know young also means you know my cost of living was you know super low and and things like that so I think I was like uh yeah like I think in hindsight you know I'm the founder that I now look for right which I now being in my position as an investor I realize like holy crap like I'm much more rare than I thought like trying to find this kind of person I thought I would start start a fund and I would go find hundreds of me like you know all around the world you know there's this quote you know Talent is evenly distributed but opportunity is not and so you know with covet and remote like I I think I think people actually you know and this is a lot of my growth in the last year I think has been about like why why do I continue to be surprised you know you know when when the data doesn't seem to line up with that so yeah anyway something I think a lot about right I I'd say Talent is rare and I would say you're kind of a unique Triple Threat So you you're able to actually do the coding and build the product yourself but you're also super articulate and you have leadership qualities and those are roughly independent things right so sometimes the CTO yeah can hold stuff or first engineer can build stuff but he can't articulate the",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 556, "maxCueIdx": 594},
    },
    {
        "content": " you you're able to actually do the coding and build the product yourself but you're also super articulate and you have leadership qualities and those are roughly independent things right so sometimes the CTO yeah can hold stuff or first engineer can build stuff but he can't articulate the business plan very well and maybe he doesn't have leadership qualities and you could Shuffle around like the CEO usually can't build anything right so yeah so yeah yeah I think you have three very independent qualities that are unusual yeah I would say like most people who I know who've raised you know that that age do it with a team and I yep I did it completely by myself I had no team no co-founders I didn't know a single person in Silicon Valley you know less than a year before that but were you at that age were you as articulate as you are now and is able to talk to you know a super powerful venture capitalist or did that was there a little bit of a learning curve for you I would I would love to think that I'm better now but I honestly sometimes I go back to those emails that I wrote and I'm like holy crap I was way more articulate in a in in this just and and to be honest like I again I sort of feel similarly today where like people send me emails and they're like friends of mine and they say Hey sahil you know like just like there's just so much fluff in in human discourse and for whatever reason I just never signed up for that and or try you know try not to ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 587, "maxCueIdx": 626},
    },
    {
        "content": " feel similarly today where like people send me emails and they're like friends of mine and they say Hey sahil you know like just like there's just so much fluff in in human discourse and for whatever reason I just never signed up for that and or try you know try not to and and so I've all I look back at these emails and I'm like wow I was emailing emails and I'm like wow I was emailing like like Mark Cuban like the an email with just the word no in it you know or whatever like I I just have and and to be honest I'll tell you where that comes from because I actually have unpacked this quite a bit and maybe it answers for that like humble grounded stuff too a little bit which is all men are created equal and I think that has just my parents ingrained that into me so deeply which I think is part part of why like you know now the conversation about privilege is quite prevalent but I like didn't know that word even though I certainly grew up you know in a sort of a top you know sort of a quartile family in Singapore blah blah all that kind of stuff but like yeah I just think they never would I ever expected that I was better smarter harder working like than anybody else I was just completely in the middle of the bell curve on everything and even when I got to you know even like even after even you know I think I had a conversation with like a friend that I would consider a mentor and this is like 20 20 and he was like look at",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 620, "maxCueIdx": 659},
    },
    {
        "content": "652 was just completely in the middle of the bell curve on everything and even when I got to you know even like even after even you know I think I had a conversation with like a friend that I would consider a mentor and this is like 20 20 and he was like look at your track record like you cannot you have to stop thinking that you're in the middle of the bell curve and I'm like well I don't know if I can like I feel like that's so like it's almost a religion to me of like no that's like that's what I signed up for you know that's why I'm here and so anyway I forget exactly why I bring that up but yeah I just I've always felt like part part of the reason I think I can communicate with people articulately is because I think of them like myself you know and I'm gonna treat you like I would treat myself and I treat myself decently well and a lot of people don't a lot of people talk up they talk down you know they they change the way they speak no matter who they talk to and I'm sure I do that to some degree too like telling my grandma's a little bit different than talking to like you know somebody else talking to like you know somebody else but but I think at the end of the day like I really think just like I treat every I try to treat everybody like an equal and so max leftgen is just like hey it's so cool that you built PayPal like what the hell you know that's awesome and that's just like that's just",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 653, "maxCueIdx": 690},
    },
    {
        "content": " I think at the end of the day like I really think just like I treat every I try to treat everybody like an equal and so max leftgen is just like hey it's so cool that you built PayPal like what the hell you know that's awesome and that's just like that's just like how I talk to everybody you know like if I met Obama I would you know I'd be like wow that you're president like that's kind of nuts at the end of the day everyone knows everyone else is freaking out in their head right like like the first night you sleep in the White House like no one is no one thinks that I hope and no one is like oh yeah finally you know my day has come you know like everyone should be freaking out like life is crazy life is super weird but yeah anyway I really think that's important you know even when I you know a big moment for me was like hiring people when I was 19 you know I would hire 40 year olds managing a team you know and like yeah I was just like they're that forced me to consider that you know like I have to treat everybody like an equal because if they don't treat me like an equal I'm gonna lose you know we have to establish this early here culturally so yeah I've always been a big fan of that I think Tech generally is pretty good about that that I guess the word for it is meritocracy right which is like the idea sort of the best idea should win the most competent person out whatever skills should sort of be in charge of ID:",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 684, "maxCueIdx": 722},
    },
    {
        "content": " I've always been a big fan of that I think Tech generally is pretty good about that that I guess the word for it is meritocracy right which is like the idea sort of the best idea should win the most competent person out whatever skills should sort of be in charge of that but now I think meritocracy sometimes I think has a negative slant to it for some reason yeah I can go too far but it's it is refreshing that Silicon Valley still has as a kind of core value meritocracy I want to go through a little bit of just the mechanics the numbers of how it worked out for you for gumroad and you've talked about this elsewhere so let me let me just try to summarize it for my audience and then you you tell me what I get wrong so you raise an a round which was seven or eight million and started building the company but the growth while healthy was not what Venture capitalists really look for if they're trying to say build a unicorn and so when it came time to raise your B round you felt upon advice from others that you know might be difficult because you're at that point you had enough of a track record maybe a year or two had gone by where the growth really wasn't where the VCS really would want it to be and so for your beat route you took a couple million more but the investors again it was maybe led by Kleiner took a 4X preference which for the audience means that if the company is sold they're guaranteed to recover the investors 4X on that amount that say",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 716, "maxCueIdx": 755},
    },
    {
        "content": " to be and so for your beat route you took a couple million more but the investors again it was maybe led by Kleiner took a 4X preference which for the audience means that if the company is sold they're guaranteed to recover the investors 4X on that amount that say 2 million that they put in in the B round so that creates a hurdle if you're tracking this seven or eight million in the a round and then another eight when you include the preference so sahil had a a hurdle of 16 million or so which the preferred shares the investors in the company were entitled to before he would see a penny if he were to sell the company are those numbers about right exactly yeah we had about 16 and a half in in preferences and I think at the time gumrad was maybe at a million and a half or two million in in total sort of Revenue and so and and barely making profits on that because you know half the half the fees kind of went to stripe and and PayPal so yeah it was it was like yeah I I have no idea when that you know when this you know I think we we had an acquisition offer for about a million bucks from somebody so maybe you know a path to be you know selling for 16 million but then you know yeah all that money goes right back to investors and so yeah it was not it was not fun to be in that in that tunnel so at that point you decided though you weren't going to try to wind up the company or liquidated you were going to try to continue",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 749, "maxCueIdx": 787},
    },
    {
        "content": " then you know yeah all that money goes right back to investors and so yeah it was not it was not fun to be in that in that tunnel so at that point you decided though you weren't going to try to wind up the company or liquidated you were going to try to continue running it and for that you know in order to do that you had to lay off a lot of your team exactly yeah I think this is also like one of those decisions that is not taken or one of the paths that that's not taken super frequently most of the time folks will either sell the business you know VCS invest in lots of companies so VCS will often help do this they'll help sort of sell a a fledgling company into a more mature company or you you shut down you return the you know money to investors investors come right back and say here's some more money if you want it to go start a new company because that's kind of really what they want right is they want more bets that they can take and if you think you know if they think you're a great founder working on a b company like the you know they kind of want you to start again and yeah I just said look like at the end of the day like government is it's working it's driving Revenue it's a valuable product to tens of thousands of people like who am I to just turn that off but yeah it's not growing super fast we can't really afford a big team and so yeah the only thing I felt I could do yeah the only thing I felt I could do was was ID",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 781, "maxCueIdx": 818},
    },
    {
        "content": " a valuable product to tens of thousands of people like who am I to just turn that off but yeah it's not growing super fast we can't really afford a big team and so yeah the only thing I felt I could do yeah the only thing I felt I could do was was lean out the staff we went from about 20 people down to three or four eventually just down to me I started hiring only contractors and I basically said I'm gonna run this thing indefinitely right it's going to keep growing presumably it's like nice lovely software it mostly runs itself I just have to have a couple support people someone doing fraud and risk we'll hire you know a contract designer a couple you know a contract designer a couple engineers engineers engineers and and you know TBD right what happens we still have the 16 million dollars in preferences and then everything really changed I think it was December 2017. so this is like two and a half years of just like doing that right and Kleiner emails and says hey you know we were interested in buying basically selling our position back to you for a dollar one dollar and I said you know are there any strings attached and they said nope and I you know I didn't really even ask why to be honest I didn't want to sort of bite the mouth or bite the hand that feeds and so I said yeah it sounds good and they ended up writing off their investment I'm sure they you know got some nice tax write-offs out of it but ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 812, "maxCueIdx": 852},
    },
    {
        "content": " didn't really even ask why to be honest I didn't want to sort of bite the mouth or bite the hand that feeds and so I said yeah it sounds good and they ended up writing off their investment I'm sure they you know got some nice tax write-offs out of it but basically that you know changed the game because basically that preference stack as you mentioned went from 16 and a half down to two and a half I think something like that it drastically you know changed the picture because of that that 4X that they were a part of and then the the original seven million dollars that they that they put in and so all of a sudden literally almost like an overnight deus ex machina moment you know government all of a sudden looked like a valuable company instead of a you know a a basically a a worthless company that was still providing a lot of value to the to the actual people using the the to the actual people using the product product yeah I mean today it sounds like the guys who held on to that whatever that stake was that wasn't kleiners to sell you for a buck those guys could be quite happy I'm guessing Kleiner you know I can think of multiple reasons why they'd want to dispose of the thing because one you know partner time is Super valuable so you don't want to have Partners worrying about some Investments that probably not going to turn out anyway they get a tax deduction as you said and they may have to wind up a fund and actually like issue a p l for that fund",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 846, "maxCueIdx": 885},
    },
    {
        "content": " because one you know partner time is Super valuable so you don't want to have Partners worrying about some Investments that probably not going to turn out anyway they get a tax deduction as you said and they may have to wind up a fund and actually like issue a p l for that fund you know an Roi for that fund so lots of reasons for them to do that it was great for you of course but by persisting you've now built it into a you know it's not a it's not a unicorn but it's a it's a super successful company as far as I understand yeah we're we we did a crowdfunding round in 2021 we raised at 100 million dollar valuation more more importantly where we do about 200 million in gmv for our creators we do about 12 million in Revenue off of that 200 million and we're profitable you know well we're trying to actually work through issuing our first dividend to our investors next year so we'll see how that goes quite unusual thing and another you know that's the kind of the next step on my you know unusual Journey with gumroad is you know doing the boring thing of issuing dividends and seeing if that actually works for us but yeah yeah I want I wanted to ask you about the crowd fundraise but it seems like with your numbers you don't really need it right so the law changed to allow non-accredited investors to participate in Venture and I think the limit which which you hit is five million you could raise five million a year that through that kind of route ID:",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 879, "maxCueIdx": 917},
    },
    {
        "content": "fundraise but it seems like with your numbers you don't really need it right so the law changed to allow non-accredited investors to participate in Venture and I think the limit which which you hit is five million you could raise five million a year that through that kind of route but do you really need the money now it seems like you're you're profitable right yeah I mean we don't we don't we don't need the money and we didn't either I think for us it was about showing people hey this new thing exists a lot of people wanted to invest in gumroad and so you know why not use this tool to allow people to do that we'll sort of be able to hire 10 more people and and build out the product faster than we originally anticipated and you know selling five percent of the company in order to kind of take that bet I think was felt worth it to us and going forward yeah I think I think we're gonna see if we can figure out this dividend thing and if we can the goal is to sort of start returning in you know Capital to investors right like Investments should eventually and yeah we'll we'll see how that we'll see how that goes I I think generally startups don't do that because interest rates have been so low that you know there's just been too much incentive on a sort of evaluation secondary sales IPO basis like it just dividends would never compare right to just selling a small percent of your of the stock that you own and and that I think is you know has changed quite dramatically and we'll see",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 911, "maxCueIdx": 949},
    },
    {
        "content": " low that you know there's just been too much incentive on a sort of evaluation secondary sales IPO basis like it just dividends would never compare right to just selling a small percent of your of the stock that you own and and that I think is you know has changed quite dramatically and we'll see what happens in 2023 but if the interest rates continue to go up you know five percent or more I think people will will start to say hey maybe we should turn these businesses into you know profitable businesses right the it doesn't make sense to to pay 400 000 a year for you know a thousand Engineers just because you can because at the end of the day like they're not actually driving any additional growth right they're just they're just being spent on on on metastock instead of you know solving you know all the problems that we see day to day that software Engineers could make a large impact on right societally so you did that crowd funded raise in 2021 and for one of the startups that I founded that's that's going right now I'm getting a ton of emails from different platforms that do this crowdfunding thing and I honestly I didn't really know much about it until I you know actually answered one of the emails and had a conversation with the guy representing the platform but how do you feel about that as a viable alternative to venture yeah I mean at the at the end of the day historically Venture raising Venture Capital has become so easy operationally right in terms of it doesn",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 943, "maxCueIdx": 983},
    },
    {
        "content": " 976 emails and had a conversation with the guy representing the platform but how do you feel about that as a viable alternative to venture yeah I mean at the at the end of the day historically Venture raising Venture Capital has become so easy operationally right in terms of it doesn't take a lot of time it doesn't take a lot of money they're effectively all standardized documents and interest rates have been so low that yeah people there just hasn't been an issue in terms of raising Capital privately from accredited investors so crowdfunding has has sort of been the the sort of ugly duckling I guess where people generally have a tendency to ask like why are you doing that you know like what's wrong with your business that you can't raise money the the other easier cheaper way from better more famous people or or whatnot and yeah I I I'm but I'm hopeful that over time people will realize that it's not about just raising from professional investors it's about like allowing the average person to have equity in a business right at the end of the day Equity is how people get rich people complain all the time about inequality and diversity equity and inclusion and I just sort of think about well the answer is equity it's in the word you know or phrase like if everyone has equity in Amazon and Tesla guess what those people get rich and should we force people no probably not but how do we encourage more and more people to actually own equity in businesses businesses they work for business",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 977, "maxCueIdx": 1015},
    },
    {
        "content": " in the word you know or phrase like if everyone has equity in Amazon and Tesla guess what those people get rich and should we force people no probably not but how do we encourage more and more people to actually own equity in businesses businesses they work for businesses they can invest in their local coffee shop Etc you know I I think I think that world seems pretty interesting and compelling to me it doesn't seem like a world that you know has tons of lottery tickets turning into billion dollar outcomes but you know in terms of again getting four five six seven ten percent return I think it would lead to a much more stable growth sort of mechanism for society and so yeah I I think it's so new I think I'm hoping that it gets easier to do I'm excited to show people maybe a path from crowdfunding to dividends because that I think is a big question mark generally in Stardust but certainly if you're an average investor and you're like why would I invest in a startup that makes no money you know and pays Engineers a lot like what what this doesn't seem like a good business but Gummer is different right if I say hey you don't actually have to care about what we build who we build how big the team is all you have to care about is free cash flow right and you can decide what your discount rate is just like you would a traditional investment and say hey government's worth 100 million they're issuing 5",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1009, "maxCueIdx": 1045},
    },
    {
        "content": " what we build who we build how big the team is all you have to care about is free cash flow right and you can decide what your discount rate is just like you would a traditional investment and say hey government's worth 100 million they're issuing 5 million dollars a year to their investors you know I want some of that right and then boom the valuation goes to 120 or I don't want that valuation goes to 75 right and so I just think basically that's what I think like that price Discovery like I think there's a lot of value to that to that liquidity to that knowledge and insight and ultimately to like the shared alignment that just very very very very very few people get to participate in right are you in a secondary market so are are your shares actually liquid right now they're not or you know they're technically legally allowed to be liquid so people can sell them to each other and that's allowed and we've you know we've done six figures worth of those transactions in the last six months as people want to buy and want to sell so we kind of do them OTC but there isn't a formal secondary Market which I think is a big opportunity actually I think my guess is in the next five to ten years if gumroad is able to show folks hey dividends work and this and that it probably doesn't make sense to to go list on the NASDAQ but maybe there's a way to build in like you know",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1039, "maxCueIdx": 1075},
    },
    {
        "content": "9 opportunity actually I think my guess is in the next five to ten years if gumroad is able to show folks hey dividends work and this and that it probably doesn't make sense to to go list on the NASDAQ but maybe there's a way to build in like you know a yearly secondary event or you know BuyBacks by the company or or other mechanisms that allow people to exit their position because that will be I think really really important and there may be people are like I don't want dividends you know cash me out and they should be able to to do that one of the one of the platforms that contacted me does actually have a secondary market and I think they they make their money from a I think it's probably something like a three percent transaction fee for trading of the shares oh wow on that secondary more so it's kind of they're kind of building toward all this stuff yeah it's coming and I think you know that's one of the nice things about a a bear Market is people will just get back to building a little bit more and it takes time so it's not going to be evident immediately but I'm sure there's you know a lot of people building a lot of cool stuff right now I wanted to we have about 20 minutes left so I wanted to ship gears to something else which you know is part of the reason why I discovered who you are I actually kind of knew what gumroad was ID: ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1070, "maxCueIdx": 1105},
    },
    {
        "content": "1099 people building a lot of cool stuff right now I wanted to we have about 20 minutes left so I wanted to ship gears to something else which you know is part of the reason why I discovered who you are I actually kind of knew what gumroad was although not really that well um mainly I think because of some podcasts that I listened to you know having you know preferred content for people who subscribe via gumroad or something like this so I knew what you guys were but I didn't really know much about you personally and the way I actually discovered you is that one of the new startups that I'm working on has to do with large language models and trying to focus them on a particular Corpus and try to force them to confine their answers to a particular Corpus and I discovered a I think it was a video of you building something like this based on your book your book The minimalist entrepreneur I think you were using the open Ai apis and you had built a question and answer query engine which was in our language focused on your book which was the Corpus yeah can you talk a little bit in a project totally so like a lot of people I've been tracking all the AI stuff in the last few years the generative AI stuff you know starting I guess with GPT 3 was probably when I was like okay this seems to this seems different than than what I saw before maybe there's some commercial value not yet but getting close",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1100, "maxCueIdx": 1136},
    },
    {
        "content": ": 1130 the AI stuff in the last few years the generative AI stuff you know starting I guess with GPT 3 was probably when I was like okay this seems to this seems different than than what I saw before maybe there's some commercial value not yet but getting close and and then Dolly and all that kind of stuff and yeah I just felt like I want to build stuff you know I like building stuff I still do and it it sort of I got to a point where I could you know similar to pre-app store I couldn't accept payments on the internet but the App Store made it possible for me to build an app and you know just upload it you know that's all I had to do and it worked you know people could buy it and download on their phone Etc and so I feel like AI got to this this year where a developer like me who isn't super sophisticated in terms of like you know back-end computer sciencey data structures algorithms type stuff but can like hack together some Python and some HTML Sim CSS and JavaScript and I was like wow that's a moment you know like I remember this happening with payments on the internet and that led to stripe so you know I should pay attention to this feeling I have and so I started building stuff as sort of almost like a like a metal detector right of like if I want to build some interesting thing in AI it'll lead me to all the tools that you know I will use and then I'll",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1131, "maxCueIdx": 1166},
    },
    {
        "content": " know I should pay attention to this feeling I have and so I started building stuff as sort of almost like a like a metal detector right of like if I want to build some interesting thing in AI it'll lead me to all the tools that you know I will use and then I'll email those Founders and ask to be on the cap table and blah blah blah and so you know this was kind of mulling around in my head and I had some ideas actually the first thing I built was was a was a thing trained on images from progress pictures like weight loss progress pictures from Reddit and I wanted to train fine tune a stable diffusion model that would basically generate progress pictures so you could effectively see your weight loss before it happens and if you've tried fine-tuning a model like you probably are listening to this being like this guy's an idiot like how would he think that like yeah enough to be able to do something like that and the point is like you know I knew that I I was 99 sure it was not going to be good but I would have to do it you know the cool thing about AI is that it's not deterministic and so the only way I'm going to know how bad it is is to actually just go through the exercise and I was actually surprised at how it was bad it certainly isn't functionally useful you know to like look at yourself you know and it's not accurate at all but it certainly was accurate enough where I could say a",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1161, "maxCueIdx": 1196},
    },
    {
        "content": " 1190 is to actually just go through the exercise and I was actually surprised at how it was bad it certainly isn't functionally useful you know to like look at yourself you know and it's not accurate at all but it certainly was accurate enough where I could say a hundred pounds or it's 500 pounds and it would do it would kind of get a sense of of that but anyway I started just just hacking on that and and then I had this idea where I wrote this book The minimalist entrepreneur came out in in minimalist entrepreneur came out in in 2021 2021 and you know it's done decently well it's like sold 10 000 plus copies Etc all that good stuff but I just felt like and I've been feeling this for a while where like books don't feel like the right like I love reading books but most people don't read books not that much not that frequently and when they do it's like Catcher in the Rye or Harry Potter or something and nothing wrong with it well you know 10K copies sold is a very good outcome for a non-fiction book but you know you might reach people more more people with one tweet exactly and so I just I felt like you know their books are so great I you know and I still read them and people should continue to write them but maybe there are different kinds of formats that that you know we can explore and AI felt like one of those and I",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1191, "maxCueIdx": 1226},
    },
    {
        "content": " I just I felt like you know their books are so great I you know and I still read them and people should continue to write them but maybe there are different kinds of formats that that you know we can explore and AI felt like one of those and I I saw this I forgot exactly how I saw it but I I sort of realized like oh wait like you know one issue with with gpt3 is that you can't it's not focused right it's like it's just like you can't ask it questions on like a book or something like that you can ask it if it happens to have read the book it's part of you know it's training maybe but but not really and so what I what I discovered was this concept of embeddings which blew my mind which was just basically this idea that pretty simply I could take 50 000 words from my book and effectively find the most relevant 500 effectively find the most relevant 500 Words Words and that means that that's enough that I can just put those words directly in the prompt and effectively you know all of the code is all the sort of conditional logic is just actually part of that you know prompt window that the user doesn't actually see but it basically says you know sahil is you know the founder of gum ready wrote a book this is a question answer it right that sort of thing but what you can do with embeddings is you can actually say by the way here",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1220, "maxCueIdx": 1256},
    },
    {
        "content": ": 1250 the user doesn't actually see but it basically says you know sahil is you know the founder of gum ready wrote a book this is a question answer it right that sort of thing but what you can do with embeddings is you can actually say by the way here's some context from the book that might be useful insert all of that in the context and then answer you know sort of have that have the AI complete that prompt and when I realized that Insight I was like wait a second this this is an amazing use case for AI this this is an amazing use case for AI and and this would make chatting about a subject interesting and and at that point this is you know before chat gbt so now chatting with AI is popular again but that was a pretty I think key Insight I had which was like there's a better format for like question answer question answer is you know really ai's become really good for question answer people don't know this yet and so I'm going to build a chat UI you know for my book basically to to be able to talk to my book and so I built that past mybook.com it's you know like maybe 200 300 lines of python it sort of takes the the PDF of my manuscript turns it into a CSV file of file of pages pages and then takes that Pages CSV file you know creates embeddings on it using open ai's API and then uses those embeddings to you know stop",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1251, "maxCueIdx": 1287},
    },
    {
        "content": " the the PDF of my manuscript turns it into a CSV file of file of pages pages and then takes that Pages CSV file you know creates embeddings on it using open ai's API and then uses those embeddings to you know stop the prompt and so it's effectively like sort of two two things happening but yeah it's it's kind of magical it's kind of magical when you realize like oh wow it's just like it's a very simple thing right but it feels like you're sort of standing on the shoulders of giants you know it's like I built Google search without having to build Google search you know just by building the the Box the input and so it's pretty it's pretty crazy it's pretty it's pretty cool and I have some you know stuff working on now that I think will be pretty interesting too I'm happy to talk about but I do think AI is getting to that point where you know people can build consumer facing applications with it which is important right because at the end of the day Google assistant is great but like you need a thousand Engineers to do that right or Alexa or Siri but like I'm just Joe Schmo I just I'm one dude who likes to build stuff and we had a variable that I can do we had a very similar realization to yours also pre-chat GPT and for the audience let me just unpack a little bit what you just because you just explained what you did and by the",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1280, "maxCueIdx": 1316},
    },
    {
        "content": " I just I'm one dude who likes to build stuff and we had a variable that I can do we had a very similar realization to yours also pre-chat GPT and for the audience let me just unpack a little bit what you just because you just explained what you did and by the way if you I'll put the link in the show notes but if you're interested to see how this works so I would definitely suggest you go to ask my book and see how well this works it's only as I'll set a few hundred lines of python I believe you chunked your book into page link chunks and then through the embedding engine you basically map that page of natural you basically map that page of natural language language into the word Vector space so these all these large language models work by taking the semantic meaning of human natural language and mapping to a vector in an abstract space of human Concepts and so is that right your chunk size was about one page exactly right exactly yeah so he then if you type in a query it can fi it can take that natural language query map that also into the embedding space find the vector Which is closest which has the smallest inner product with the vector corresponding to your query among all those one page vectors that came from his book and then he can use that as a prompt hidden prompt to the AI saying hey take this into account and answer this guy's question it's and you get extremely good",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1311, "maxCueIdx": 1348},
    },
    {
        "content": " the vector corresponding to your query among all those one page vectors that came from his book and then he can use that as a prompt hidden prompt to the AI saying hey take this into account and answer this guy's question it's and you get extremely good results I mean I've played around with your on your with your ask my book functionality it's extremely good it's yeah it's crazy good and one thing that I think is so empowering about it is that it is almost like coding with natural language right where you're sort of able to say like if this do that else do this but I actually do it by actually just writing it out which is kind of it's almost like a Transformer right where you're able to effectively write pseudo code and then like kind of it outputs it sort of does what the what the proper code would have done if that code had been written right in a different setting like some listeners may know about codex and copilot and stuff like this in like we're talking about tricks to allow you to ask questions and then the the AI answers using information that's in sahil's book but the other thing you could do is just give pseudo code to the AI and it actually returned well-formatted python still executable python crazies yeah it's crazy so it's almost it's yeah it's very very very exciting to see AI get to a place where consumers will start to use it because what that means is that",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1342, "maxCueIdx": 1378},
    },
    {
        "content": "2 code to the AI and it actually returned well-formatted python still executable python crazies yeah it's crazy so it's almost it's yeah it's very very very exciting to see AI get to a place where consumers will start to use it because what that means is that consumers will start to give AI all their data and reinforcement learning will start to happen I think at like you know 10 100x when you're all these people starting to like upvote and downvote AI picks and all that kind of stuff yeah so that's going to be I mean I can see the the feedback loop right of like you launch an app you get 10 000 users the model is kind of crappy but these people need it badly enough it's the people who are the best and most worth thinking that probably will use this Tech anyway they're going to inform the model and then the new model comes out and all of a sudden the model is like 50 times better and now works for everybody else too you know yeah the key the key is what you just said that you're gonna suddenly have huge corpuses for of reinforcement learning data which previously hadn't really been in used in GPT 3 but was used in chat GPT there was a lot of RL stuff in chat GPT and I think and yeah if that you might think what it leads to I mean that's pretty epic right I mean the yeah the believability I think the information I think they",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1373, "maxCueIdx": 1407},
    },
    {
        "content": "PT 3 but was used in chat GPT there was a lot of RL stuff in chat GPT and I think and yeah if that you might think what it leads to I mean that's pretty epic right I mean the yeah the believability I think the information I think they said this where like the the accuracy is roughly equivalent which is why they don't sort of give it a four maybe maybe they intended to make this four and they but like I think the human rating of the responses like it just feels so much better right it just it basically has like learned to like speak like how you would expect a human like kind of a librarian to kind of speak which I also think is by the way just like a fascinating thing to think about which is like you know you kind of mentioned my American accent right but like what if like like I kind of have like an international accent all it's like what if this is like the accent of AI right like it's just the accent and uh and you know if you're training an AI that sort of generally you know general purpose like this is sort of like the the mean you know the and and it sort of talks like that right like it's sort of for some reason it sort of reminds me of like talking to a college admissions counselor or a librarian or like you know we've kind of picked like the the middle of the Bell you know like we've picked a voice and which is which",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1402, "maxCueIdx": 1438},
    },
    {
        "content": "2 right like it's sort of for some reason it sort of reminds me of like talking to a college admissions counselor or a librarian or like you know we've kind of picked like the the middle of the Bell you know like we've picked a voice and which is which is kind of interesting you know it kind of I think there's a lot of yeah in GPT specifically I think there's a lot of Reddit and Twitter and you know there is a certain influence of the Corpus on what what the thing actually sounds sounds and feels like when you interact with it the thing we're interested in ourselves like one of the problems still with chat GPT is that it has the right feels right it does seem like you're chatting with a real human-like thing but it will occasionally insert false information and say things to you authoritatively which are just completely wrong and probably because the original huge training Corpus you know that that tuned those 100 or 200 billion Connections in the neural net some of that information is not true and and it would be better if you could force it to when it makes authoritative statements draw from a focused Corpus and ignore that earlier stuff that was used in its training which isn't necessarily true and so that that's what we're working on now is you know because like I I never had this experience when it was talk I was talking to your book it was talk I was talking to your book but ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1433, "maxCueIdx": 1468},
    },
    {
        "content": " was used in its training which isn't necessarily true and so that that's what we're working on now is you know because like I I never had this experience when it was talk I was talking to your book it was talk I was talking to your book but but I could imagine it saying something about startups or you know financing or something that was just wrong and didn't come from your book right that's that's actually possible for it to do or at least chat gbt will do stuff like that um totally say stuff like you know saw you know yeah you could you could get it to say things that are that are not true I try to avoid that you know I can you can set the temperature and things like this but yeah at the end of the day and that's kind of yeah you can't yeah you don't you don't want to stop it from saying like one Hill soil was very sad to drop out of the NASA astronaut program but he really wanted to start his company here so yeah exactly probably could get it to say something like that yes the best bullshiter alive yeah exactly so if you can make it less of a good bullshitter but actually better at like going through all everything Bloomberg knows about this particular new drug development you know then an investment banker can use it as something that just reads all the things that he doesn't have time to read but it is a extremely useful tool for ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1463, "maxCueIdx": 1499},
    },
    {
        "content": " 1493 better at like going through all everything Bloomberg knows about this particular new drug development you know then an investment banker can use it as something that just reads all the things that he doesn't have time to read but it is a extremely useful tool for him in doing his job exactly and so that's what we're trying to do is make it more reliable that's awesome yeah and I think I don't know if transparency fits into this but I've always up that that transparency is always appeal to me generally as like just being open about gumroad and financials and I think that's also kind of an opportunity that I think will unfold over the next several years is is you know we may not be able to tell you exactly like where this information comes from all the time but I do think being able to cite sources and say hey this is kind of where we you know these are the top three URLs that we think we may have sourced this stuff for them or you know things like that and certainly you can do it on like a on that sort of focused Corpus right where you could say hey Paige this is from page 178 this this is from page 271 Etc and I do think that I mean like the key Insight that I think I had with ask my book was it's actually a very simple productivity gain which is the book is 250 pages and I'm telling you based on your question the page right like or the three or the",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1494, "maxCueIdx": 1529},
    },
    {
        "content": " Etc and I do think that I mean like the key Insight that I think I had with ask my book was it's actually a very simple productivity gain which is the book is 250 pages and I'm telling you based on your question the page right like or the three or the four pages and so it's even if that's all that's really happening that's still a massive productivity game because you basically went from you know 250 pages to two like 100x yeah right and so even if all you're doing then is still saying you know what you know answer this question based on what's above and return the page number so the person can actually go read it or whatever you're it's still massively valuable right it's kind of like yeah the glossary at the end of a book we should we should just completely Stop Printing it makes no sense you know it's like so and by the way someone is I learned this like with my book like there's a job and like someone manually makes that list literally yeah and I'm like that is exact you know that should not be like the only reason that exists because you can't control F right like an actual book but yeah like that that's such a sort of sort of a vestigial you know tail in a way and yeah it really makes sense to me that you know you buy the book and if you you know have rights to that book you should be able to ask it questions just like you can read the ID: ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1524, "maxCueIdx": 1558},
    },
    {
        "content": " such a sort of sort of a vestigial you know tail in a way and yeah it really makes sense to me that you know you buy the book and if you you know have rights to that book you should be able to ask it questions just like you can read the book and ask it questions right you just you don't actually have to read them but now now imagine an app where it scans the hundred books that you tell it that you want in the Corpus that are on your hard drive and it basically uses all of those so say that's 100 books on data science or something and you're a data scientist and you and maybe in addition to 100 papers you have 100 books you have like a thousand 100 books you have like a thousand papers papers and that's your Corpus and now your little buddy your data science AI buddy is on your in the app on your machine basically navigates that literature for you I think that I think there's a market for that I think it's very interesting and I I I've thought a little like in the context of asked my book I've thought a little bit about what would be really cool is yeah being able to ask multiple books at the same time the same question and maybe even figuring out could you get these folks to argue you know yep hey Peter Thiel this you say this go you know I think that's one thing that I I really think there's going to be a huge unlock is ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1553, "maxCueIdx": 1589},
    },
    {
        "content": " time the same question and maybe even figuring out could you get these folks to argue you know yep hey Peter Thiel this you say this go you know I think that's one thing that I I really think there's going to be a huge unlock is when people figure out how to get the AI to talk to humans right because at the end of the day Tick Tock and Netflix they're appealing because you can just sit there you know you can just like kind of conk out and that will always be a human desire to conk out and you know I think right now it's just like reading books it's still a lot of energy you know asking questions having a chat that's getting better it's getting more interesting I assume that 10 or 100 x more people are going to do that than read the books themselves once this stuff is really out there but even better it would be like tell me what you know like based on my Twitter account you know tell me what's interesting from your book right like and then I can ask you a question you know like it can yeah well ask me a question you know like I think there's a there's a lot more there that will start to happen once we get the reinforcement learning like once we get the layers of you know it's gonna start to happen and it's going to be I'm just so excited because it feels like it genuinely feels like there will be new formats you know that that will have words like we will",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1583, "maxCueIdx": 1618},
    },
    {
        "content": " to happen once we get the reinforcement learning like once we get the layers of you know it's gonna start to happen and it's going to be I'm just so excited because it feels like it genuinely feels like there will be new formats you know that that will have words like we will have new nouns you know ask books or something you know like there will be a new way of thinking about this sort of thing I'm very AI books very excited thing I'm very AI books very excited yeah yeah so last question because I know you gotta stop do you ever think you'll start another company right now you're doing investing but uh do you ever get the itch to be a Founder again um I don't know if I'll ever I think if I started a new company it would be it because it is not software consumer software like it requires a completely different team I think I would I think I would potentially co-found a company like if there was somebody who I felt like wow this person probably like a scientist of some sort needs help needs a co-founder and like this is you know the the sort of the thing I want to work on for the next 10 20 years like if it's some crazy you know synthetic womb startup or you know something like that I think I could get really excited about but I don't know I I just love building stuff and I I think I'm good at this certain thing and I'm gonna you know I ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1613, "maxCueIdx": 1648},
    },
    {
        "content": "'s some crazy you know synthetic womb startup or you know something like that I think I could get really excited about but I don't know I I just love building stuff and I I think I'm good at this certain thing and I'm gonna you know I can invest and hopefully that you know satisfies my fomo but yeah I mean I think at the end of the day what I would love to do is figure out how can I eat my cake and have it too you know like can I make fun road you know we're building a new product at Gum Road now which is like kind of like all the fun Parts about building a company you know I don't have to hire anyone I don't have to fire anyone I can just say hey we're building a new product now and so you know we'll if that works we'll spin it out and that you know may be a new company and I might be the CEO of two two things and you know government kind of becomes more of like an incubator lab type deal but yeah I just I I'm always just kind of thinking about like do I need a company to do that right at the end of the day that's just a legal concept right and yeah I don't I don't know but I'm I'm open to it but I also think like I'd rather what I've learned in Latin especially building stuff for the AI what's so important is to just solve your own problem right and I think a lot of people especially ID:",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1643, "maxCueIdx": 1677},
    },
    {
        "content": " I don't I don't know but I'm I'm open to it but I also think like I'd rather what I've learned in Latin especially building stuff for the AI what's so important is to just solve your own problem right and I think a lot of people especially when markets were really good or like I need to go start a company you know what can I go do what can I go solve what skills do I have and I think the best companies are kind of like toys they're kind of like hey I'm just gonna solve my own problem I'm going to make it better and better oh crap this VC wants to give me a bunch of money or oh crap like Sony is like you know we want this to power you know this thing or or whatnot right and I don't know I think Randomness is always like a pretty key thing when you hear stories sometimes it feels like it wasn't random you know it was all planned right but but yeah I don't know I think I I like to just sort of stay focused on just solving problems and if it makes sense to start a company then you know doing that I think luckily like nowadays starting a company is the easy part raising money and audience building and all that stuff what's hard is like the science the research the tech the engineering you know that's the stuff that I think is really hard takes a lot of time and you don't need a company necessarily to do that you know so well as a guy",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1672, "maxCueIdx": 1707},
    },
    {
        "content": " all that stuff what's hard is like the science the research the tech the engineering you know that's the stuff that I think is really hard takes a lot of time and you don't need a company necessarily to do that you know so well as a guy who's primarily founded deep Tech type companies I can tell you yeah it is it's a different situation than than using kind of off-the-shelf software to build a product it's it's quite a different thing yeah just the idea that I could have you know built gumroad in a weekend and then raised a million dollars off this like 20 hour project right like it's crazy it shows like what supply and demand looks like for a consumer sort of software product engineer type early stage CEOs but I'd rather do that I'd rather build a thing and then raise the money because that's kind of the things that I tend to build anyway right like they don't need a lot of people a lot of you know a lot of Staff or Capital you know expenditure they're sort of simple apps you know but yeah I could totally see myself like I'm not opposed to it I think a lot of people are kind of like I'm done you know and I'm like I'm definitely not done like I will be working in some capacity you know on stuff until I die like I just think it's it's just so fun and rewarding and yeah it's what I do for fun you know like it's it's it's it",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1701, "maxCueIdx": 1736},
    },
    {
        "content": " know and I'm like I'm definitely not done like I will be working in some capacity you know on stuff until I die like I just think it's it's just so fun and rewarding and yeah it's what I do for fun you know like it's it's it's it's more fun than it's ever been to be honest like reading reading patents for like one click checkout is pales come in comparison to reading AI papers where people are tearing like 2D text prompt like text prompts into like 3D models you know so yeah it's like a video game you know it's like better than any video all right well Sal I know you've got to go so um let's just uh stop here thank you very much for your time it's been fantastic I really look forward to seeing some of the future projects that you work on thank you it was super fun to do this I really enjoy the chat to do this I really enjoy the chat ",
        "metadata": {"videoId": "rAFkAvC27yI", "minCueIdx": 1731, "maxCueIdx": 1754},
    },
]

resources = [
    {
        "content": 'Anatomy of an AI Agent  | "A Survey on Large Language Model based Autonomous Agents"'
    },
    {
        "content": "How Large Language Models Work",
    },
    {
        "content": "MIT CSAIL Explains: Large Language Models: Part 1",
    },
    {
        "content": "How Neural Networks Learned to Talk | ChatGPT: A 30 Year History",
    },
    {
        "content": "[1hr Talk] Intro to Large Language Models",
    },
    {
        "content": "GPT-3: Language Models are Few-Shot Learners (Paper Explained)",
    },
    {
        "content": "Why Large Language Models Hallucinate",
    },
    {
        "content": "Large Language Models and the Future of AI with Connor Leahy, EleutherAI",
    },
    {
        "content": "What are Large Language Models (LLMs)?",
    },
    {
        "content": "GPT3: An Even Bigger Language Model - Computerphile",
    },
    {
        "content": "Are Large Language Models a Path to AGI? with Ben Goertzel - 625",
    },
    {"content": "LLM agents in science"},
]

if __name__ == "__main__":
    res = rag(
        {
            "query": "Examples of real-world scenarios where LLM Agents are currently being utilized?",
            #     "How have LLM Agents advanced and developed since their inception?",
            #     "What are the applications of LLM Agents in various fields?",
            # ],
            "docs": resources,
            "k": 10,
        }
    )
    print(json.dumps(res, indent=2))
